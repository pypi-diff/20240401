# Comparing `tmp/sparseml_nightly-1.7.0.20240304-py3-none-any.whl.zip` & `tmp/sparseml_nightly-1.8.0.20240401-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,539 +1,569 @@
-Zip file size: 1273169 bytes, number of entries: 537
--rw-r--r--  2.0 unx     1489 b- defN 24-Mar-04 22:24 sparseml/__init__.py
--rw-r--r--  2.0 unx      898 b- defN 24-Mar-04 22:24 sparseml/analytics.py
--rw-r--r--  2.0 unx    10284 b- defN 24-Mar-04 22:24 sparseml/base.py
--rw-r--r--  2.0 unx     7288 b- defN 24-Mar-04 22:24 sparseml/integration_helper_functions.py
--rw-r--r--  2.0 unx     2483 b- defN 24-Mar-04 22:24 sparseml/log.py
--rw-r--r--  2.0 unx     1511 b- defN 24-Mar-04 22:24 sparseml/version.py
--rw-r--r--  2.0 unx      758 b- defN 24-Mar-04 22:24 sparseml/benchmark/__init__.py
--rw-r--r--  2.0 unx    17763 b- defN 24-Mar-04 22:24 sparseml/benchmark/info.py
--rw-r--r--  2.0 unx    10778 b- defN 24-Mar-04 22:24 sparseml/benchmark/serialization.py
--rw-r--r--  2.0 unx      915 b- defN 24-Mar-04 22:24 sparseml/core/__init__.py
--rw-r--r--  2.0 unx     6842 b- defN 24-Mar-04 22:24 sparseml/core/event.py
--rw-r--r--  2.0 unx     6492 b- defN 24-Mar-04 22:24 sparseml/core/factory.py
--rw-r--r--  2.0 unx     2850 b- defN 24-Mar-04 22:24 sparseml/core/framework.py
--rw-r--r--  2.0 unx     2855 b- defN 24-Mar-04 22:24 sparseml/core/framework_object.py
--rw-r--r--  2.0 unx     3780 b- defN 24-Mar-04 22:24 sparseml/core/helpers.py
--rw-r--r--  2.0 unx    23720 b- defN 24-Mar-04 22:24 sparseml/core/session.py
--rw-r--r--  2.0 unx     9034 b- defN 24-Mar-04 22:24 sparseml/core/state.py
--rw-r--r--  2.0 unx      667 b- defN 24-Mar-04 22:24 sparseml/core/data/__init__.py
--rw-r--r--  2.0 unx     1565 b- defN 24-Mar-04 22:24 sparseml/core/data/base.py
--rw-r--r--  2.0 unx     6415 b- defN 24-Mar-04 22:24 sparseml/core/data/pytorch.py
--rw-r--r--  2.0 unx      678 b- defN 24-Mar-04 22:24 sparseml/core/lifecycle/__init__.py
--rw-r--r--  2.0 unx    11954 b- defN 24-Mar-04 22:24 sparseml/core/lifecycle/event.py
--rw-r--r--  2.0 unx     8242 b- defN 24-Mar-04 22:24 sparseml/core/lifecycle/session.py
--rw-r--r--  2.0 unx      654 b- defN 24-Mar-04 22:24 sparseml/core/logger/__init__.py
--rw-r--r--  2.0 unx    44657 b- defN 24-Mar-04 22:24 sparseml/core/logger/logger.py
--rw-r--r--  2.0 unx      667 b- defN 24-Mar-04 22:24 sparseml/core/logger/utils/__init__.py
--rw-r--r--  2.0 unx    12725 b- defN 24-Mar-04 22:24 sparseml/core/logger/utils/frequency_manager.py
--rw-r--r--  2.0 unx      693 b- defN 24-Mar-04 22:24 sparseml/core/model/__init__.py
--rw-r--r--  2.0 unx     5639 b- defN 24-Mar-04 22:24 sparseml/core/model/base.py
--rw-r--r--  2.0 unx     5200 b- defN 24-Mar-04 22:24 sparseml/core/model/pytorch.py
--rw-r--r--  2.0 unx      699 b- defN 24-Mar-04 22:24 sparseml/core/modifier/__init__.py
--rw-r--r--  2.0 unx     3326 b- defN 24-Mar-04 22:24 sparseml/core/modifier/base.py
--rw-r--r--  2.0 unx    10810 b- defN 24-Mar-04 22:24 sparseml/core/modifier/modifier.py
--rw-r--r--  2.0 unx     6093 b- defN 24-Mar-04 22:24 sparseml/core/modifier/stage.py
--rw-r--r--  2.0 unx      672 b- defN 24-Mar-04 22:24 sparseml/core/optimizer/__init__.py
--rw-r--r--  2.0 unx     3409 b- defN 24-Mar-04 22:24 sparseml/core/optimizer/base.py
--rw-r--r--  2.0 unx     4584 b- defN 24-Mar-04 22:24 sparseml/core/optimizer/pytorch.py
--rw-r--r--  2.0 unx      790 b- defN 24-Mar-04 22:24 sparseml/core/recipe/__init__.py
--rw-r--r--  2.0 unx     6872 b- defN 24-Mar-04 22:24 sparseml/core/recipe/args.py
--rw-r--r--  2.0 unx     1599 b- defN 24-Mar-04 22:24 sparseml/core/recipe/base.py
--rw-r--r--  2.0 unx     6016 b- defN 24-Mar-04 22:24 sparseml/core/recipe/container.py
--rw-r--r--  2.0 unx     2932 b- defN 24-Mar-04 22:24 sparseml/core/recipe/metadata.py
--rw-r--r--  2.0 unx     4196 b- defN 24-Mar-04 22:24 sparseml/core/recipe/modifier.py
--rw-r--r--  2.0 unx    19994 b- defN 24-Mar-04 22:24 sparseml/core/recipe/recipe.py
--rw-r--r--  2.0 unx     7629 b- defN 24-Mar-04 22:24 sparseml/core/recipe/stage.py
--rw-r--r--  2.0 unx      863 b- defN 24-Mar-04 22:24 sparseml/deepsparse/__init__.py
--rw-r--r--  2.0 unx     3516 b- defN 24-Mar-04 22:24 sparseml/deepsparse/base.py
--rw-r--r--  2.0 unx      801 b- defN 24-Mar-04 22:24 sparseml/deepsparse/framework/__init__.py
--rw-r--r--  2.0 unx     6032 b- defN 24-Mar-04 22:24 sparseml/deepsparse/framework/info.py
--rw-r--r--  2.0 unx      813 b- defN 24-Mar-04 22:24 sparseml/deepsparse/sparsification/__init__.py
--rw-r--r--  2.0 unx     1348 b- defN 24-Mar-04 22:24 sparseml/deepsparse/sparsification/info.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/evaluation/__init__.py
--rw-r--r--  2.0 unx     5689 b- defN 24-Mar-04 22:24 sparseml/evaluation/cli.py
--rw-r--r--  2.0 unx     1983 b- defN 24-Mar-04 22:24 sparseml/evaluation/evaluator.py
--rw-r--r--  2.0 unx      940 b- defN 24-Mar-04 22:24 sparseml/evaluation/integrations_config.yaml
--rw-r--r--  2.0 unx     5571 b- defN 24-Mar-04 22:24 sparseml/evaluation/registry.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/evaluation/integrations/__init__.py
--rw-r--r--  2.0 unx     5834 b- defN 24-Mar-04 22:24 sparseml/evaluation/integrations/lm_evaluation_harness.py
--rw-r--r--  2.0 unx    11062 b- defN 24-Mar-04 22:24 sparseml/evaluation/integrations/perplexity.py
--rw-r--r--  2.0 unx      661 b- defN 24-Mar-04 22:24 sparseml/export/__init__.py
--rw-r--r--  2.0 unx    21172 b- defN 24-Mar-04 22:24 sparseml/export/export.py
--rw-r--r--  2.0 unx     8049 b- defN 24-Mar-04 22:24 sparseml/export/export_data.py
--rw-r--r--  2.0 unx     2681 b- defN 24-Mar-04 22:24 sparseml/export/export_torch_model.py
--rw-r--r--  2.0 unx    13052 b- defN 24-Mar-04 22:24 sparseml/export/helpers.py
--rw-r--r--  2.0 unx     7951 b- defN 24-Mar-04 22:24 sparseml/export/validators.py
--rw-r--r--  2.0 unx      786 b- defN 24-Mar-04 22:24 sparseml/exporters/__init__.py
--rw-r--r--  2.0 unx     1477 b- defN 24-Mar-04 22:24 sparseml/exporters/base_exporter.py
--rw-r--r--  2.0 unx     6576 b- defN 24-Mar-04 22:24 sparseml/exporters/kv_cache_injector.py
--rw-r--r--  2.0 unx     5522 b- defN 24-Mar-04 22:24 sparseml/exporters/onnx_to_deepsparse.py
--rw-r--r--  2.0 unx     2350 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/__init__.py
--rw-r--r--  2.0 unx     2333 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/base_transform.py
--rw-r--r--  2.0 unx     1388 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/constants_to_initializers.py
--rw-r--r--  2.0 unx     4630 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/conv_to_convinteger_add_cast_mul.py
--rw-r--r--  2.0 unx     5973 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/conv_to_qlinearconv.py
--rw-r--r--  2.0 unx     2440 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/delete_repeated_qdq.py
--rw-r--r--  2.0 unx     1842 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/delete_trivial_onnx_adds.py
--rw-r--r--  2.0 unx     2241 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/flatten_qparams.py
--rw-r--r--  2.0 unx     3553 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/fold_conv_div_bn.py
--rw-r--r--  2.0 unx     1669 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/fold_identity_initializers.py
--rw-r--r--  2.0 unx     2070 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/fold_relu_quants.py
--rw-r--r--  2.0 unx     4418 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/gemm_to_matmulinteger_add_cast_mul.py
--rw-r--r--  2.0 unx     7629 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/gemm_to_qlinearmatmul.py
--rw-r--r--  2.0 unx     1645 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/initializers_to_uint8.py
--rw-r--r--  2.0 unx     6297 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/matmul_add_to_matmulinteger_add_cast_mul.py
--rw-r--r--  2.0 unx     4681 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/matmul_to_matmulinteger_cast_mul.py
--rw-r--r--  2.0 unx     4156 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/matmul_to_qlinearmatmul.py
--rw-r--r--  2.0 unx     3770 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/onnx_transform.py
--rw-r--r--  2.0 unx     3433 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/propagate_dequant_through_split.py
--rw-r--r--  2.0 unx     4801 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/propagate_embedding_quantization.py
--rw-r--r--  2.0 unx     4464 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/quantize_qat_embedding.py
--rw-r--r--  2.0 unx     3869 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/quantize_residuals.py
--rw-r--r--  2.0 unx     3331 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/remove_duplicate_qconv_weights.py
--rw-r--r--  2.0 unx     2545 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/remove_duplicate_quantize_ops.py
--rw-r--r--  2.0 unx     3210 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/skip_input_quantize.py
--rw-r--r--  2.0 unx     1373 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/unwrap_batchnorms.py
--rw-r--r--  2.0 unx      911 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/__init__.py
--rw-r--r--  2.0 unx    30558 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/cache_keys_and_values.py
--rw-r--r--  2.0 unx    10686 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/configs.py
--rw-r--r--  2.0 unx     7027 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/transforms_base.py
--rw-r--r--  2.0 unx     4974 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/transforms_codegen.py
--rw-r--r--  2.0 unx     8801 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/transforms_llama.py
--rw-r--r--  2.0 unx     4261 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/transforms_mpt.py
--rw-r--r--  2.0 unx     6066 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/kv_cache/transforms_opt.py
--rw-r--r--  2.0 unx      730 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/utils/__init__.py
--rw-r--r--  2.0 unx    11112 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/utils/add_quantized_conv_matmul_add_ops.py
--rw-r--r--  2.0 unx     6809 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/utils/helpers.py
--rw-r--r--  2.0 unx    14429 b- defN 24-Mar-04 22:24 sparseml/exporters/transforms/utils/matching.py
--rw-r--r--  2.0 unx      790 b- defN 24-Mar-04 22:24 sparseml/framework/__init__.py
--rw-r--r--  2.0 unx     9479 b- defN 24-Mar-04 22:24 sparseml/framework/info.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/__init__.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/__init__.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/evaluator.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/trainer.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/data/__init__.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/metrics/__init__.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/model/__init__.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/integrations/torchvision/optim/__init__.py
--rw-r--r--  2.0 unx     1144 b- defN 24-Mar-04 22:24 sparseml/keras/__init__.py
--rw-r--r--  2.0 unx     8054 b- defN 24-Mar-04 22:24 sparseml/keras/base.py
--rw-r--r--  2.0 unx      943 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/__init__.py
--rw-r--r--  2.0 unx     3297 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/dataset.py
--rw-r--r--  2.0 unx     2423 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/helpers.py
--rw-r--r--  2.0 unx     2761 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/registry.py
--rw-r--r--  2.0 unx      786 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/classification/__init__.py
--rw-r--r--  2.0 unx     8369 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/classification/imagefolder.py
--rw-r--r--  2.0 unx     4301 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/classification/imagenet.py
--rw-r--r--  2.0 unx     2727 b- defN 24-Mar-04 22:24 sparseml/keras/datasets/classification/imagenette.py
--rw-r--r--  2.0 unx      793 b- defN 24-Mar-04 22:24 sparseml/keras/framework/__init__.py
--rw-r--r--  2.0 unx     5906 b- defN 24-Mar-04 22:24 sparseml/keras/framework/info.py
--rw-r--r--  2.0 unx      921 b- defN 24-Mar-04 22:24 sparseml/keras/models/__init__.py
--rw-r--r--  2.0 unx    11814 b- defN 24-Mar-04 22:24 sparseml/keras/models/registry.py
--rw-r--r--  2.0 unx      656 b- defN 24-Mar-04 22:24 sparseml/keras/models/classification/__init__.py
--rw-r--r--  2.0 unx    17932 b- defN 24-Mar-04 22:24 sparseml/keras/models/classification/resnet.py
--rw-r--r--  2.0 unx      768 b- defN 24-Mar-04 22:24 sparseml/keras/models/external/__init__.py
--rw-r--r--  2.0 unx     4402 b- defN 24-Mar-04 22:24 sparseml/keras/models/external/keras_applications.py
--rw-r--r--  2.0 unx     1166 b- defN 24-Mar-04 22:24 sparseml/keras/optim/__init__.py
--rw-r--r--  2.0 unx     5677 b- defN 24-Mar-04 22:24 sparseml/keras/optim/manager.py
--rw-r--r--  2.0 unx    14777 b- defN 24-Mar-04 22:24 sparseml/keras/optim/mask_pruning.py
--rw-r--r--  2.0 unx    19740 b- defN 24-Mar-04 22:24 sparseml/keras/optim/mask_pruning_creator.py
--rw-r--r--  2.0 unx     9183 b- defN 24-Mar-04 22:24 sparseml/keras/optim/modifier.py
--rw-r--r--  2.0 unx     1676 b- defN 24-Mar-04 22:24 sparseml/keras/optim/modifier_epoch.py
--rw-r--r--  2.0 unx    14736 b- defN 24-Mar-04 22:24 sparseml/keras/optim/modifier_lr.py
--rw-r--r--  2.0 unx     5477 b- defN 24-Mar-04 22:24 sparseml/keras/optim/modifier_params.py
--rw-r--r--  2.0 unx    24031 b- defN 24-Mar-04 22:24 sparseml/keras/optim/modifier_pruning.py
--rw-r--r--  2.0 unx     1133 b- defN 24-Mar-04 22:24 sparseml/keras/optim/utils.py
--rw-r--r--  2.0 unx      808 b- defN 24-Mar-04 22:24 sparseml/keras/sparsification/__init__.py
--rw-r--r--  2.0 unx     1356 b- defN 24-Mar-04 22:24 sparseml/keras/sparsification/info.py
--rw-r--r--  2.0 unx      962 b- defN 24-Mar-04 22:24 sparseml/keras/utils/__init__.py
--rw-r--r--  2.0 unx     8202 b- defN 24-Mar-04 22:24 sparseml/keras/utils/callbacks.py
--rw-r--r--  2.0 unx     1022 b- defN 24-Mar-04 22:24 sparseml/keras/utils/compat.py
--rw-r--r--  2.0 unx     5737 b- defN 24-Mar-04 22:24 sparseml/keras/utils/exporter.py
--rw-r--r--  2.0 unx     6087 b- defN 24-Mar-04 22:24 sparseml/keras/utils/logger.py
--rw-r--r--  2.0 unx     1738 b- defN 24-Mar-04 22:24 sparseml/keras/utils/model.py
--rw-r--r--  2.0 unx      800 b- defN 24-Mar-04 22:24 sparseml/modifiers/__init__.py
--rw-r--r--  2.0 unx      656 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/__init__.py
--rw-r--r--  2.0 unx      654 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/output/__init__.py
--rw-r--r--  2.0 unx     1343 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/output/base.py
--rw-r--r--  2.0 unx     7612 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/output/pytorch.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/utils/__init__.py
--rw-r--r--  2.0 unx      715 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/utils/pytorch/__init__.py
--rw-r--r--  2.0 unx    13320 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/utils/pytorch/kd_factory.py
--rw-r--r--  2.0 unx     3921 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/utils/pytorch/kd_wrapper.py
--rw-r--r--  2.0 unx     4379 b- defN 24-Mar-04 22:24 sparseml/modifiers/distillation/utils/pytorch/model_wrapper.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/experimental/__init__.py
--rw-r--r--  2.0 unx      654 b- defN 24-Mar-04 22:24 sparseml/modifiers/logarithmic_equalization/__init__.py
--rw-r--r--  2.0 unx     2764 b- defN 24-Mar-04 22:24 sparseml/modifiers/logarithmic_equalization/base.py
--rw-r--r--  2.0 unx     1947 b- defN 24-Mar-04 22:24 sparseml/modifiers/logarithmic_equalization/pytorch.py
--rw-r--r--  2.0 unx      654 b- defN 24-Mar-04 22:24 sparseml/modifiers/obcq/__init__.py
--rw-r--r--  2.0 unx     5181 b- defN 24-Mar-04 22:24 sparseml/modifiers/obcq/base.py
--rw-r--r--  2.0 unx     3543 b- defN 24-Mar-04 22:24 sparseml/modifiers/obcq/pytorch.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/obcq/utils/__init__.py
--rw-r--r--  2.0 unx     6686 b- defN 24-Mar-04 22:24 sparseml/modifiers/obcq/utils/helpers.py
--rw-r--r--  2.0 unx     6753 b- defN 24-Mar-04 22:24 sparseml/modifiers/obcq/utils/sgpt_wrapper.py
--rw-r--r--  2.0 unx      683 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/__init__.py
--rw-r--r--  2.0 unx     5725 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/helpers.py
--rw-r--r--  2.0 unx      676 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/constant/__init__.py
--rw-r--r--  2.0 unx      951 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/constant/base.py
--rw-r--r--  2.0 unx     2907 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/constant/pytorch.py
--rw-r--r--  2.0 unx      677 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/magnitude/__init__.py
--rw-r--r--  2.0 unx     1168 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/magnitude/base.py
--rw-r--r--  2.0 unx     5262 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/magnitude/pytorch.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/utils/__init__.py
--rw-r--r--  2.0 unx      688 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/utils/pytorch/__init__.py
--rw-r--r--  2.0 unx     5984 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/utils/pytorch/layer_mask.py
--rw-r--r--  2.0 unx     5622 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/utils/pytorch/mask_factory.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/wanda/__init__.py
--rw-r--r--  2.0 unx     3947 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/wanda/base.py
--rw-r--r--  2.0 unx     9922 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/wanda/pytorch.py
--rw-r--r--  2.0 unx      633 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/wanda/utils/__init__.py
--rw-r--r--  2.0 unx     4469 b- defN 24-Mar-04 22:24 sparseml/modifiers/pruning/wanda/utils/wanda_wrapper.py
--rw-r--r--  2.0 unx      654 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/__init__.py
--rw-r--r--  2.0 unx     5512 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/base.py
--rw-r--r--  2.0 unx     8924 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/pytorch.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/utils/__init__.py
--rw-r--r--  2.0 unx     2220 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/utils/constants.py
--rw-r--r--  2.0 unx     2906 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/utils/fake_quant_wrapper.py
--rw-r--r--  2.0 unx    32720 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/utils/helpers.py
--rw-r--r--  2.0 unx    13545 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/utils/quantization_scheme.py
--rw-r--r--  2.0 unx    19811 b- defN 24-Mar-04 22:24 sparseml/modifiers/quantization/utils/quantize.py
--rw-r--r--  2.0 unx      654 b- defN 24-Mar-04 22:24 sparseml/modifiers/smoothquant/__init__.py
--rw-r--r--  2.0 unx     7535 b- defN 24-Mar-04 22:24 sparseml/modifiers/smoothquant/base.py
--rw-r--r--  2.0 unx     8167 b- defN 24-Mar-04 22:24 sparseml/modifiers/smoothquant/pytorch.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/modifiers/utils/__init__.py
--rw-r--r--  2.0 unx     3944 b- defN 24-Mar-04 22:24 sparseml/modifiers/utils/compression_wrapper.py
--rw-r--r--  2.0 unx     5017 b- defN 24-Mar-04 22:24 sparseml/modifiers/utils/layer_compressor.py
--rw-r--r--  2.0 unx     3265 b- defN 24-Mar-04 22:24 sparseml/modifiers/utils/pytorch_helpers.py
--rw-r--r--  2.0 unx     1036 b- defN 24-Mar-04 22:24 sparseml/onnx/__init__.py
--rw-r--r--  2.0 unx     6202 b- defN 24-Mar-04 22:24 sparseml/onnx/base.py
--rw-r--r--  2.0 unx      743 b- defN 24-Mar-04 22:24 sparseml/onnx/benchmark/__init__.py
--rw-r--r--  2.0 unx    15366 b- defN 24-Mar-04 22:24 sparseml/onnx/benchmark/info.py
--rw-r--r--  2.0 unx      823 b- defN 24-Mar-04 22:24 sparseml/onnx/framework/__init__.py
--rw-r--r--  2.0 unx     6116 b- defN 24-Mar-04 22:24 sparseml/onnx/framework/info.py
--rw-r--r--  2.0 unx      820 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/__init__.py
--rw-r--r--  2.0 unx    13285 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/analyzer_model.py
--rw-r--r--  2.0 unx    19639 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/sensitivity_pruning.py
--rw-r--r--  2.0 unx     6470 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/structured_pruning.py
--rw-r--r--  2.0 unx      815 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/quantization/__init__.py
--rw-r--r--  2.0 unx    14753 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/quantization/calibration.py
--rw-r--r--  2.0 unx    73551 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/quantization/quantize.py
--rw-r--r--  2.0 unx     4552 b- defN 24-Mar-04 22:24 sparseml/onnx/optim/quantization/quantize_model_post_training.py
--rw-r--r--  2.0 unx      869 b- defN 24-Mar-04 22:24 sparseml/onnx/sparsification/__init__.py
--rw-r--r--  2.0 unx    10209 b- defN 24-Mar-04 22:24 sparseml/onnx/sparsification/analyzer.py
--rw-r--r--  2.0 unx     1363 b- defN 24-Mar-04 22:24 sparseml/onnx/sparsification/info.py
--rw-r--r--  2.0 unx     8009 b- defN 24-Mar-04 22:24 sparseml/onnx/sparsification/model_info.py
--rw-r--r--  2.0 unx      867 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/__init__.py
--rw-r--r--  2.0 unx    13013 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/data.py
--rw-r--r--  2.0 unx    20691 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/graph_editor.py
--rw-r--r--  2.0 unx     8133 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/graph_optimizer.py
--rw-r--r--  2.0 unx    40230 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/helpers.py
--rw-r--r--  2.0 unx     1958 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/loss.py
--rw-r--r--  2.0 unx    31591 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/model.py
--rw-r--r--  2.0 unx     5437 b- defN 24-Mar-04 22:24 sparseml/onnx/utils/sparse_tensor.py
--rw-r--r--  2.0 unx      931 b- defN 24-Mar-04 22:24 sparseml/openpifpaf/__init__.py
--rw-r--r--  2.0 unx     3713 b- defN 24-Mar-04 22:24 sparseml/openpifpaf/export.py
--rw-r--r--  2.0 unx    10950 b- defN 24-Mar-04 22:24 sparseml/openpifpaf/train.py
--rw-r--r--  2.0 unx     4211 b- defN 24-Mar-04 22:24 sparseml/openpifpaf/trainer.py
--rw-r--r--  2.0 unx      882 b- defN 24-Mar-04 22:24 sparseml/optim/__init__.py
--rw-r--r--  2.0 unx     6302 b- defN 24-Mar-04 22:24 sparseml/optim/analyzer.py
--rw-r--r--  2.0 unx    25563 b- defN 24-Mar-04 22:24 sparseml/optim/helpers.py
--rw-r--r--  2.0 unx    25984 b- defN 24-Mar-04 22:24 sparseml/optim/manager.py
--rw-r--r--  2.0 unx    30708 b- defN 24-Mar-04 22:24 sparseml/optim/modifier.py
--rw-r--r--  2.0 unx    26315 b- defN 24-Mar-04 22:24 sparseml/optim/sensitivity.py
--rw-r--r--  2.0 unx     2190 b- defN 24-Mar-04 22:24 sparseml/pytorch/__init__.py
--rw-r--r--  2.0 unx     6154 b- defN 24-Mar-04 22:24 sparseml/pytorch/base.py
--rw-r--r--  2.0 unx      933 b- defN 24-Mar-04 22:24 sparseml/pytorch/opset.py
--rw-r--r--  2.0 unx    12086 b- defN 24-Mar-04 22:24 sparseml/pytorch/torch_to_onnx_exporter.py
--rw-r--r--  2.0 unx      998 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/__init__.py
--rw-r--r--  2.0 unx     4193 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/generic.py
--rw-r--r--  2.0 unx     3014 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/registry.py
--rw-r--r--  2.0 unx      828 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/classification/__init__.py
--rw-r--r--  2.0 unx     4457 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/classification/cifar.py
--rw-r--r--  2.0 unx     3669 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/classification/imagefolder.py
--rw-r--r--  2.0 unx     4000 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/classification/imagenet.py
--rw-r--r--  2.0 unx     6491 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/classification/imagenette.py
--rw-r--r--  2.0 unx     2434 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/classification/mnist.py
--rw-r--r--  2.0 unx      767 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/detection/__init__.py
--rw-r--r--  2.0 unx    16159 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/detection/coco.py
--rw-r--r--  2.0 unx     5705 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/detection/helpers.py
--rw-r--r--  2.0 unx    10759 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/detection/voc.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/image_classification/__init__.py
--rw-r--r--  2.0 unx     9512 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/image_classification/ffcv_dataset.py
--rw-r--r--  2.0 unx      684 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/recommendation/__init__.py
--rw-r--r--  2.0 unx      693 b- defN 24-Mar-04 22:24 sparseml/pytorch/datasets/video/__init__.py
--rw-r--r--  2.0 unx      814 b- defN 24-Mar-04 22:24 sparseml/pytorch/framework/__init__.py
--rw-r--r--  2.0 unx     5580 b- defN 24-Mar-04 22:24 sparseml/pytorch/framework/info.py
--rw-r--r--  2.0 unx      753 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/__init__.py
--rw-r--r--  2.0 unx    18265 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/export.py
--rw-r--r--  2.0 unx     4991 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/integration_helper_functions.py
--rw-r--r--  2.0 unx    15494 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/lr_analysis.py
--rw-r--r--  2.0 unx    14444 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/pr_sensitivity.py
--rw-r--r--  2.0 unx    29287 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/train.py
--rw-r--r--  2.0 unx      682 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/utils/__init__.py
--rw-r--r--  2.0 unx     4278 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/utils/cli_helpers.py
--rw-r--r--  2.0 unx     1257 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/utils/constants.py
--rw-r--r--  2.0 unx    23894 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/utils/helpers.py
--rw-r--r--  2.0 unx    12056 b- defN 24-Mar-04 22:24 sparseml/pytorch/image_classification/utils/trainer.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/pytorch/model_load/__init__.py
--rw-r--r--  2.0 unx    10586 b- defN 24-Mar-04 22:24 sparseml/pytorch/model_load/helpers.py
--rw-r--r--  2.0 unx      976 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/__init__.py
--rw-r--r--  2.0 unx    14753 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/registry.py
--rw-r--r--  2.0 unx      901 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/__init__.py
--rw-r--r--  2.0 unx    11658 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/darknet.py
--rw-r--r--  2.0 unx    40293 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/efficientnet.py
--rw-r--r--  2.0 unx    16512 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/inception_v3.py
--rw-r--r--  2.0 unx     4164 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/mnist.py
--rw-r--r--  2.0 unx     9546 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/mobilenet.py
--rw-r--r--  2.0 unx    13014 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/mobilenet_v2.py
--rw-r--r--  2.0 unx    40800 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/resnet.py
--rw-r--r--  2.0 unx    16649 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/classification/vgg.py
--rw-r--r--  2.0 unx      824 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/detection/__init__.py
--rw-r--r--  2.0 unx     6820 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/detection/ssd.py
--rw-r--r--  2.0 unx     8116 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/detection/ssd_lite.py
--rw-r--r--  2.0 unx     4046 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/detection/ssd_mobilenet.py
--rw-r--r--  2.0 unx     9069 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/detection/ssd_resnet.py
--rw-r--r--  2.0 unx    10188 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/detection/yolo_v3.py
--rw-r--r--  2.0 unx      763 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/external/__init__.py
--rw-r--r--  2.0 unx     6759 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/external/torchvision.py
--rw-r--r--  2.0 unx      676 b- defN 24-Mar-04 22:24 sparseml/pytorch/models/recommendation/__init__.py
--rw-r--r--  2.0 unx      925 b- defN 24-Mar-04 22:24 sparseml/pytorch/nn/__init__.py
--rw-r--r--  2.0 unx     8673 b- defN 24-Mar-04 22:24 sparseml/pytorch/nn/activations.py
--rw-r--r--  2.0 unx    11854 b- defN 24-Mar-04 22:24 sparseml/pytorch/nn/fatrelu.py
--rw-r--r--  2.0 unx     1690 b- defN 24-Mar-04 22:24 sparseml/pytorch/nn/identity.py
--rw-r--r--  2.0 unx     2828 b- defN 24-Mar-04 22:24 sparseml/pytorch/nn/se.py
--rw-r--r--  2.0 unx     1243 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/__init__.py
--rw-r--r--  2.0 unx    13638 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/analyzer_as.py
--rw-r--r--  2.0 unx    17069 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/analyzer_module.py
--rw-r--r--  2.0 unx     3955 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/analyzer_pruning.py
--rw-r--r--  2.0 unx    26838 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/manager.py
--rw-r--r--  2.0 unx    36844 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/mask_creator_pruning.py
--rw-r--r--  2.0 unx    23085 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/mask_pruning.py
--rw-r--r--  2.0 unx    10449 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/mask_pruning_scorer.py
--rw-r--r--  2.0 unx     6605 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/optimizer.py
--rw-r--r--  2.0 unx    14879 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/sensitivity_as.py
--rw-r--r--  2.0 unx     6101 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/sensitivity_lr.py
--rw-r--r--  2.0 unx     9324 b- defN 24-Mar-04 22:24 sparseml/pytorch/optim/sensitivity_pruning.py
--rw-r--r--  2.0 unx      633 b- defN 24-Mar-04 22:24 sparseml/pytorch/recipe_template/__init__.py
--rw-r--r--  2.0 unx     4534 b- defN 24-Mar-04 22:24 sparseml/pytorch/recipe_template/cli.py
--rw-r--r--  2.0 unx     1559 b- defN 24-Mar-04 22:24 sparseml/pytorch/recipe_template/description.py
--rw-r--r--  2.0 unx    15943 b- defN 24-Mar-04 22:24 sparseml/pytorch/recipe_template/main.py
--rw-r--r--  2.0 unx      992 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/__init__.py
--rw-r--r--  2.0 unx     1366 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/info.py
--rw-r--r--  2.0 unx    32159 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/modifier.py
--rw-r--r--  2.0 unx    18952 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/modifier_thinning.py
--rw-r--r--  2.0 unx      705 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/distillation/__init__.py
--rw-r--r--  2.0 unx     4741 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/distillation/modifier_distillation.py
--rw-r--r--  2.0 unx    14742 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/distillation/modifier_distillation_base.py
--rw-r--r--  2.0 unx    19177 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/distillation/modifier_per_layer.py
--rw-r--r--  2.0 unx     1276 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/__init__.py
--rw-r--r--  2.0 unx    29250 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/mask_creator.py
--rw-r--r--  2.0 unx    24209 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/mask_params.py
--rw-r--r--  2.0 unx    13389 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_as.py
--rw-r--r--  2.0 unx    12006 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_powerpropagation.py
--rw-r--r--  2.0 unx    10455 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_acdc.py
--rw-r--r--  2.0 unx    33219 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_base.py
--rw-r--r--  2.0 unx     5757 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_constant.py
--rw-r--r--  2.0 unx     8860 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_layer.py
--rw-r--r--  2.0 unx    15595 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_magnitude.py
--rw-r--r--  2.0 unx    63519 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_mfac.py
--rw-r--r--  2.0 unx     8774 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_movement.py
--rw-r--r--  2.0 unx    24121 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_obs.py
--rw-r--r--  2.0 unx    23346 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_rigl.py
--rw-r--r--  2.0 unx    18245 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_structured.py
--rw-r--r--  2.0 unx    17756 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/modifier_pruning_topkast.py
--rw-r--r--  2.0 unx     4644 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/pruning/scorer.py
--rw-r--r--  2.0 unx      813 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/__init__.py
--rw-r--r--  2.0 unx     2220 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/constants.py
--rw-r--r--  2.0 unx    34914 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/helpers.py
--rw-r--r--  2.0 unx    33626 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/legacy_modifier_quantization.py
--rw-r--r--  2.0 unx    26778 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/modifier_quantization.py
--rw-r--r--  2.0 unx    13482 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/quantization_scheme.py
--rw-r--r--  2.0 unx    18047 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/quantize.py
--rw-r--r--  2.0 unx    76796 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/quantization/quantize_qat_export.py
--rw-r--r--  2.0 unx      790 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/training/__init__.py
--rw-r--r--  2.0 unx     1778 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/training/modifier_epoch.py
--rw-r--r--  2.0 unx     2883 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/training/modifier_logging.py
--rw-r--r--  2.0 unx    24287 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/training/modifier_lr.py
--rw-r--r--  2.0 unx    21497 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/training/modifier_params.py
--rw-r--r--  2.0 unx     6690 b- defN 24-Mar-04 22:24 sparseml/pytorch/sparsification/training/modifier_regularizer.py
--rw-r--r--  2.0 unx      943 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/__init__.py
--rw-r--r--  2.0 unx     6490 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/export_onnx.py
--rw-r--r--  2.0 unx     2870 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/presets.py
--rw-r--r--  2.0 unx     2530 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/sampler.py
--rw-r--r--  2.0 unx    42927 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/train.py
--rw-r--r--  2.0 unx     7128 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/transforms.py
--rw-r--r--  2.0 unx    16675 b- defN 24-Mar-04 22:24 sparseml/pytorch/torchvision/utils.py
--rw-r--r--  2.0 unx     1160 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/__init__.py
--rw-r--r--  2.0 unx     9706 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/benchmarker.py
--rw-r--r--  2.0 unx     2846 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/callbacks.py
--rw-r--r--  2.0 unx     1061 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/distributed.py
--rw-r--r--  2.0 unx    30884 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/exporter.py
--rw-r--r--  2.0 unx    42297 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/helpers.py
--rw-r--r--  2.0 unx     1663 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/log_sparsification_info.py
--rw-r--r--  2.0 unx    31374 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/logger.py
--rw-r--r--  2.0 unx    27048 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/loss.py
--rw-r--r--  2.0 unx    11754 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/model.py
--rw-r--r--  2.0 unx    39117 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/module.py
--rw-r--r--  2.0 unx     9139 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/sparsification.py
--rw-r--r--  2.0 unx    30059 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/ssd_helpers.py
--rw-r--r--  2.0 unx    12337 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/yolo_helpers.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/sparsification_info/__init__.py
--rw-r--r--  2.0 unx    15081 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/sparsification_info/configs.py
--rw-r--r--  2.0 unx     4336 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/sparsification_info/helpers.py
--rw-r--r--  2.0 unx     2788 b- defN 24-Mar-04 22:24 sparseml/pytorch/utils/sparsification_info/module_sparsification_info.py
--rw-r--r--  2.0 unx      655 b- defN 24-Mar-04 22:24 sparseml/recipe_template/__init__.py
--rw-r--r--  2.0 unx     4788 b- defN 24-Mar-04 22:24 sparseml/recipe_template/utils.py
--rw-r--r--  2.0 unx     1058 b- defN 24-Mar-04 22:24 sparseml/sparsification/__init__.py
--rw-r--r--  2.0 unx     9387 b- defN 24-Mar-04 22:24 sparseml/sparsification/analyzer.py
--rw-r--r--  2.0 unx     9065 b- defN 24-Mar-04 22:24 sparseml/sparsification/info.py
--rw-r--r--  2.0 unx    15565 b- defN 24-Mar-04 22:24 sparseml/sparsification/model_info.py
--rw-r--r--  2.0 unx     2002 b- defN 24-Mar-04 22:24 sparseml/sparsification/modifier_epoch.py
--rw-r--r--  2.0 unx    10117 b- defN 24-Mar-04 22:24 sparseml/sparsification/modifier_lr.py
--rw-r--r--  2.0 unx     5505 b- defN 24-Mar-04 22:24 sparseml/sparsification/modifier_params.py
--rw-r--r--  2.0 unx    12845 b- defN 24-Mar-04 22:24 sparseml/sparsification/modifier_pruning.py
--rw-r--r--  2.0 unx     3700 b- defN 24-Mar-04 22:24 sparseml/sparsification/oracle.py
--rw-r--r--  2.0 unx    18570 b- defN 24-Mar-04 22:24 sparseml/sparsification/recipe_builder.py
--rw-r--r--  2.0 unx    14413 b- defN 24-Mar-04 22:24 sparseml/sparsification/recipe_editor.py
--rw-r--r--  2.0 unx     1250 b- defN 24-Mar-04 22:24 sparseml/sparsification/types.py
--rw-r--r--  2.0 unx     1169 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/__init__.py
--rw-r--r--  2.0 unx     7272 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/base.py
--rw-r--r--  2.0 unx      925 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/__init__.py
--rw-r--r--  2.0 unx     8121 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/dataset.py
--rw-r--r--  2.0 unx     5600 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/helpers.py
--rw-r--r--  2.0 unx     2768 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/registry.py
--rw-r--r--  2.0 unx      807 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/classification/__init__.py
--rw-r--r--  2.0 unx    12686 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/classification/cifar.py
--rw-r--r--  2.0 unx     8690 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/classification/imagefolder.py
--rw-r--r--  2.0 unx     2032 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/classification/imagenet.py
--rw-r--r--  2.0 unx     4695 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/datasets/classification/imagenette.py
--rw-r--r--  2.0 unx      805 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/framework/__init__.py
--rw-r--r--  2.0 unx     5859 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/framework/info.py
--rw-r--r--  2.0 unx      925 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/__init__.py
--rw-r--r--  2.0 unx    19752 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/estimator.py
--rw-r--r--  2.0 unx    14774 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/registry.py
--rw-r--r--  2.0 unx      822 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/classification/__init__.py
--rw-r--r--  2.0 unx     3540 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/classification/mnist.py
--rw-r--r--  2.0 unx    11161 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/classification/mobilenet.py
--rw-r--r--  2.0 unx    18359 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/classification/mobilenet_v2.py
--rw-r--r--  2.0 unx    28103 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/classification/resnet.py
--rw-r--r--  2.0 unx    26886 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/models/classification/vgg.py
--rw-r--r--  2.0 unx      865 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/nn/__init__.py
--rw-r--r--  2.0 unx    18670 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/nn/layers.py
--rw-r--r--  2.0 unx     1238 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/__init__.py
--rw-r--r--  2.0 unx     8607 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/analyzer_module.py
--rw-r--r--  2.0 unx     9591 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/manager.py
--rw-r--r--  2.0 unx    19683 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/mask_creator_pruning.py
--rw-r--r--  2.0 unx    33919 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/mask_pruning.py
--rw-r--r--  2.0 unx    15955 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/modifier.py
--rw-r--r--  2.0 unx     1715 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/modifier_epoch.py
--rw-r--r--  2.0 unx    10685 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/modifier_lr.py
--rw-r--r--  2.0 unx     7092 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/modifier_params.py
--rw-r--r--  2.0 unx    15702 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/modifier_pruning.py
--rw-r--r--  2.0 unx     5682 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/schedule_lr.py
--rw-r--r--  2.0 unx     9232 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/optim/sensitivity_pruning.py
--rw-r--r--  2.0 unx      801 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/sparsification/__init__.py
--rw-r--r--  2.0 unx     1385 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/sparsification/info.py
--rw-r--r--  2.0 unx      967 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/__init__.py
--rw-r--r--  2.0 unx    10913 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/exporter.py
--rw-r--r--  2.0 unx      996 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/helpers.py
--rw-r--r--  2.0 unx     1974 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/loss.py
--rw-r--r--  2.0 unx     8119 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/nets_utils.py
--rw-r--r--  2.0 unx     1327 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/summary.py
--rw-r--r--  2.0 unx    12536 b- defN 24-Mar-04 22:24 sparseml/tensorflow_v1/utils/variable.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/tools/__init__.py
--rw-r--r--  2.0 unx     2060 b- defN 24-Mar-04 22:24 sparseml/transformers/__init__.py
--rw-r--r--  2.0 unx    23943 b- defN 24-Mar-04 22:24 sparseml/transformers/export.py
--rw-r--r--  2.0 unx     9485 b- defN 24-Mar-04 22:24 sparseml/transformers/integration_helper_functions.py
--rw-r--r--  2.0 unx    30756 b- defN 24-Mar-04 22:24 sparseml/transformers/masked_language_modeling.py
--rw-r--r--  2.0 unx    36976 b- defN 24-Mar-04 22:24 sparseml/transformers/question_answering.py
--rw-r--r--  2.0 unx    40299 b- defN 24-Mar-04 22:24 sparseml/transformers/text_classification.py
--rw-r--r--  2.0 unx      818 b- defN 24-Mar-04 22:24 sparseml/transformers/text_generation.py
--rw-r--r--  2.0 unx    34350 b- defN 24-Mar-04 22:24 sparseml/transformers/token_classification.py
--rw-r--r--  2.0 unx      701 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/__init__.py
--rw-r--r--  2.0 unx     5251 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/callbacks.py
--rw-r--r--  2.0 unx     2346 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/model_args.py
--rw-r--r--  2.0 unx    11539 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/runner.py
--rw-r--r--  2.0 unx    22233 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/session_mixin.py
--rw-r--r--  2.0 unx    13019 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/text_generation.py
--rw-r--r--  2.0 unx     4290 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/trainer.py
--rw-r--r--  2.0 unx     3028 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/training_args.py
--rw-r--r--  2.0 unx      974 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/__init__.py
--rw-r--r--  2.0 unx     8736 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/base.py
--rw-r--r--  2.0 unx     1322 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/c4.py
--rw-r--r--  2.0 unx     3659 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/custom.py
--rw-r--r--  2.0 unx     5194 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/data_args.py
--rw-r--r--  2.0 unx     7914 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/data_helpers.py
--rw-r--r--  2.0 unx     2892 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/evolcodealpaca.py
--rw-r--r--  2.0 unx     2597 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/gsm8k.py
--rw-r--r--  2.0 unx     3435 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/open_platypus.py
--rw-r--r--  2.0 unx     1369 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/ptb.py
--rw-r--r--  2.0 unx     3521 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/ultrachat_200k.py
--rw-r--r--  2.0 unx     1237 b- defN 24-Mar-04 22:24 sparseml/transformers/finetune/data/wikitext.py
--rw-r--r--  2.0 unx      833 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/__init__.py
--rw-r--r--  2.0 unx    19529 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/question_answering.py
--rw-r--r--  2.0 unx    41727 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/trainer.py
--rw-r--r--  2.0 unx     1890 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/training_args.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/obcq/__init__.py
--rw-r--r--  2.0 unx    19722 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/obcq/export.py
--rw-r--r--  2.0 unx     7695 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/obcq/obcq.py
--rw-r--r--  2.0 unx      617 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/obcq/utils/__init__.py
--rw-r--r--  2.0 unx     3671 b- defN 24-Mar-04 22:24 sparseml/transformers/sparsification/obcq/utils/helpers.py
--rw-r--r--  2.0 unx      894 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/__init__.py
--rw-r--r--  2.0 unx    20002 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/helpers.py
--rw-r--r--  2.0 unx     6711 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/initializers.py
--rw-r--r--  2.0 unx     5081 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/load_task_dataset.py
--rw-r--r--  2.0 unx     2755 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/load_task_model.py
--rw-r--r--  2.0 unx     2536 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/metrics.py
--rw-r--r--  2.0 unx     1972 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/optimizations.py
--rw-r--r--  2.0 unx     1874 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/sparse_config.py
--rw-r--r--  2.0 unx    18556 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/sparse_model.py
--rw-r--r--  2.0 unx     2178 b- defN 24-Mar-04 22:24 sparseml/transformers/utils/sparse_tokenizer.py
--rw-r--r--  2.0 unx      844 b- defN 24-Mar-04 22:24 sparseml/utils/__init__.py
--rw-r--r--  2.0 unx      886 b- defN 24-Mar-04 22:24 sparseml/utils/frameworks.py
--rw-r--r--  2.0 unx    30188 b- defN 24-Mar-04 22:24 sparseml/utils/helpers.py
--rw-r--r--  2.0 unx     3983 b- defN 24-Mar-04 22:24 sparseml/utils/restricted_eval.py
--rw-r--r--  2.0 unx     1083 b- defN 24-Mar-04 22:24 sparseml/utils/singleton.py
--rw-r--r--  2.0 unx     6312 b- defN 24-Mar-04 22:24 sparseml/utils/worker.py
--rw-r--r--  2.0 unx     2952 b- defN 24-Mar-04 22:24 sparseml/utils/wrapper.py
--rw-r--r--  2.0 unx      819 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/__init__.py
--rw-r--r--  2.0 unx      833 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/cifar.py
--rw-r--r--  2.0 unx     3750 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/coco.py
--rw-r--r--  2.0 unx     1217 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/helpers.py
--rw-r--r--  2.0 unx    23366 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/imagenet.py
--rw-r--r--  2.0 unx     8967 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/imagenette.py
--rw-r--r--  2.0 unx     1009 b- defN 24-Mar-04 22:24 sparseml/utils/datasets/voc.py
--rw-r--r--  2.0 unx      633 b- defN 24-Mar-04 22:24 sparseml/utils/fsdp/__init__.py
--rw-r--r--  2.0 unx     2096 b- defN 24-Mar-04 22:24 sparseml/utils/fsdp/context.py
--rw-r--r--  2.0 unx     5492 b- defN 24-Mar-04 22:24 sparseml/utils/fsdp/helpers.py
--rw-r--r--  2.0 unx      656 b- defN 24-Mar-04 22:24 sparseml/utils/pytorch/__init__.py
--rw-r--r--  2.0 unx     9787 b- defN 24-Mar-04 22:24 sparseml/utils/pytorch/module.py
--rw-r--r--  2.0 unx      680 b- defN 24-Mar-04 22:24 sparseml/utils/pytorch/pruning/__init__.py
--rw-r--r--  2.0 unx     1875 b- defN 24-Mar-04 22:24 sparseml/yolact/COCO.sh
--rw-r--r--  2.0 unx     1418 b- defN 24-Mar-04 22:24 sparseml/yolact/COCO_test.sh
--rw-r--r--  2.0 unx     4020 b- defN 24-Mar-04 22:24 sparseml/yolact/__init__.py
--rw-r--r--  2.0 unx     1784 b- defN 24-Mar-04 22:24 sparseml/yolact/scripts.py
--rw-r--r--  2.0 unx     1440 b- defN 24-Mar-04 22:24 sparseml/yolov5/__init__.py
--rw-r--r--  2.0 unx     4505 b- defN 24-Mar-04 22:24 sparseml/yolov5/helpers.py
--rw-r--r--  2.0 unx     1609 b- defN 24-Mar-04 22:24 sparseml/yolov5/scripts.py
--rw-r--r--  2.0 unx     1220 b- defN 24-Mar-04 22:24 sparseml/yolov5/yolov5.status.yaml
--rw-r--r--  2.0 unx     1117 b- defN 24-Mar-04 22:24 sparseml/yolov8/__init__.py
--rw-r--r--  2.0 unx     6061 b- defN 24-Mar-04 22:24 sparseml/yolov8/default.yaml
--rw-r--r--  2.0 unx     2815 b- defN 24-Mar-04 22:24 sparseml/yolov8/export.py
--rw-r--r--  2.0 unx     2259 b- defN 24-Mar-04 22:24 sparseml/yolov8/modules.py
--rw-r--r--  2.0 unx     7394 b- defN 24-Mar-04 22:24 sparseml/yolov8/train.py
--rw-r--r--  2.0 unx    37860 b- defN 24-Mar-04 22:24 sparseml/yolov8/trainers.py
--rw-r--r--  2.0 unx     2748 b- defN 24-Mar-04 22:24 sparseml/yolov8/val.py
--rw-r--r--  2.0 unx     8459 b- defN 24-Mar-04 22:24 sparseml/yolov8/validators.py
--rw-r--r--  2.0 unx      685 b- defN 24-Mar-04 22:24 sparseml/yolov8/utils/__init__.py
--rw-r--r--  2.0 unx     6683 b- defN 24-Mar-04 22:24 sparseml/yolov8/utils/export_samples.py
--rw-r--r--  2.0 unx     4041 b- defN 24-Mar-04 22:24 sparseml/yolov8/utils/helpers.py
--rw-r--r--  2.0 unx    11357 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/LICENSE
--rw-r--r--  2.0 unx    13747 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/LICENSE-ULTRALYTICS
--rw-r--r--  2.0 unx    23605 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/METADATA
--rw-r--r--  2.0 unx     2085 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/NOTICE
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/WHEEL
--rw-r--r--  2.0 unx     3122 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        9 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    53371 b- defN 24-Mar-04 22:24 sparseml_nightly-1.7.0.20240304.dist-info/RECORD
-537 files, 4434007 bytes uncompressed, 1186743 bytes compressed:  73.2%
+Zip file size: 1319161 bytes, number of entries: 567
+-rw-r--r--  2.0 unx     1489 b- defN 24-Apr-01 00:45 sparseml/__init__.py
+-rw-r--r--  2.0 unx      898 b- defN 24-Apr-01 00:45 sparseml/analytics.py
+-rw-r--r--  2.0 unx    10284 b- defN 24-Apr-01 00:45 sparseml/base.py
+-rw-r--r--  2.0 unx     7288 b- defN 24-Apr-01 00:45 sparseml/integration_helper_functions.py
+-rw-r--r--  2.0 unx     2483 b- defN 24-Apr-01 00:45 sparseml/log.py
+-rw-r--r--  2.0 unx     1607 b- defN 24-Apr-01 00:45 sparseml/version.py
+-rw-r--r--  2.0 unx      758 b- defN 24-Apr-01 00:45 sparseml/benchmark/__init__.py
+-rw-r--r--  2.0 unx    17763 b- defN 24-Apr-01 00:45 sparseml/benchmark/info.py
+-rw-r--r--  2.0 unx    10778 b- defN 24-Apr-01 00:45 sparseml/benchmark/serialization.py
+-rw-r--r--  2.0 unx      915 b- defN 24-Apr-01 00:45 sparseml/core/__init__.py
+-rw-r--r--  2.0 unx     6842 b- defN 24-Apr-01 00:45 sparseml/core/event.py
+-rw-r--r--  2.0 unx     6492 b- defN 24-Apr-01 00:45 sparseml/core/factory.py
+-rw-r--r--  2.0 unx     2850 b- defN 24-Apr-01 00:45 sparseml/core/framework.py
+-rw-r--r--  2.0 unx     2855 b- defN 24-Apr-01 00:45 sparseml/core/framework_object.py
+-rw-r--r--  2.0 unx     3780 b- defN 24-Apr-01 00:45 sparseml/core/helpers.py
+-rw-r--r--  2.0 unx    23720 b- defN 24-Apr-01 00:45 sparseml/core/session.py
+-rw-r--r--  2.0 unx     9034 b- defN 24-Apr-01 00:45 sparseml/core/state.py
+-rw-r--r--  2.0 unx      667 b- defN 24-Apr-01 00:45 sparseml/core/data/__init__.py
+-rw-r--r--  2.0 unx     1565 b- defN 24-Apr-01 00:45 sparseml/core/data/base.py
+-rw-r--r--  2.0 unx     6415 b- defN 24-Apr-01 00:45 sparseml/core/data/pytorch.py
+-rw-r--r--  2.0 unx      678 b- defN 24-Apr-01 00:45 sparseml/core/lifecycle/__init__.py
+-rw-r--r--  2.0 unx    11954 b- defN 24-Apr-01 00:45 sparseml/core/lifecycle/event.py
+-rw-r--r--  2.0 unx     8242 b- defN 24-Apr-01 00:45 sparseml/core/lifecycle/session.py
+-rw-r--r--  2.0 unx      654 b- defN 24-Apr-01 00:45 sparseml/core/logger/__init__.py
+-rw-r--r--  2.0 unx    44703 b- defN 24-Apr-01 00:45 sparseml/core/logger/logger.py
+-rw-r--r--  2.0 unx      667 b- defN 24-Apr-01 00:45 sparseml/core/logger/utils/__init__.py
+-rw-r--r--  2.0 unx    12725 b- defN 24-Apr-01 00:45 sparseml/core/logger/utils/frequency_manager.py
+-rw-r--r--  2.0 unx      693 b- defN 24-Apr-01 00:45 sparseml/core/model/__init__.py
+-rw-r--r--  2.0 unx     5895 b- defN 24-Apr-01 00:45 sparseml/core/model/base.py
+-rw-r--r--  2.0 unx     5641 b- defN 24-Apr-01 00:45 sparseml/core/model/pytorch.py
+-rw-r--r--  2.0 unx      699 b- defN 24-Apr-01 00:45 sparseml/core/modifier/__init__.py
+-rw-r--r--  2.0 unx     3326 b- defN 24-Apr-01 00:45 sparseml/core/modifier/base.py
+-rw-r--r--  2.0 unx    10810 b- defN 24-Apr-01 00:45 sparseml/core/modifier/modifier.py
+-rw-r--r--  2.0 unx     6093 b- defN 24-Apr-01 00:45 sparseml/core/modifier/stage.py
+-rw-r--r--  2.0 unx      672 b- defN 24-Apr-01 00:45 sparseml/core/optimizer/__init__.py
+-rw-r--r--  2.0 unx     3409 b- defN 24-Apr-01 00:45 sparseml/core/optimizer/base.py
+-rw-r--r--  2.0 unx     4584 b- defN 24-Apr-01 00:45 sparseml/core/optimizer/pytorch.py
+-rw-r--r--  2.0 unx      790 b- defN 24-Apr-01 00:45 sparseml/core/recipe/__init__.py
+-rw-r--r--  2.0 unx     6872 b- defN 24-Apr-01 00:45 sparseml/core/recipe/args.py
+-rw-r--r--  2.0 unx     1599 b- defN 24-Apr-01 00:45 sparseml/core/recipe/base.py
+-rw-r--r--  2.0 unx     6313 b- defN 24-Apr-01 00:45 sparseml/core/recipe/container.py
+-rw-r--r--  2.0 unx     2932 b- defN 24-Apr-01 00:45 sparseml/core/recipe/metadata.py
+-rw-r--r--  2.0 unx     4224 b- defN 24-Apr-01 00:45 sparseml/core/recipe/modifier.py
+-rw-r--r--  2.0 unx    24978 b- defN 24-Apr-01 00:45 sparseml/core/recipe/recipe.py
+-rw-r--r--  2.0 unx     7629 b- defN 24-Apr-01 00:45 sparseml/core/recipe/stage.py
+-rw-r--r--  2.0 unx      663 b- defN 24-Apr-01 00:45 sparseml/core/utils/__init__.py
+-rw-r--r--  2.0 unx     1025 b- defN 24-Apr-01 00:45 sparseml/core/utils/session_helpers.py
+-rw-r--r--  2.0 unx      863 b- defN 24-Apr-01 00:45 sparseml/deepsparse/__init__.py
+-rw-r--r--  2.0 unx     3516 b- defN 24-Apr-01 00:45 sparseml/deepsparse/base.py
+-rw-r--r--  2.0 unx      801 b- defN 24-Apr-01 00:45 sparseml/deepsparse/framework/__init__.py
+-rw-r--r--  2.0 unx     6032 b- defN 24-Apr-01 00:45 sparseml/deepsparse/framework/info.py
+-rw-r--r--  2.0 unx      813 b- defN 24-Apr-01 00:45 sparseml/deepsparse/sparsification/__init__.py
+-rw-r--r--  2.0 unx     1348 b- defN 24-Apr-01 00:45 sparseml/deepsparse/sparsification/info.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/evaluation/__init__.py
+-rw-r--r--  2.0 unx     5689 b- defN 24-Apr-01 00:45 sparseml/evaluation/cli.py
+-rw-r--r--  2.0 unx     2140 b- defN 24-Apr-01 00:45 sparseml/evaluation/evaluator.py
+-rw-r--r--  2.0 unx      940 b- defN 24-Apr-01 00:45 sparseml/evaluation/integrations_config.yaml
+-rw-r--r--  2.0 unx     5571 b- defN 24-Apr-01 00:45 sparseml/evaluation/registry.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/evaluation/integrations/__init__.py
+-rw-r--r--  2.0 unx     6000 b- defN 24-Apr-01 00:45 sparseml/evaluation/integrations/lm_evaluation_harness.py
+-rw-r--r--  2.0 unx    10987 b- defN 24-Apr-01 00:45 sparseml/evaluation/integrations/perplexity.py
+-rw-r--r--  2.0 unx      661 b- defN 24-Apr-01 00:45 sparseml/export/__init__.py
+-rw-r--r--  2.0 unx    21172 b- defN 24-Apr-01 00:45 sparseml/export/export.py
+-rw-r--r--  2.0 unx     8049 b- defN 24-Apr-01 00:45 sparseml/export/export_data.py
+-rw-r--r--  2.0 unx     2681 b- defN 24-Apr-01 00:45 sparseml/export/export_torch_model.py
+-rw-r--r--  2.0 unx    13052 b- defN 24-Apr-01 00:45 sparseml/export/helpers.py
+-rw-r--r--  2.0 unx     8850 b- defN 24-Apr-01 00:45 sparseml/export/validators.py
+-rw-r--r--  2.0 unx      786 b- defN 24-Apr-01 00:45 sparseml/exporters/__init__.py
+-rw-r--r--  2.0 unx     1477 b- defN 24-Apr-01 00:45 sparseml/exporters/base_exporter.py
+-rw-r--r--  2.0 unx     6576 b- defN 24-Apr-01 00:45 sparseml/exporters/kv_cache_injector.py
+-rw-r--r--  2.0 unx     5522 b- defN 24-Apr-01 00:45 sparseml/exporters/onnx_to_deepsparse.py
+-rw-r--r--  2.0 unx     2350 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/__init__.py
+-rw-r--r--  2.0 unx     2333 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/base_transform.py
+-rw-r--r--  2.0 unx     1388 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/constants_to_initializers.py
+-rw-r--r--  2.0 unx     4630 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/conv_to_convinteger_add_cast_mul.py
+-rw-r--r--  2.0 unx     5973 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/conv_to_qlinearconv.py
+-rw-r--r--  2.0 unx     2440 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/delete_repeated_qdq.py
+-rw-r--r--  2.0 unx     1842 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/delete_trivial_onnx_adds.py
+-rw-r--r--  2.0 unx     2241 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/flatten_qparams.py
+-rw-r--r--  2.0 unx     3553 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/fold_conv_div_bn.py
+-rw-r--r--  2.0 unx     1669 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/fold_identity_initializers.py
+-rw-r--r--  2.0 unx     2070 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/fold_relu_quants.py
+-rw-r--r--  2.0 unx     4418 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/gemm_to_matmulinteger_add_cast_mul.py
+-rw-r--r--  2.0 unx     7629 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/gemm_to_qlinearmatmul.py
+-rw-r--r--  2.0 unx     1645 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/initializers_to_uint8.py
+-rw-r--r--  2.0 unx     6297 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/matmul_add_to_matmulinteger_add_cast_mul.py
+-rw-r--r--  2.0 unx     4681 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/matmul_to_matmulinteger_cast_mul.py
+-rw-r--r--  2.0 unx     4156 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/matmul_to_qlinearmatmul.py
+-rw-r--r--  2.0 unx     3770 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/onnx_transform.py
+-rw-r--r--  2.0 unx     3433 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/propagate_dequant_through_split.py
+-rw-r--r--  2.0 unx     4801 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/propagate_embedding_quantization.py
+-rw-r--r--  2.0 unx     4464 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/quantize_qat_embedding.py
+-rw-r--r--  2.0 unx     3869 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/quantize_residuals.py
+-rw-r--r--  2.0 unx     3331 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/remove_duplicate_qconv_weights.py
+-rw-r--r--  2.0 unx     2545 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/remove_duplicate_quantize_ops.py
+-rw-r--r--  2.0 unx     3210 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/skip_input_quantize.py
+-rw-r--r--  2.0 unx     1373 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/unwrap_batchnorms.py
+-rw-r--r--  2.0 unx      911 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/__init__.py
+-rw-r--r--  2.0 unx    30558 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/cache_keys_and_values.py
+-rw-r--r--  2.0 unx    10686 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/configs.py
+-rw-r--r--  2.0 unx     7027 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/transforms_base.py
+-rw-r--r--  2.0 unx     4974 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/transforms_codegen.py
+-rw-r--r--  2.0 unx     8801 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/transforms_llama.py
+-rw-r--r--  2.0 unx     4261 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/transforms_mpt.py
+-rw-r--r--  2.0 unx     6066 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/kv_cache/transforms_opt.py
+-rw-r--r--  2.0 unx      730 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/utils/__init__.py
+-rw-r--r--  2.0 unx    11112 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/utils/add_quantized_conv_matmul_add_ops.py
+-rw-r--r--  2.0 unx     6809 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/utils/helpers.py
+-rw-r--r--  2.0 unx    14429 b- defN 24-Apr-01 00:45 sparseml/exporters/transforms/utils/matching.py
+-rw-r--r--  2.0 unx      790 b- defN 24-Apr-01 00:45 sparseml/framework/__init__.py
+-rw-r--r--  2.0 unx     9479 b- defN 24-Apr-01 00:45 sparseml/framework/info.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/__init__.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/__init__.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/evaluator.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/trainer.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/data/__init__.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/metrics/__init__.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/model/__init__.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/integrations/torchvision/optim/__init__.py
+-rw-r--r--  2.0 unx     1144 b- defN 24-Apr-01 00:45 sparseml/keras/__init__.py
+-rw-r--r--  2.0 unx     8054 b- defN 24-Apr-01 00:45 sparseml/keras/base.py
+-rw-r--r--  2.0 unx      943 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/__init__.py
+-rw-r--r--  2.0 unx     3297 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/dataset.py
+-rw-r--r--  2.0 unx     2423 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/helpers.py
+-rw-r--r--  2.0 unx     2761 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/registry.py
+-rw-r--r--  2.0 unx      786 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/classification/__init__.py
+-rw-r--r--  2.0 unx     8369 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/classification/imagefolder.py
+-rw-r--r--  2.0 unx     4301 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/classification/imagenet.py
+-rw-r--r--  2.0 unx     2727 b- defN 24-Apr-01 00:45 sparseml/keras/datasets/classification/imagenette.py
+-rw-r--r--  2.0 unx      793 b- defN 24-Apr-01 00:45 sparseml/keras/framework/__init__.py
+-rw-r--r--  2.0 unx     5906 b- defN 24-Apr-01 00:45 sparseml/keras/framework/info.py
+-rw-r--r--  2.0 unx      921 b- defN 24-Apr-01 00:45 sparseml/keras/models/__init__.py
+-rw-r--r--  2.0 unx    11814 b- defN 24-Apr-01 00:45 sparseml/keras/models/registry.py
+-rw-r--r--  2.0 unx      656 b- defN 24-Apr-01 00:45 sparseml/keras/models/classification/__init__.py
+-rw-r--r--  2.0 unx    17932 b- defN 24-Apr-01 00:45 sparseml/keras/models/classification/resnet.py
+-rw-r--r--  2.0 unx      768 b- defN 24-Apr-01 00:45 sparseml/keras/models/external/__init__.py
+-rw-r--r--  2.0 unx     4402 b- defN 24-Apr-01 00:45 sparseml/keras/models/external/keras_applications.py
+-rw-r--r--  2.0 unx     1166 b- defN 24-Apr-01 00:45 sparseml/keras/optim/__init__.py
+-rw-r--r--  2.0 unx     5677 b- defN 24-Apr-01 00:45 sparseml/keras/optim/manager.py
+-rw-r--r--  2.0 unx    14777 b- defN 24-Apr-01 00:45 sparseml/keras/optim/mask_pruning.py
+-rw-r--r--  2.0 unx    19740 b- defN 24-Apr-01 00:45 sparseml/keras/optim/mask_pruning_creator.py
+-rw-r--r--  2.0 unx     9183 b- defN 24-Apr-01 00:45 sparseml/keras/optim/modifier.py
+-rw-r--r--  2.0 unx     1676 b- defN 24-Apr-01 00:45 sparseml/keras/optim/modifier_epoch.py
+-rw-r--r--  2.0 unx    14736 b- defN 24-Apr-01 00:45 sparseml/keras/optim/modifier_lr.py
+-rw-r--r--  2.0 unx     5477 b- defN 24-Apr-01 00:45 sparseml/keras/optim/modifier_params.py
+-rw-r--r--  2.0 unx    24031 b- defN 24-Apr-01 00:45 sparseml/keras/optim/modifier_pruning.py
+-rw-r--r--  2.0 unx     1133 b- defN 24-Apr-01 00:45 sparseml/keras/optim/utils.py
+-rw-r--r--  2.0 unx      808 b- defN 24-Apr-01 00:45 sparseml/keras/sparsification/__init__.py
+-rw-r--r--  2.0 unx     1356 b- defN 24-Apr-01 00:45 sparseml/keras/sparsification/info.py
+-rw-r--r--  2.0 unx      962 b- defN 24-Apr-01 00:45 sparseml/keras/utils/__init__.py
+-rw-r--r--  2.0 unx     8202 b- defN 24-Apr-01 00:45 sparseml/keras/utils/callbacks.py
+-rw-r--r--  2.0 unx     1022 b- defN 24-Apr-01 00:45 sparseml/keras/utils/compat.py
+-rw-r--r--  2.0 unx     5737 b- defN 24-Apr-01 00:45 sparseml/keras/utils/exporter.py
+-rw-r--r--  2.0 unx     6087 b- defN 24-Apr-01 00:45 sparseml/keras/utils/logger.py
+-rw-r--r--  2.0 unx     1738 b- defN 24-Apr-01 00:45 sparseml/keras/utils/model.py
+-rw-r--r--  2.0 unx      800 b- defN 24-Apr-01 00:45 sparseml/modifiers/__init__.py
+-rw-r--r--  2.0 unx      656 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/__init__.py
+-rw-r--r--  2.0 unx      654 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/output/__init__.py
+-rw-r--r--  2.0 unx     1343 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/output/base.py
+-rw-r--r--  2.0 unx     7612 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/output/pytorch.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/utils/__init__.py
+-rw-r--r--  2.0 unx      715 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/utils/pytorch/__init__.py
+-rw-r--r--  2.0 unx    13320 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/utils/pytorch/kd_factory.py
+-rw-r--r--  2.0 unx     3921 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/utils/pytorch/kd_wrapper.py
+-rw-r--r--  2.0 unx     4527 b- defN 24-Apr-01 00:45 sparseml/modifiers/distillation/utils/pytorch/model_wrapper.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/experimental/__init__.py
+-rw-r--r--  2.0 unx      654 b- defN 24-Apr-01 00:45 sparseml/modifiers/logarithmic_equalization/__init__.py
+-rw-r--r--  2.0 unx     2764 b- defN 24-Apr-01 00:45 sparseml/modifiers/logarithmic_equalization/base.py
+-rw-r--r--  2.0 unx     1947 b- defN 24-Apr-01 00:45 sparseml/modifiers/logarithmic_equalization/pytorch.py
+-rw-r--r--  2.0 unx      654 b- defN 24-Apr-01 00:45 sparseml/modifiers/obcq/__init__.py
+-rw-r--r--  2.0 unx     5181 b- defN 24-Apr-01 00:45 sparseml/modifiers/obcq/base.py
+-rw-r--r--  2.0 unx     3543 b- defN 24-Apr-01 00:45 sparseml/modifiers/obcq/pytorch.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/obcq/utils/__init__.py
+-rw-r--r--  2.0 unx     6686 b- defN 24-Apr-01 00:45 sparseml/modifiers/obcq/utils/helpers.py
+-rw-r--r--  2.0 unx     6753 b- defN 24-Apr-01 00:45 sparseml/modifiers/obcq/utils/sgpt_wrapper.py
+-rw-r--r--  2.0 unx      683 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/__init__.py
+-rw-r--r--  2.0 unx     5725 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/helpers.py
+-rw-r--r--  2.0 unx      676 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/constant/__init__.py
+-rw-r--r--  2.0 unx      951 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/constant/base.py
+-rw-r--r--  2.0 unx     3103 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/constant/pytorch.py
+-rw-r--r--  2.0 unx      677 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/magnitude/__init__.py
+-rw-r--r--  2.0 unx     1168 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/magnitude/base.py
+-rw-r--r--  2.0 unx     5262 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/magnitude/pytorch.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/utils/__init__.py
+-rw-r--r--  2.0 unx      688 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/utils/pytorch/__init__.py
+-rw-r--r--  2.0 unx     5984 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/utils/pytorch/layer_mask.py
+-rw-r--r--  2.0 unx     5622 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/utils/pytorch/mask_factory.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/wanda/__init__.py
+-rw-r--r--  2.0 unx     3905 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/wanda/base.py
+-rw-r--r--  2.0 unx    10346 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/wanda/pytorch.py
+-rw-r--r--  2.0 unx      633 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/wanda/utils/__init__.py
+-rw-r--r--  2.0 unx     4469 b- defN 24-Apr-01 00:45 sparseml/modifiers/pruning/wanda/utils/wanda_wrapper.py
+-rw-r--r--  2.0 unx      654 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/__init__.py
+-rw-r--r--  2.0 unx     5512 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/base.py
+-rw-r--r--  2.0 unx     8924 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/pytorch.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/utils/__init__.py
+-rw-r--r--  2.0 unx     2220 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/utils/constants.py
+-rw-r--r--  2.0 unx     2906 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/utils/fake_quant_wrapper.py
+-rw-r--r--  2.0 unx    32720 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/utils/helpers.py
+-rw-r--r--  2.0 unx    13545 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/utils/quantization_scheme.py
+-rw-r--r--  2.0 unx    19811 b- defN 24-Apr-01 00:45 sparseml/modifiers/quantization/utils/quantize.py
+-rw-r--r--  2.0 unx      654 b- defN 24-Apr-01 00:45 sparseml/modifiers/smoothquant/__init__.py
+-rw-r--r--  2.0 unx     7535 b- defN 24-Apr-01 00:45 sparseml/modifiers/smoothquant/base.py
+-rw-r--r--  2.0 unx     8167 b- defN 24-Apr-01 00:45 sparseml/modifiers/smoothquant/pytorch.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/modifiers/utils/__init__.py
+-rw-r--r--  2.0 unx     3944 b- defN 24-Apr-01 00:45 sparseml/modifiers/utils/compression_wrapper.py
+-rw-r--r--  2.0 unx     5257 b- defN 24-Apr-01 00:45 sparseml/modifiers/utils/layer_compressor.py
+-rw-r--r--  2.0 unx     3265 b- defN 24-Apr-01 00:45 sparseml/modifiers/utils/pytorch_helpers.py
+-rw-r--r--  2.0 unx     1036 b- defN 24-Apr-01 00:45 sparseml/onnx/__init__.py
+-rw-r--r--  2.0 unx     6202 b- defN 24-Apr-01 00:45 sparseml/onnx/base.py
+-rw-r--r--  2.0 unx      743 b- defN 24-Apr-01 00:45 sparseml/onnx/benchmark/__init__.py
+-rw-r--r--  2.0 unx    15366 b- defN 24-Apr-01 00:45 sparseml/onnx/benchmark/info.py
+-rw-r--r--  2.0 unx      823 b- defN 24-Apr-01 00:45 sparseml/onnx/framework/__init__.py
+-rw-r--r--  2.0 unx     6116 b- defN 24-Apr-01 00:45 sparseml/onnx/framework/info.py
+-rw-r--r--  2.0 unx      820 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/__init__.py
+-rw-r--r--  2.0 unx    13285 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/analyzer_model.py
+-rw-r--r--  2.0 unx    19639 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/sensitivity_pruning.py
+-rw-r--r--  2.0 unx     6470 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/structured_pruning.py
+-rw-r--r--  2.0 unx      815 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/quantization/__init__.py
+-rw-r--r--  2.0 unx    14753 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/quantization/calibration.py
+-rw-r--r--  2.0 unx    73551 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/quantization/quantize.py
+-rw-r--r--  2.0 unx     4552 b- defN 24-Apr-01 00:45 sparseml/onnx/optim/quantization/quantize_model_post_training.py
+-rw-r--r--  2.0 unx      869 b- defN 24-Apr-01 00:45 sparseml/onnx/sparsification/__init__.py
+-rw-r--r--  2.0 unx    10209 b- defN 24-Apr-01 00:45 sparseml/onnx/sparsification/analyzer.py
+-rw-r--r--  2.0 unx     1363 b- defN 24-Apr-01 00:45 sparseml/onnx/sparsification/info.py
+-rw-r--r--  2.0 unx     8009 b- defN 24-Apr-01 00:45 sparseml/onnx/sparsification/model_info.py
+-rw-r--r--  2.0 unx      867 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/__init__.py
+-rw-r--r--  2.0 unx    13013 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/data.py
+-rw-r--r--  2.0 unx    20691 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/graph_editor.py
+-rw-r--r--  2.0 unx     8133 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/graph_optimizer.py
+-rw-r--r--  2.0 unx    40230 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/helpers.py
+-rw-r--r--  2.0 unx     1958 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/loss.py
+-rw-r--r--  2.0 unx    31591 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/model.py
+-rw-r--r--  2.0 unx     5437 b- defN 24-Apr-01 00:45 sparseml/onnx/utils/sparse_tensor.py
+-rw-r--r--  2.0 unx      931 b- defN 24-Apr-01 00:45 sparseml/openpifpaf/__init__.py
+-rw-r--r--  2.0 unx     3713 b- defN 24-Apr-01 00:45 sparseml/openpifpaf/export.py
+-rw-r--r--  2.0 unx    10950 b- defN 24-Apr-01 00:45 sparseml/openpifpaf/train.py
+-rw-r--r--  2.0 unx     4211 b- defN 24-Apr-01 00:45 sparseml/openpifpaf/trainer.py
+-rw-r--r--  2.0 unx      882 b- defN 24-Apr-01 00:45 sparseml/optim/__init__.py
+-rw-r--r--  2.0 unx     6302 b- defN 24-Apr-01 00:45 sparseml/optim/analyzer.py
+-rw-r--r--  2.0 unx    25563 b- defN 24-Apr-01 00:45 sparseml/optim/helpers.py
+-rw-r--r--  2.0 unx    25984 b- defN 24-Apr-01 00:45 sparseml/optim/manager.py
+-rw-r--r--  2.0 unx    30708 b- defN 24-Apr-01 00:45 sparseml/optim/modifier.py
+-rw-r--r--  2.0 unx    26315 b- defN 24-Apr-01 00:45 sparseml/optim/sensitivity.py
+-rw-r--r--  2.0 unx     2190 b- defN 24-Apr-01 00:45 sparseml/pytorch/__init__.py
+-rw-r--r--  2.0 unx     6154 b- defN 24-Apr-01 00:45 sparseml/pytorch/base.py
+-rw-r--r--  2.0 unx      933 b- defN 24-Apr-01 00:45 sparseml/pytorch/opset.py
+-rw-r--r--  2.0 unx    12086 b- defN 24-Apr-01 00:45 sparseml/pytorch/torch_to_onnx_exporter.py
+-rw-r--r--  2.0 unx      998 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/__init__.py
+-rw-r--r--  2.0 unx     4193 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/generic.py
+-rw-r--r--  2.0 unx     3014 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/registry.py
+-rw-r--r--  2.0 unx      828 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/classification/__init__.py
+-rw-r--r--  2.0 unx     4457 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/classification/cifar.py
+-rw-r--r--  2.0 unx     3669 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/classification/imagefolder.py
+-rw-r--r--  2.0 unx     4000 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/classification/imagenet.py
+-rw-r--r--  2.0 unx     6491 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/classification/imagenette.py
+-rw-r--r--  2.0 unx     2434 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/classification/mnist.py
+-rw-r--r--  2.0 unx      767 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/detection/__init__.py
+-rw-r--r--  2.0 unx    16159 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/detection/coco.py
+-rw-r--r--  2.0 unx     5705 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/detection/helpers.py
+-rw-r--r--  2.0 unx    10759 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/detection/voc.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/image_classification/__init__.py
+-rw-r--r--  2.0 unx     9512 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/image_classification/ffcv_dataset.py
+-rw-r--r--  2.0 unx      684 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/recommendation/__init__.py
+-rw-r--r--  2.0 unx      693 b- defN 24-Apr-01 00:45 sparseml/pytorch/datasets/video/__init__.py
+-rw-r--r--  2.0 unx      814 b- defN 24-Apr-01 00:45 sparseml/pytorch/framework/__init__.py
+-rw-r--r--  2.0 unx     5580 b- defN 24-Apr-01 00:45 sparseml/pytorch/framework/info.py
+-rw-r--r--  2.0 unx      753 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/__init__.py
+-rw-r--r--  2.0 unx    18265 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/export.py
+-rw-r--r--  2.0 unx     4991 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/integration_helper_functions.py
+-rw-r--r--  2.0 unx    15494 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/lr_analysis.py
+-rw-r--r--  2.0 unx    14444 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/pr_sensitivity.py
+-rw-r--r--  2.0 unx    29287 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/train.py
+-rw-r--r--  2.0 unx      682 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/utils/__init__.py
+-rw-r--r--  2.0 unx     4278 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/utils/cli_helpers.py
+-rw-r--r--  2.0 unx     1257 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/utils/constants.py
+-rw-r--r--  2.0 unx    23894 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/utils/helpers.py
+-rw-r--r--  2.0 unx    12056 b- defN 24-Apr-01 00:45 sparseml/pytorch/image_classification/utils/trainer.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/pytorch/model_load/__init__.py
+-rw-r--r--  2.0 unx    11440 b- defN 24-Apr-01 00:45 sparseml/pytorch/model_load/helpers.py
+-rw-r--r--  2.0 unx      976 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/__init__.py
+-rw-r--r--  2.0 unx    14753 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/registry.py
+-rw-r--r--  2.0 unx      901 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/__init__.py
+-rw-r--r--  2.0 unx    11658 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/darknet.py
+-rw-r--r--  2.0 unx    40293 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/efficientnet.py
+-rw-r--r--  2.0 unx    16512 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/inception_v3.py
+-rw-r--r--  2.0 unx     4164 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/mnist.py
+-rw-r--r--  2.0 unx     9546 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/mobilenet.py
+-rw-r--r--  2.0 unx    13014 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/mobilenet_v2.py
+-rw-r--r--  2.0 unx    40800 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/resnet.py
+-rw-r--r--  2.0 unx    16649 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/classification/vgg.py
+-rw-r--r--  2.0 unx      824 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/detection/__init__.py
+-rw-r--r--  2.0 unx     6820 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/detection/ssd.py
+-rw-r--r--  2.0 unx     8116 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/detection/ssd_lite.py
+-rw-r--r--  2.0 unx     4046 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/detection/ssd_mobilenet.py
+-rw-r--r--  2.0 unx     9069 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/detection/ssd_resnet.py
+-rw-r--r--  2.0 unx    10188 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/detection/yolo_v3.py
+-rw-r--r--  2.0 unx      763 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/external/__init__.py
+-rw-r--r--  2.0 unx     6759 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/external/torchvision.py
+-rw-r--r--  2.0 unx      676 b- defN 24-Apr-01 00:45 sparseml/pytorch/models/recommendation/__init__.py
+-rw-r--r--  2.0 unx      925 b- defN 24-Apr-01 00:45 sparseml/pytorch/nn/__init__.py
+-rw-r--r--  2.0 unx     8673 b- defN 24-Apr-01 00:45 sparseml/pytorch/nn/activations.py
+-rw-r--r--  2.0 unx    11854 b- defN 24-Apr-01 00:45 sparseml/pytorch/nn/fatrelu.py
+-rw-r--r--  2.0 unx     1690 b- defN 24-Apr-01 00:45 sparseml/pytorch/nn/identity.py
+-rw-r--r--  2.0 unx     2828 b- defN 24-Apr-01 00:45 sparseml/pytorch/nn/se.py
+-rw-r--r--  2.0 unx     1243 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/__init__.py
+-rw-r--r--  2.0 unx    13638 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/analyzer_as.py
+-rw-r--r--  2.0 unx    15582 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/analyzer_module.py
+-rw-r--r--  2.0 unx     3955 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/analyzer_pruning.py
+-rw-r--r--  2.0 unx    26838 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/manager.py
+-rw-r--r--  2.0 unx    36844 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/mask_creator_pruning.py
+-rw-r--r--  2.0 unx    23085 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/mask_pruning.py
+-rw-r--r--  2.0 unx    10449 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/mask_pruning_scorer.py
+-rw-r--r--  2.0 unx     6605 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/optimizer.py
+-rw-r--r--  2.0 unx    14879 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/sensitivity_as.py
+-rw-r--r--  2.0 unx     6101 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/sensitivity_lr.py
+-rw-r--r--  2.0 unx     9324 b- defN 24-Apr-01 00:45 sparseml/pytorch/optim/sensitivity_pruning.py
+-rw-r--r--  2.0 unx      633 b- defN 24-Apr-01 00:45 sparseml/pytorch/recipe_template/__init__.py
+-rw-r--r--  2.0 unx     4534 b- defN 24-Apr-01 00:45 sparseml/pytorch/recipe_template/cli.py
+-rw-r--r--  2.0 unx     1559 b- defN 24-Apr-01 00:45 sparseml/pytorch/recipe_template/description.py
+-rw-r--r--  2.0 unx    15943 b- defN 24-Apr-01 00:45 sparseml/pytorch/recipe_template/main.py
+-rw-r--r--  2.0 unx      992 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/__init__.py
+-rw-r--r--  2.0 unx     1366 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/info.py
+-rw-r--r--  2.0 unx    32159 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/modifier.py
+-rw-r--r--  2.0 unx    18952 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/modifier_thinning.py
+-rw-r--r--  2.0 unx      705 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/distillation/__init__.py
+-rw-r--r--  2.0 unx     4741 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/distillation/modifier_distillation.py
+-rw-r--r--  2.0 unx    14742 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/distillation/modifier_distillation_base.py
+-rw-r--r--  2.0 unx    19177 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/distillation/modifier_per_layer.py
+-rw-r--r--  2.0 unx     1276 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/__init__.py
+-rw-r--r--  2.0 unx    29250 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/mask_creator.py
+-rw-r--r--  2.0 unx    24209 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/mask_params.py
+-rw-r--r--  2.0 unx    13389 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_as.py
+-rw-r--r--  2.0 unx    12006 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_powerpropagation.py
+-rw-r--r--  2.0 unx    10455 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_acdc.py
+-rw-r--r--  2.0 unx    33219 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_base.py
+-rw-r--r--  2.0 unx     5757 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_constant.py
+-rw-r--r--  2.0 unx     8857 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_layer.py
+-rw-r--r--  2.0 unx    15595 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_magnitude.py
+-rw-r--r--  2.0 unx    63519 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_mfac.py
+-rw-r--r--  2.0 unx     8774 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_movement.py
+-rw-r--r--  2.0 unx    24121 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_obs.py
+-rw-r--r--  2.0 unx    23735 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_rigl.py
+-rw-r--r--  2.0 unx    18245 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_structured.py
+-rw-r--r--  2.0 unx    17683 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/modifier_pruning_topkast.py
+-rw-r--r--  2.0 unx     4644 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/pruning/scorer.py
+-rw-r--r--  2.0 unx      813 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/__init__.py
+-rw-r--r--  2.0 unx     2220 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/constants.py
+-rw-r--r--  2.0 unx    34914 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/helpers.py
+-rw-r--r--  2.0 unx    33626 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/legacy_modifier_quantization.py
+-rw-r--r--  2.0 unx    26778 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/modifier_quantization.py
+-rw-r--r--  2.0 unx    13482 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/quantization_scheme.py
+-rw-r--r--  2.0 unx    18047 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/quantize.py
+-rw-r--r--  2.0 unx    76796 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/quantization/quantize_qat_export.py
+-rw-r--r--  2.0 unx      790 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/training/__init__.py
+-rw-r--r--  2.0 unx     1778 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/training/modifier_epoch.py
+-rw-r--r--  2.0 unx     2883 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/training/modifier_logging.py
+-rw-r--r--  2.0 unx    24287 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/training/modifier_lr.py
+-rw-r--r--  2.0 unx    21497 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/training/modifier_params.py
+-rw-r--r--  2.0 unx     6690 b- defN 24-Apr-01 00:45 sparseml/pytorch/sparsification/training/modifier_regularizer.py
+-rw-r--r--  2.0 unx      943 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/__init__.py
+-rw-r--r--  2.0 unx     6490 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/export_onnx.py
+-rw-r--r--  2.0 unx     2870 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/presets.py
+-rw-r--r--  2.0 unx     2530 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/sampler.py
+-rw-r--r--  2.0 unx    43917 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/train.py
+-rw-r--r--  2.0 unx     7128 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/transforms.py
+-rw-r--r--  2.0 unx    16675 b- defN 24-Apr-01 00:45 sparseml/pytorch/torchvision/utils.py
+-rw-r--r--  2.0 unx     1160 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/__init__.py
+-rw-r--r--  2.0 unx     9706 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/benchmarker.py
+-rw-r--r--  2.0 unx     2846 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/callbacks.py
+-rw-r--r--  2.0 unx     1061 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/distributed.py
+-rw-r--r--  2.0 unx    30884 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/exporter.py
+-rw-r--r--  2.0 unx    42811 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/helpers.py
+-rw-r--r--  2.0 unx     1663 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/log_sparsification_info.py
+-rw-r--r--  2.0 unx    31374 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/logger.py
+-rw-r--r--  2.0 unx    27048 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/loss.py
+-rw-r--r--  2.0 unx    11754 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/model.py
+-rw-r--r--  2.0 unx    39117 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/module.py
+-rw-r--r--  2.0 unx     9180 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/sparsification.py
+-rw-r--r--  2.0 unx    30059 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/ssd_helpers.py
+-rw-r--r--  2.0 unx    12337 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/yolo_helpers.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/sparsification_info/__init__.py
+-rw-r--r--  2.0 unx    15081 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/sparsification_info/configs.py
+-rw-r--r--  2.0 unx     4336 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/sparsification_info/helpers.py
+-rw-r--r--  2.0 unx     2788 b- defN 24-Apr-01 00:45 sparseml/pytorch/utils/sparsification_info/module_sparsification_info.py
+-rw-r--r--  2.0 unx      655 b- defN 24-Apr-01 00:45 sparseml/recipe_template/__init__.py
+-rw-r--r--  2.0 unx     4788 b- defN 24-Apr-01 00:45 sparseml/recipe_template/utils.py
+-rw-r--r--  2.0 unx     1058 b- defN 24-Apr-01 00:45 sparseml/sparsification/__init__.py
+-rw-r--r--  2.0 unx     9387 b- defN 24-Apr-01 00:45 sparseml/sparsification/analyzer.py
+-rw-r--r--  2.0 unx     9065 b- defN 24-Apr-01 00:45 sparseml/sparsification/info.py
+-rw-r--r--  2.0 unx    15565 b- defN 24-Apr-01 00:45 sparseml/sparsification/model_info.py
+-rw-r--r--  2.0 unx     2002 b- defN 24-Apr-01 00:45 sparseml/sparsification/modifier_epoch.py
+-rw-r--r--  2.0 unx    10117 b- defN 24-Apr-01 00:45 sparseml/sparsification/modifier_lr.py
+-rw-r--r--  2.0 unx     5505 b- defN 24-Apr-01 00:45 sparseml/sparsification/modifier_params.py
+-rw-r--r--  2.0 unx    12845 b- defN 24-Apr-01 00:45 sparseml/sparsification/modifier_pruning.py
+-rw-r--r--  2.0 unx     3700 b- defN 24-Apr-01 00:45 sparseml/sparsification/oracle.py
+-rw-r--r--  2.0 unx    18570 b- defN 24-Apr-01 00:45 sparseml/sparsification/recipe_builder.py
+-rw-r--r--  2.0 unx    14413 b- defN 24-Apr-01 00:45 sparseml/sparsification/recipe_editor.py
+-rw-r--r--  2.0 unx     1250 b- defN 24-Apr-01 00:45 sparseml/sparsification/types.py
+-rw-r--r--  2.0 unx     1169 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/__init__.py
+-rw-r--r--  2.0 unx     7272 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/base.py
+-rw-r--r--  2.0 unx      925 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/__init__.py
+-rw-r--r--  2.0 unx     8121 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/dataset.py
+-rw-r--r--  2.0 unx     5600 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/helpers.py
+-rw-r--r--  2.0 unx     2768 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/registry.py
+-rw-r--r--  2.0 unx      807 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/classification/__init__.py
+-rw-r--r--  2.0 unx    12686 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/classification/cifar.py
+-rw-r--r--  2.0 unx     8690 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/classification/imagefolder.py
+-rw-r--r--  2.0 unx     2032 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/classification/imagenet.py
+-rw-r--r--  2.0 unx     4695 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/datasets/classification/imagenette.py
+-rw-r--r--  2.0 unx      805 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/framework/__init__.py
+-rw-r--r--  2.0 unx     5859 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/framework/info.py
+-rw-r--r--  2.0 unx      925 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/__init__.py
+-rw-r--r--  2.0 unx    19752 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/estimator.py
+-rw-r--r--  2.0 unx    14774 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/registry.py
+-rw-r--r--  2.0 unx      822 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/classification/__init__.py
+-rw-r--r--  2.0 unx     3540 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/classification/mnist.py
+-rw-r--r--  2.0 unx    11161 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/classification/mobilenet.py
+-rw-r--r--  2.0 unx    18359 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/classification/mobilenet_v2.py
+-rw-r--r--  2.0 unx    28103 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/classification/resnet.py
+-rw-r--r--  2.0 unx    26886 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/models/classification/vgg.py
+-rw-r--r--  2.0 unx      865 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/nn/__init__.py
+-rw-r--r--  2.0 unx    18670 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/nn/layers.py
+-rw-r--r--  2.0 unx     1238 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/__init__.py
+-rw-r--r--  2.0 unx     8607 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/analyzer_module.py
+-rw-r--r--  2.0 unx     9591 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/manager.py
+-rw-r--r--  2.0 unx    19683 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/mask_creator_pruning.py
+-rw-r--r--  2.0 unx    33919 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/mask_pruning.py
+-rw-r--r--  2.0 unx    15955 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/modifier.py
+-rw-r--r--  2.0 unx     1715 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/modifier_epoch.py
+-rw-r--r--  2.0 unx    10685 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/modifier_lr.py
+-rw-r--r--  2.0 unx     7092 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/modifier_params.py
+-rw-r--r--  2.0 unx    15702 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/modifier_pruning.py
+-rw-r--r--  2.0 unx     5682 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/schedule_lr.py
+-rw-r--r--  2.0 unx     9232 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/optim/sensitivity_pruning.py
+-rw-r--r--  2.0 unx      801 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/sparsification/__init__.py
+-rw-r--r--  2.0 unx     1385 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/sparsification/info.py
+-rw-r--r--  2.0 unx      967 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/__init__.py
+-rw-r--r--  2.0 unx    10913 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/exporter.py
+-rw-r--r--  2.0 unx      996 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/helpers.py
+-rw-r--r--  2.0 unx     1974 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/loss.py
+-rw-r--r--  2.0 unx     8119 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/nets_utils.py
+-rw-r--r--  2.0 unx     1327 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/summary.py
+-rw-r--r--  2.0 unx    12536 b- defN 24-Apr-01 00:45 sparseml/tensorflow_v1/utils/variable.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/tools/__init__.py
+-rw-r--r--  2.0 unx     1193 b- defN 24-Apr-01 00:45 sparseml/transformers/__init__.py
+-rw-r--r--  2.0 unx      985 b- defN 24-Apr-01 00:45 sparseml/transformers/base.py
+-rw-r--r--  2.0 unx    23904 b- defN 24-Apr-01 00:45 sparseml/transformers/export.py
+-rw-r--r--  2.0 unx     9485 b- defN 24-Apr-01 00:45 sparseml/transformers/integration_helper_functions.py
+-rw-r--r--  2.0 unx    30795 b- defN 24-Apr-01 00:45 sparseml/transformers/masked_language_modeling.py
+-rw-r--r--  2.0 unx    37002 b- defN 24-Apr-01 00:45 sparseml/transformers/question_answering.py
+-rw-r--r--  2.0 unx    40360 b- defN 24-Apr-01 00:45 sparseml/transformers/text_classification.py
+-rw-r--r--  2.0 unx      818 b- defN 24-Apr-01 00:45 sparseml/transformers/text_generation.py
+-rw-r--r--  2.0 unx    34389 b- defN 24-Apr-01 00:45 sparseml/transformers/token_classification.py
+-rw-r--r--  2.0 unx      683 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/__init__.py
+-rw-r--r--  2.0 unx      749 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/compressors/__init__.py
+-rw-r--r--  2.0 unx     3136 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/compressors/base.py
+-rw-r--r--  2.0 unx     1160 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/compressors/dense.py
+-rw-r--r--  2.0 unx     8377 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/compressors/sparse_bitmask.py
+-rw-r--r--  2.0 unx      751 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/config/__init__.py
+-rw-r--r--  2.0 unx     3846 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/config/base.py
+-rw-r--r--  2.0 unx     1263 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/config/dense.py
+-rw-r--r--  2.0 unx     1236 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/config/sparse_bitmask.py
+-rw-r--r--  2.0 unx      718 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/utils/__init__.py
+-rw-r--r--  2.0 unx     6092 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/utils/compress_save.py
+-rw-r--r--  2.0 unx     1778 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/utils/helpers.py
+-rw-r--r--  2.0 unx     5276 b- defN 24-Apr-01 00:45 sparseml/transformers/compression/utils/safetensors_load.py
+-rw-r--r--  2.0 unx      701 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/__init__.py
+-rw-r--r--  2.0 unx     5251 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/callbacks.py
+-rw-r--r--  2.0 unx     2519 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/model_args.py
+-rw-r--r--  2.0 unx    11988 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/runner.py
+-rw-r--r--  2.0 unx    22944 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/session_mixin.py
+-rw-r--r--  2.0 unx    13101 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/text_generation.py
+-rw-r--r--  2.0 unx     4290 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/trainer.py
+-rw-r--r--  2.0 unx     3005 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/training_args.py
+-rw-r--r--  2.0 unx     1021 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/__init__.py
+-rw-r--r--  2.0 unx     8736 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/base.py
+-rw-r--r--  2.0 unx     1322 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/c4.py
+-rw-r--r--  2.0 unx     2537 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/cnn_dailymail.py
+-rw-r--r--  2.0 unx     4281 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/custom.py
+-rw-r--r--  2.0 unx     5399 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/data_args.py
+-rw-r--r--  2.0 unx     8961 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/data_helpers.py
+-rw-r--r--  2.0 unx     2892 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/evolcodealpaca.py
+-rw-r--r--  2.0 unx     2597 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/gsm8k.py
+-rw-r--r--  2.0 unx     3435 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/open_platypus.py
+-rw-r--r--  2.0 unx     1369 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/ptb.py
+-rw-r--r--  2.0 unx     3521 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/ultrachat_200k.py
+-rw-r--r--  2.0 unx     1237 b- defN 24-Apr-01 00:45 sparseml/transformers/finetune/data/wikitext.py
+-rw-r--r--  2.0 unx      922 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/__init__.py
+-rw-r--r--  2.0 unx    19529 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/question_answering.py
+-rw-r--r--  2.0 unx     1874 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/sparse_config.py
+-rw-r--r--  2.0 unx    20054 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/sparse_model.py
+-rw-r--r--  2.0 unx     2327 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/sparse_tokenizer.py
+-rw-r--r--  2.0 unx    41727 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/trainer.py
+-rw-r--r--  2.0 unx     1890 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/training_args.py
+-rw-r--r--  2.0 unx      866 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/__init__.py
+-rw-r--r--  2.0 unx     2429 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/base.py
+-rw-r--r--  2.0 unx     3922 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modification_objects.py
+-rw-r--r--  2.0 unx     2434 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modify_model.py
+-rw-r--r--  2.0 unx     9199 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modifying_bert.py
+-rw-r--r--  2.0 unx     5492 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modifying_distilbert.py
+-rw-r--r--  2.0 unx     8703 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modifying_llama.py
+-rw-r--r--  2.0 unx     6945 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modifying_mistral.py
+-rw-r--r--  2.0 unx     2549 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modifying_mobilebert.py
+-rw-r--r--  2.0 unx     9618 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/modifying_opt.py
+-rw-r--r--  2.0 unx     1486 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/modification/registry.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/obcq/__init__.py
+-rw-r--r--  2.0 unx    19683 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/obcq/export.py
+-rw-r--r--  2.0 unx     7695 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/obcq/obcq.py
+-rw-r--r--  2.0 unx      617 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/obcq/utils/__init__.py
+-rw-r--r--  2.0 unx     3671 b- defN 24-Apr-01 00:45 sparseml/transformers/sparsification/obcq/utils/helpers.py
+-rw-r--r--  2.0 unx      805 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/__init__.py
+-rw-r--r--  2.0 unx    20055 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/helpers.py
+-rw-r--r--  2.0 unx     6711 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/initializers.py
+-rw-r--r--  2.0 unx     5081 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/load_task_dataset.py
+-rw-r--r--  2.0 unx     2764 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/load_task_model.py
+-rw-r--r--  2.0 unx     2536 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/metrics.py
+-rw-r--r--  2.0 unx     1972 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/optimizations.py
+-rw-r--r--  2.0 unx     1037 b- defN 24-Apr-01 00:45 sparseml/transformers/utils/preprocessing_functions.py
+-rw-r--r--  2.0 unx      844 b- defN 24-Apr-01 00:45 sparseml/utils/__init__.py
+-rw-r--r--  2.0 unx      886 b- defN 24-Apr-01 00:45 sparseml/utils/frameworks.py
+-rw-r--r--  2.0 unx    31604 b- defN 24-Apr-01 00:45 sparseml/utils/helpers.py
+-rw-r--r--  2.0 unx     3983 b- defN 24-Apr-01 00:45 sparseml/utils/restricted_eval.py
+-rw-r--r--  2.0 unx     1083 b- defN 24-Apr-01 00:45 sparseml/utils/singleton.py
+-rw-r--r--  2.0 unx     6312 b- defN 24-Apr-01 00:45 sparseml/utils/worker.py
+-rw-r--r--  2.0 unx     2952 b- defN 24-Apr-01 00:45 sparseml/utils/wrapper.py
+-rw-r--r--  2.0 unx      819 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/__init__.py
+-rw-r--r--  2.0 unx      833 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/cifar.py
+-rw-r--r--  2.0 unx     3750 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/coco.py
+-rw-r--r--  2.0 unx     1217 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/helpers.py
+-rw-r--r--  2.0 unx    23366 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/imagenet.py
+-rw-r--r--  2.0 unx     8967 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/imagenette.py
+-rw-r--r--  2.0 unx     1009 b- defN 24-Apr-01 00:45 sparseml/utils/datasets/voc.py
+-rw-r--r--  2.0 unx      633 b- defN 24-Apr-01 00:45 sparseml/utils/fsdp/__init__.py
+-rw-r--r--  2.0 unx     2096 b- defN 24-Apr-01 00:45 sparseml/utils/fsdp/context.py
+-rw-r--r--  2.0 unx     6631 b- defN 24-Apr-01 00:45 sparseml/utils/fsdp/helpers.py
+-rw-r--r--  2.0 unx      656 b- defN 24-Apr-01 00:45 sparseml/utils/pytorch/__init__.py
+-rw-r--r--  2.0 unx    10897 b- defN 24-Apr-01 00:45 sparseml/utils/pytorch/module.py
+-rw-r--r--  2.0 unx     1696 b- defN 24-Apr-01 00:45 sparseml/utils/pytorch/utils.py
+-rw-r--r--  2.0 unx      680 b- defN 24-Apr-01 00:45 sparseml/utils/pytorch/pruning/__init__.py
+-rw-r--r--  2.0 unx     1875 b- defN 24-Apr-01 00:45 sparseml/yolact/COCO.sh
+-rw-r--r--  2.0 unx     1418 b- defN 24-Apr-01 00:45 sparseml/yolact/COCO_test.sh
+-rw-r--r--  2.0 unx     4020 b- defN 24-Apr-01 00:45 sparseml/yolact/__init__.py
+-rw-r--r--  2.0 unx     1784 b- defN 24-Apr-01 00:45 sparseml/yolact/scripts.py
+-rw-r--r--  2.0 unx     1440 b- defN 24-Apr-01 00:45 sparseml/yolov5/__init__.py
+-rw-r--r--  2.0 unx     4505 b- defN 24-Apr-01 00:45 sparseml/yolov5/helpers.py
+-rw-r--r--  2.0 unx     1609 b- defN 24-Apr-01 00:45 sparseml/yolov5/scripts.py
+-rw-r--r--  2.0 unx     1220 b- defN 24-Apr-01 00:45 sparseml/yolov5/yolov5.status.yaml
+-rw-r--r--  2.0 unx     1117 b- defN 24-Apr-01 00:45 sparseml/yolov8/__init__.py
+-rw-r--r--  2.0 unx     6061 b- defN 24-Apr-01 00:45 sparseml/yolov8/default.yaml
+-rw-r--r--  2.0 unx     2815 b- defN 24-Apr-01 00:45 sparseml/yolov8/export.py
+-rw-r--r--  2.0 unx     2259 b- defN 24-Apr-01 00:45 sparseml/yolov8/modules.py
+-rw-r--r--  2.0 unx     7394 b- defN 24-Apr-01 00:45 sparseml/yolov8/train.py
+-rw-r--r--  2.0 unx    37860 b- defN 24-Apr-01 00:45 sparseml/yolov8/trainers.py
+-rw-r--r--  2.0 unx     2748 b- defN 24-Apr-01 00:45 sparseml/yolov8/val.py
+-rw-r--r--  2.0 unx     8459 b- defN 24-Apr-01 00:45 sparseml/yolov8/validators.py
+-rw-r--r--  2.0 unx      685 b- defN 24-Apr-01 00:45 sparseml/yolov8/utils/__init__.py
+-rw-r--r--  2.0 unx     6683 b- defN 24-Apr-01 00:45 sparseml/yolov8/utils/export_samples.py
+-rw-r--r--  2.0 unx     4041 b- defN 24-Apr-01 00:45 sparseml/yolov8/utils/helpers.py
+-rw-r--r--  2.0 unx    11357 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/LICENSE
+-rw-r--r--  2.0 unx    13747 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/LICENSE-ULTRALYTICS
+-rw-r--r--  2.0 unx    23637 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/METADATA
+-rw-r--r--  2.0 unx     2085 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/NOTICE
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/WHEEL
+-rw-r--r--  2.0 unx     3122 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        9 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    56768 b- defN 24-Apr-01 00:46 sparseml_nightly-1.8.0.20240401.dist-info/RECORD
+567 files, 4551480 bytes uncompressed, 1227073 bytes compressed:  73.0%
```

## zipnote {}

```diff
@@ -129,14 +129,20 @@
 
 Filename: sparseml/core/recipe/recipe.py
 Comment: 
 
 Filename: sparseml/core/recipe/stage.py
 Comment: 
 
+Filename: sparseml/core/utils/__init__.py
+Comment: 
+
+Filename: sparseml/core/utils/session_helpers.py
+Comment: 
+
 Filename: sparseml/deepsparse/__init__.py
 Comment: 
 
 Filename: sparseml/deepsparse/base.py
 Comment: 
 
 Filename: sparseml/deepsparse/framework/__init__.py
@@ -1326,14 +1332,17 @@
 
 Filename: sparseml/tools/__init__.py
 Comment: 
 
 Filename: sparseml/transformers/__init__.py
 Comment: 
 
+Filename: sparseml/transformers/base.py
+Comment: 
+
 Filename: sparseml/transformers/export.py
 Comment: 
 
 Filename: sparseml/transformers/integration_helper_functions.py
 Comment: 
 
 Filename: sparseml/transformers/masked_language_modeling.py
@@ -1347,14 +1356,53 @@
 
 Filename: sparseml/transformers/text_generation.py
 Comment: 
 
 Filename: sparseml/transformers/token_classification.py
 Comment: 
 
+Filename: sparseml/transformers/compression/__init__.py
+Comment: 
+
+Filename: sparseml/transformers/compression/compressors/__init__.py
+Comment: 
+
+Filename: sparseml/transformers/compression/compressors/base.py
+Comment: 
+
+Filename: sparseml/transformers/compression/compressors/dense.py
+Comment: 
+
+Filename: sparseml/transformers/compression/compressors/sparse_bitmask.py
+Comment: 
+
+Filename: sparseml/transformers/compression/config/__init__.py
+Comment: 
+
+Filename: sparseml/transformers/compression/config/base.py
+Comment: 
+
+Filename: sparseml/transformers/compression/config/dense.py
+Comment: 
+
+Filename: sparseml/transformers/compression/config/sparse_bitmask.py
+Comment: 
+
+Filename: sparseml/transformers/compression/utils/__init__.py
+Comment: 
+
+Filename: sparseml/transformers/compression/utils/compress_save.py
+Comment: 
+
+Filename: sparseml/transformers/compression/utils/helpers.py
+Comment: 
+
+Filename: sparseml/transformers/compression/utils/safetensors_load.py
+Comment: 
+
 Filename: sparseml/transformers/finetune/__init__.py
 Comment: 
 
 Filename: sparseml/transformers/finetune/callbacks.py
 Comment: 
 
 Filename: sparseml/transformers/finetune/model_args.py
@@ -1380,14 +1428,17 @@
 
 Filename: sparseml/transformers/finetune/data/base.py
 Comment: 
 
 Filename: sparseml/transformers/finetune/data/c4.py
 Comment: 
 
+Filename: sparseml/transformers/finetune/data/cnn_dailymail.py
+Comment: 
+
 Filename: sparseml/transformers/finetune/data/custom.py
 Comment: 
 
 Filename: sparseml/transformers/finetune/data/data_args.py
 Comment: 
 
 Filename: sparseml/transformers/finetune/data/data_helpers.py
@@ -1413,20 +1464,62 @@
 
 Filename: sparseml/transformers/sparsification/__init__.py
 Comment: 
 
 Filename: sparseml/transformers/sparsification/question_answering.py
 Comment: 
 
+Filename: sparseml/transformers/sparsification/sparse_config.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/sparse_model.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/sparse_tokenizer.py
+Comment: 
+
 Filename: sparseml/transformers/sparsification/trainer.py
 Comment: 
 
 Filename: sparseml/transformers/sparsification/training_args.py
 Comment: 
 
+Filename: sparseml/transformers/sparsification/modification/__init__.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/base.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modification_objects.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modify_model.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modifying_bert.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modifying_distilbert.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modifying_llama.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modifying_mistral.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modifying_mobilebert.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/modifying_opt.py
+Comment: 
+
+Filename: sparseml/transformers/sparsification/modification/registry.py
+Comment: 
+
 Filename: sparseml/transformers/sparsification/obcq/__init__.py
 Comment: 
 
 Filename: sparseml/transformers/sparsification/obcq/export.py
 Comment: 
 
 Filename: sparseml/transformers/sparsification/obcq/obcq.py
@@ -1455,21 +1548,15 @@
 
 Filename: sparseml/transformers/utils/metrics.py
 Comment: 
 
 Filename: sparseml/transformers/utils/optimizations.py
 Comment: 
 
-Filename: sparseml/transformers/utils/sparse_config.py
-Comment: 
-
-Filename: sparseml/transformers/utils/sparse_model.py
-Comment: 
-
-Filename: sparseml/transformers/utils/sparse_tokenizer.py
+Filename: sparseml/transformers/utils/preprocessing_functions.py
 Comment: 
 
 Filename: sparseml/utils/__init__.py
 Comment: 
 
 Filename: sparseml/utils/frameworks.py
 Comment: 
@@ -1521,14 +1608,17 @@
 
 Filename: sparseml/utils/pytorch/__init__.py
 Comment: 
 
 Filename: sparseml/utils/pytorch/module.py
 Comment: 
 
+Filename: sparseml/utils/pytorch/utils.py
+Comment: 
+
 Filename: sparseml/utils/pytorch/pruning/__init__.py
 Comment: 
 
 Filename: sparseml/yolact/COCO.sh
 Comment: 
 
 Filename: sparseml/yolact/COCO_test.sh
@@ -1581,32 +1671,32 @@
 
 Filename: sparseml/yolov8/utils/export_samples.py
 Comment: 
 
 Filename: sparseml/yolov8/utils/helpers.py
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/LICENSE
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/LICENSE
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/LICENSE-ULTRALYTICS
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/LICENSE-ULTRALYTICS
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/METADATA
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/METADATA
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/NOTICE
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/NOTICE
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/WHEEL
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/WHEEL
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/entry_points.txt
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/entry_points.txt
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/top_level.txt
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/top_level.txt
 Comment: 
 
-Filename: sparseml_nightly-1.7.0.20240304.dist-info/RECORD
+Filename: sparseml_nightly-1.8.0.20240401.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## sparseml/version.py

```diff
@@ -15,24 +15,27 @@
 """
 Functionality for storing and setting the version info for SparseML
 """
 
 from datetime import date
 
 
-version_base = "1.7.0"
+version_base = "1.8.0"
 is_release = False  # change to True to set the generated version as a release version
+is_dev = False
+dev_number = None
 
 
 def _generate_version():
-    return (
-        version_base
-        if is_release
-        else f"{version_base}.{date.today().strftime('%Y%m%d')}"
-    )
+    if is_release:
+        return version_base
+    elif is_dev:
+        return f"{version_base}.dev{dev_number}"
+    else:
+        return f"{version_base}.{date.today().strftime('%Y%m%d')}"
 
 
 __all__ = [
     "__version__",
     "version_base",
     "is_release",
     "version",
```

## sparseml/core/logger/logger.py

```diff
@@ -30,35 +30,38 @@
 
 from sparseml.core.logger.utils import (
     FrequencyManager,
     FrequencyType,
     LoggingModeType,
     LogStepType,
 )
+from sparseml.utils import is_package_available
 
 
 try:
     try:
         from torch.utils.tensorboard import SummaryWriter
     except (ModuleNotFoundError, ImportError):
         from tensorboardX import SummaryWriter
     tensorboard_import_error = None
 except Exception as tensorboard_err:
     SummaryWriter = object
     tensorboard_import_error = tensorboard_err
 
 
-try:
+wandb_available = is_package_available("wandb")
+if wandb_available:
     import wandb
 
     wandb_err = None
-except Exception as err:
-    wandb = None
-    wandb_err = err
-
+else:
+    wandb = object
+    wandb_err = ModuleNotFoundError(
+        "`wandb` is not installed, use `pip install wandb` to log to Weights and Biases"
+    )
 
 __all__ = [
     "BaseLogger",
     "LambdaLogger",
     "PythonLogger",
     "TensorBoardLogger",
     "WANDBLogger",
@@ -576,28 +579,25 @@
     """
 
     @staticmethod
     def available() -> bool:
         """
         :return: True if wandb is available and installed, False, otherwise
         """
-        return not wandb_err
+        return wandb_available
 
     def __init__(
         self,
         init_kwargs: Optional[Dict] = None,
         name: str = "wandb",
         enabled: bool = True,
         wandb_err: Optional[Exception] = wandb_err,
     ):
         if wandb_err:
-            raise ModuleNotFoundError(
-                "Error: Failed to import wandb. "
-                "Please install the wandb library in order to use it."
-            ) from wandb_err
+            raise wandb_err
 
         super().__init__(
             lambda_func=self._log_lambda,
             name=name,
             enabled=enabled,
         )
```

## sparseml/core/model/base.py

```diff
@@ -163,7 +163,15 @@
     def qat_active(self) -> bool:
         """
         Checks if quantization aware training is set up in the model
 
         :return: True if QAT is active in any layer, False otherwise
         """
         raise NotImplementedError()
+
+    def get_no_split_params(self) -> Union[str, List[str]]:
+        """
+        Get list of module classes that shouldn't be split when sharding
+
+        :return: list of class names that shouldn't be split
+        """
+        raise NotImplementedError()
```

## sparseml/core/model/pytorch.py

```diff
@@ -22,14 +22,15 @@
     ModuleSparsificationInfo,
 )
 from sparseml.utils.pytorch import (
     get_layer,
     get_layers,
     get_layers_params,
     get_matching_layer,
+    get_no_split_params,
     get_param,
     get_params,
     qat_active,
     set_layer,
     set_param,
 )
 
@@ -142,7 +143,17 @@
     def qat_active(self) -> bool:
         """
         Checks if quantization aware training is set up in the model
 
         :return: True if QAT is active in any layer, False otherwise
         """
         return qat_active(self.model)
+
+    def get_no_split_params(self) -> Union[str, List[str]]:
+        """
+        Get list of module classes that shouldn't be split when sharding. For
+        Hugging Face Transformer models, this is the decoder layer type. For other
+        types of models, this just returns all module names.
+
+        :return: list of class names that shouldn't be split
+        """
+        return get_no_split_params(self.model)
```

## sparseml/core/recipe/container.py

```diff
@@ -26,14 +26,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from dataclasses import dataclass, field
 from typing import Any, Dict, List, Optional, Union
 
+from sparseml.core.modifier.modifier import Modifier
 from sparseml.core.recipe.recipe import Recipe, RecipeTuple
 
 
 __all__ = ["RecipeContainer"]
 
 
 @dataclass
@@ -49,15 +50,17 @@
 
     compiled_recipe: Optional[Recipe] = None
     recipes: List[RecipeTuple] = field(default_factory=list)
     applied_stages: List[str] = field(default_factory=list)
 
     def update(
         self,
-        recipe: Union[str, List[str], Recipe, List[Recipe], None] = None,
+        recipe: Union[
+            str, List[str], Recipe, List[Recipe], Modifier, List[Modifier], None
+        ] = None,
         recipe_stage: Union[str, List[str], List[List[str]], None] = None,
         recipe_args: Union[Dict[str, Any], List[Dict[str, Any]], None] = None,
         **kwargs,
     ) -> Dict:
         """
         Update the recipes in the container. If a recipe is provided, it will
         reset any existing compiled_recipe in the container. Must call
@@ -86,41 +89,50 @@
 
         :param recipe: the recipe to update the container with
         :param recipe_stage: the recipe stage to update the container with
         :param recipe_args: the recipe args to update the recipe with
         :param kwargs: additional kwargs to return
         :return: the passed in kwargs
         """
-        if recipe is not None:
-            self.compiled_recipe = None
+        if recipe is None or isinstance(recipe, list) and len(recipe) == 0:
+            return kwargs
 
-            if not isinstance(recipe, list):
-                recipe = [recipe]
-            if recipe_stage is None:
-                recipe_stage = [None] * len(recipe)
-            else:
-                if not isinstance(recipe_stage, list):
-                    recipe_stage = [[recipe_stage]] * len(recipe)
-                if not isinstance(recipe_stage[0], list):
-                    recipe_stage = [recipe_stage] * len(recipe)
-
-            if recipe_args is None:
-                recipe_args = [{}] * len(recipe)
-            elif not isinstance(recipe_args, list):
-                recipe_args = [recipe_args] * len(recipe)
-
-            if len(recipe) != len(recipe_stage) or len(recipe) != len(recipe_args):
-                raise ValueError(
-                    "recipe, recipe_stage, and recipe_args must be the same length"
-                )
-
-            for rec, stage, args in zip(recipe, recipe_stage, recipe_args):
-                if isinstance(rec, str):
-                    rec = Recipe.create_instance(rec)
-                self.recipes.append(RecipeTuple(rec, stage, args))
+        self.compiled_recipe = None
+
+        if isinstance(recipe, Modifier) or (
+            isinstance(recipe, list)
+            and all(isinstance(mod, Modifier) for mod in recipe)
+        ):
+            recipe = Recipe.create_instance(recipe)
+
+        if not isinstance(recipe, list):
+            recipe = [recipe]
+
+        if recipe_stage is None:
+            recipe_stage = [None] * len(recipe)
+        else:
+            if not isinstance(recipe_stage, list):
+                recipe_stage = [[recipe_stage]] * len(recipe)
+            if not isinstance(recipe_stage[0], list):
+                recipe_stage = [recipe_stage] * len(recipe)
+
+        if recipe_args is None:
+            recipe_args = [{}] * len(recipe)
+        elif not isinstance(recipe_args, list):
+            recipe_args = [recipe_args] * len(recipe)
+
+        if len(recipe) != len(recipe_stage) or len(recipe) != len(recipe_args):
+            raise ValueError(
+                "recipe, recipe_stage, and recipe_args must be the same length"
+            )
+
+        for rec, stage, args in zip(recipe, recipe_stage, recipe_args):
+            if isinstance(rec, str):
+                rec = Recipe.create_instance(rec)
+            self.recipes.append(RecipeTuple(rec, stage, args))
 
         return kwargs
 
     def update_applied_stages(self, new_stages: List[str]):
         """
         Updates the applied_stages list with new stages, indicating their structure
         has already been applied
```

## sparseml/core/recipe/modifier.py

```diff
@@ -72,18 +72,18 @@
         """
         if not self.args:
             raise ValueError("args must be set before evaluating")
 
         comb_args = args or RecipeArgs()
         self.args_evaluated = comb_args.evaluate_ext(self.args)
 
-        if shift is not None and "start" in self.args_evaluated:
+        if shift is not None and self.args_evaluated.get("start") is not None:
             self.args_evaluated["start"] += shift
 
-        if shift is not None and "end" in self.args_evaluated:
+        if shift is not None and self.args_evaluated.get("end") is not None:
             self.args_evaluated["end"] += shift
 
     def create_modifier(self, framework: Framework) -> "Modifier":
         """
         Create a Framework specific Modifier instance using the ModifierFactory
 
         :param framework: the framework to create the modifier for
```

## sparseml/core/recipe/recipe.py

```diff
@@ -20,14 +20,15 @@
 from typing import Any, Dict, List, Optional, Union
 
 import yaml
 from pydantic import Field, root_validator
 
 from sparseml.core.framework import Framework
 from sparseml.core.modifier import StageModifiers
+from sparseml.core.modifier.modifier import Modifier
 from sparseml.core.recipe.args import RecipeArgs
 from sparseml.core.recipe.base import RecipeBase
 from sparseml.core.recipe.metadata import RecipeMetaData
 from sparseml.core.recipe.stage import RecipeStage
 from sparsezoo import Model
 
 
@@ -45,68 +46,138 @@
     https://docs.neuralmagic.com/products/sparseml)
 
     Recipes can be created from a file, string, or SparseZoo stub.
     Acceptable file formats include both json and yaml, however,
     when serializing a recipe, yaml will be used by default.
     """
 
-    @staticmethod
-    def create_instance(path: str) -> "Recipe":
+    @classmethod
+    def from_modifiers(
+        cls,
+        modifiers: Union[Modifier, List[Modifier]],
+        modifier_group_name: Optional[str] = None,
+    ) -> "Recipe":
         """
-        Create a recipe instance from a file, or string
+        Create a recipe instance from a list of modifiers
+
+        (Note: all modifiers are wrapped into a single stage
+        with the modifier_group_name as the stage name. If modifier_group_name is None,
+        the default run type is `oneshot`)
+
+        Lfecycle:
+        | - Validate Modifiers
+        | - Create recipe string from modifiers
+        | - Create recipe instance from recipe string
+
+        :param modifiers: The list of RecipeModifier instances
+        :param modifier_group_name: The stage_name of the recipe,
+            if `oneshot` or `train` the run_type of the recipe will be
+            inferred from the modifier_group_name, if None, a dummy default
+            group_name will be assigned.
+        :return: The Recipe instance created from the modifiers
+        """
+        _LOGGER.info("Creating recipe from modifiers")
+
+        # validate Modifiers
+        if isinstance(modifiers, Modifier):
+            modifiers: List[Modifier] = [modifiers]
+
+        if any(not isinstance(modifier, Modifier) for modifier in modifiers):
+            raise ValueError("modifiers must be a list of Modifier instances")
+
+        recipe_string: str = create_recipe_string_from_modifiers(
+            modifiers=modifiers,
+            modifier_group_name=modifier_group_name,
+        )
+
+        # modifier group name already included in the recipe string
+        return cls.create_instance(path_or_modifiers=recipe_string)
+
+    @classmethod
+    def create_instance(
+        cls,
+        path_or_modifiers: Union[str, Modifier, List[Modifier]],
+        modifier_group_name: Optional[str] = None,
+    ) -> "Recipe":
+        """
+        Create a recipe instance from a file, string, or RecipeModifier objects
 
 
         Using a recipe string or file is supported:
         >>> recipe_str = '''
         ... test_stage:
         ...     pruning_modifiers:
         ...         ConstantPruningModifier:
         ...             start: 0.0
         ...             end: 2.0
         ...             targets: ['re:.*weight']
         ... '''
         >>> recipe = Recipe.create_instance(recipe_str)
 
-        :param path: The path to the recipe file or
-            SparseZoo stub or the recipe string, must be a valid
-            json/yaml file or a valid json/yaml string
-        """
-        if not os.path.isfile(path):
+        :param path_or_modifiers: The path to the recipe file or
+            SparseZoo stub or the recipe string (must be a valid
+            json/yaml file or a valid json/yaml string). Can also
+            accept a RecipeModifier instance, or a list of
+            RecipeModifiers
+        :param modifier_group_name: The stage_name of the recipe,
+            if `oneshot` or `train` the run_type of the recipe will be
+            inferred from the modifier_group_name, if None, a dummy default
+            group_name will be assigned. This argument is only used
+            when creating a recipe from a Modifier/list of Modifier(s)
+            instance, else it's ignored.
+        :return: The Recipe instance created from the path or modifiers,
+            or a valid recipe string in yaml/json format
+        """
+
+        if isinstance(path_or_modifiers, Recipe):
+            # already a recipe
+            return path_or_modifiers
+
+        if isinstance(path_or_modifiers, (Modifier, list)):
+            return cls.from_modifiers(
+                modifiers=path_or_modifiers, modifier_group_name=modifier_group_name
+            )
+
+        if not os.path.isfile(path_or_modifiers):
             # not a local file
-            if path.startswith("zoo:"):
+            if path_or_modifiers.startswith("zoo:"):
                 # download from SparseZoo
-                model = Model(path)
-                path = model.recipes.default.path
-                _LOGGER.info(f"Loading recipe from zoo stub {path}")
+                model = Model(path_or_modifiers)
+                path_or_modifiers = model.recipes.default.path
+                _LOGGER.info(f"Loading recipe from zoo stub {path_or_modifiers}")
             else:
                 # assume it's a string
                 _LOGGER.warning(
                     "Could not process input as a file path or zoo stub, "
                     "attempting to process it as a string."
                 )
-                _LOGGER.warning(f"Input string: {path}")
-                obj = _load_json_or_yaml_string(path)
+                _LOGGER.debug(f"Input string: {path_or_modifiers}")
+                obj = _load_json_or_yaml_string(path_or_modifiers)
                 return Recipe.parse_obj(obj)
         else:
-            _LOGGER.info(f"Loading recipe from file {path}")
+            _LOGGER.info(f"Loading recipe from file {path_or_modifiers}")
 
-        with open(path, "r") as file:
+        with open(path_or_modifiers, "r") as file:
             content = file.read().strip()
-            if path.lower().endswith(".md"):
-                content = _parse_recipe_from_md(path, content)
+            if path_or_modifiers.lower().endswith(".md"):
+                content = _parse_recipe_from_md(path_or_modifiers, content)
 
-            if path.lower().endswith(".json"):
+            if path_or_modifiers.lower().endswith(".json"):
                 obj = json.loads(content)
-            elif path.lower().endswith(".yaml") or path.lower().endswith(".yml"):
+            elif path_or_modifiers.lower().endswith(
+                ".yaml"
+            ) or path_or_modifiers.lower().endswith(".yml"):
                 obj = yaml.safe_load(content)
             else:
                 try:
                     obj = _load_json_or_yaml_string(content)
                 except ValueError:
-                    raise ValueError(f"Could not parse recipe from path {path}")
+                    raise ValueError(
+                        f"Could not parse recipe from path {path_or_modifiers}"
+                    )
             return Recipe.parse_obj(obj)
 
     @staticmethod
     def simplify_recipe(
         recipe: Union["Recipe", "RecipeTuple"], shift: Optional[int] = None
     ) -> "Recipe":
         """
@@ -143,15 +214,21 @@
         stage_names = recipe.target_stages
         if stage_names is None:
             stages = recipe.recipe.stages
         else:
             for stage in recipe.recipe.stages:
                 if stage.group in stage_names:
                     stages.append(stage)
-        args = recipe.override_args if isinstance(recipe, RecipeTuple) else {}
+
+        # default args in recipe
+        args = recipe.recipe.args if isinstance(recipe, RecipeTuple) else recipe.args
+
+        # overwrite with args passed in through CLI
+        for key, val in recipe.override_args.items():
+            args[key] = val
         version = recipe.version if isinstance(recipe, Recipe) else None
 
         simplified = Recipe()
         simplified.version = version
         simplified.args = RecipeArgs(args)
         simplified.stages = stages
         simplified.evaluate(args=args, shift=shift)
@@ -321,17 +398,26 @@
         modifiers = RecipeStage.extract_dict_modifiers(values)
         if modifiers:
             default_stage = {"modifiers": modifiers, "group": "default"}
             stages.append(default_stage)
 
         extracted = Recipe.extract_dict_stages(values)
         stages.extend(extracted)
-        values["stages"] = stages
+        formatted_values = {}
+
+        # fill out stages
+        formatted_values["stages"] = stages
 
-        return values
+        # fill out any default argument values
+        args = {}
+        for key, val in values.items():
+            args[key] = val
+        formatted_values["args"] = RecipeArgs(args)
+
+        return formatted_values
 
     @staticmethod
     def extract_dict_stages(values: Dict[str, Any]) -> List[Dict[str, Any]]:
         """
         Extract stages from a dict of values, acceptable dictionary structures
         are shown below
 
@@ -576,7 +662,51 @@
     else:
         # fail if we know whe should have extracted front matter out
         raise RuntimeError(
             "Could not extract YAML front matter from recipe card:"
             " {}".format(file_path)
         )
     return yaml_str
+
+
+def create_recipe_string_from_modifiers(
+    modifiers: List[Modifier],
+    modifier_group_name: Optional[str] = None,
+) -> str:
+    """
+    Create a recipe string from a list of Modifier instances
+
+    (Note: this pathway assumes there's only one stage in the recipe
+    associated by the modifier_group_name, if None, a dummy default
+    group_name will be assigned.)
+
+    :param modifiers: The list of Modifier instances
+    :param modifier_group_name: The stage_name of the recipe,
+        if `oneshot` or `train` the run_type of the recipe will be
+        inferred from the modifier_group_name, if None, a dummy default
+        group_name will be assigned.
+    :return: A string in yaml format from which the recipe can be created
+    """
+
+    # Recipe(s) are yaml/json strings of the following format:
+    # run_type_stage: # should contain oneshot/train
+    #    modifiers:
+    #        ModifierTypeOne:
+    #            start: 0.0
+    #            end: 2.0
+    #            ...
+    #        ModifierTypeTwo:
+    #            ...
+
+    # Create a recipe string from the modifiers
+    default_group_name: str = "DEFAULT"
+    modifier_group_name: str = modifier_group_name or default_group_name
+
+    recipe_dict = {
+        f"{modifier_group_name}_stage": {
+            f"{default_group_name}_modifiers": {
+                modifier.__class__.__name__: modifier.dict() for modifier in modifiers
+            }
+        }
+    }
+    recipe_str: str = yaml.dump(recipe_dict)
+    return recipe_str
```

## sparseml/evaluation/evaluator.py

```diff
@@ -11,14 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 
 from typing import Optional
 
+from sparseml.core.utils import session_context_manager
 from sparseml.evaluation.registry import SparseMLEvaluationRegistry
 from sparsezoo.evaluation.results import Result
 
 
 __all__ = ["evaluate"]
 
 
@@ -39,19 +40,21 @@
         `open_platypus`. If None, it is left upto the integration
         to handle the default dataset.
     :param integration: Name of the eval integration to use.
         Example, `perplexity`
     :param batch_size: The batch size to use for evals, defaults to 1
     :return: The evaluation result as a Result object
     """
-
-    eval_integration = SparseMLEvaluationRegistry.resolve(
-        name=integration, datasets=datasets
-    )
-
-    if datasets is None:
-        # let the integration handle the default dataset
-        return eval_integration(model_path=model_path, batch_size=batch_size, **kwargs)
-
-    return eval_integration(
-        model_path=model_path, datasets=datasets, batch_size=batch_size, **kwargs
-    )
+    with session_context_manager():
+        eval_integration = SparseMLEvaluationRegistry.resolve(
+            name=integration, datasets=datasets
+        )
+
+        if datasets is None:
+            # let the integration handle the default dataset
+            return eval_integration(
+                model_path=model_path, batch_size=batch_size, **kwargs
+            )
+
+        return eval_integration(
+            model_path=model_path, datasets=datasets, batch_size=batch_size, **kwargs
+        )
```

## sparseml/evaluation/integrations/lm_evaluation_harness.py

```diff
@@ -30,14 +30,15 @@
         " pip install sparseml[transformers,torch]`"
     ) from import_error
 try:
     # This needs to be imported after lm_eval to ensure right transformers
     # version is installed for SparseML
     from sparseml.transformers.utils.sparse_config import SparseAutoConfig
     from sparseml.transformers.utils.sparse_model import SparseAutoModelForCausalLM
+    from sparseml.transformers.utils.sparse_tokenizer import SparseAutoTokenizer
 except ImportError as import_error:
     raise ImportError(
         "Install sparseml supported dependencies for lm-eval integration by running "
         "`pip uninstall transformers && pip install sparseml[transformers,torch]`"
     ) from import_error
 
 __all__ = ["lm_eval_harness", "SparseMLLM"]
@@ -63,17 +64,18 @@
         a local model directory or a SparseZoo/Huggingface stub
     :param datasets: the datasets to evaluate on, can be a string or
         list of strings, or a command separated string
     :param batch_size: the batch size to use for evaluation
     :param kwargs: additional keyword arguments to pass to the
         lm-evaluation-harness. For example, `limit`
     """
-
     kwargs["limit"] = int(limit) if (limit := kwargs.get("limit")) else None
-    model = SparseMLLM(pretrained=model_path, **kwargs)
+
+    tokenizer = SparseAutoTokenizer.from_pretrained(model_path)
+    model = SparseMLLM(pretrained=model_path, tokenizer=tokenizer, **kwargs)
 
     if kwargs.get("limit"):
         _LOGGER.warning(
             "WARNING: --limit SHOULD ONLY BE USED FOR TESTING. "
             "REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT."
         )
     tasks.initialize_tasks()
```

## sparseml/evaluation/integrations/perplexity.py

```diff
@@ -10,16 +10,15 @@
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 from typing import List, Optional, Union
 
-from sparseml.transformers.utils.sparse_model import SparseAutoModelForCausalLM
-from sparseml.transformers.utils.sparse_tokenizer import SparseAutoTokenizer
+from sparseml.transformers import SparseAutoModelForCausalLM, SparseAutoTokenizer
 
 
 try:
     import numpy
     import torch
     from datasets import Dataset as HuggingFaceDataset
     from datasets import load_dataset
```

## sparseml/export/validators.py

```diff
@@ -14,16 +14,18 @@
 
 import glob
 import logging
 import os.path
 from collections import OrderedDict
 from pathlib import Path
 from typing import Callable, List, Optional, Union
+from typing import OrderedDict as OrderedDictType
 
 import numpy
+import onnx
 
 from sparseml.export.export_data import InputsNames, LabelNames, OutputsNames
 from sparseml.export.helpers import ONNX_MODEL_NAME, onnx_data_files
 from sparsezoo.utils.numpy import load_numpy
 
 
 __all__ = ["validate_correctness", "validate_structure"]
@@ -160,30 +162,38 @@
         ) from err
 
     sample_inputs_path = os.path.join(target_path, InputsNames.basename.value)
     sample_outputs_path = os.path.join(target_path, OutputsNames.basename.value)
 
     sample_inputs_files = sorted(glob.glob(os.path.join(sample_inputs_path, "*")))
     sample_outputs_files = sorted(glob.glob(os.path.join(sample_outputs_path, "*")))
-
-    session = ort.InferenceSession(os.path.join(directory, onnx_model_name))
+    model_path = os.path.join(directory, onnx_model_name)
+    expected_input_names = [
+        inp.name for inp in onnx.load(model_path, load_external_data=False).graph.input
+    ]
+    session = ort.InferenceSession(model_path)
 
     validations = (
         []
     )  # stores boolean per sample pair (True if validation passes, False otherwise)
 
     for sample_input_file, sample_output_file in zip(
         sample_inputs_files, sample_outputs_files
     ):
         sample_input = load_numpy(sample_input_file)
         sample_output = load_numpy(sample_output_file)
 
         sample_input_with_batch_dim = OrderedDict(
             (key, numpy.expand_dims(value, 0)) for key, value in sample_input.items()
         )
+
+        sample_input_with_batch_dim = _potentially_rename_input(
+            sample_input_with_batch_dim, expected_input_names
+        )
+
         outputs = session.run(None, sample_input_with_batch_dim)
         if isinstance(outputs, list):
             validations_sample = []
             for o1, o2 in zip(outputs, sample_output.values()):
                 validations_sample.append(validation_function(o1, o2))
             validations.append(all(validations_sample))
         else:
@@ -201,7 +211,21 @@
         )
         return False
 
     _LOGGER.info(
         f"Successfully validated the exported model on all {len(validations)} samples."
     )
     return True
+
+
+def _potentially_rename_input(
+    sample_input_with_batch_dim: OrderedDictType[str, numpy.ndarray],
+    expected_input_names: List[str],
+) -> OrderedDictType[str, numpy.ndarray]:
+    # if required, rename the input names of the sample to match
+    # the input names of the model
+    input_names = list(sample_input_with_batch_dim.keys())
+    if set(input_names) != set(expected_input_names):
+        return OrderedDict(
+            zip(expected_input_names, sample_input_with_batch_dim.values())
+        )
+    return sample_input_with_batch_dim
```

## sparseml/modifiers/distillation/utils/pytorch/model_wrapper.py

```diff
@@ -45,15 +45,14 @@
 
         def _clear_missing_keys(module, incompatible_keys):
             incompatible_keys.missing_keys.clear()
 
         self.register_load_state_dict_post_hook(_clear_missing_keys)
 
     def forward(self, *args, **kwargs):
-        self.teacher_model.eval()
         if not self.kd_enabled:
             return self.student_model(*args, **kwargs)
 
         org_output = self.student_model(*args, **kwargs)
         with torch.no_grad():
             self.teacher_model(*args, **kwargs)
 
@@ -114,12 +113,19 @@
                 memo=memo, prefix=prefix, remove_duplicate=remove_duplicate
             )
 
         return self.student_model.named_modules(
             memo=memo, prefix=prefix, remove_duplicate=remove_duplicate
         )
 
+    def named_children(self):
+        return self.student_model.named_children()
+
+    def train(self, mode: bool = True):
+        self.student_model.train(mode)
+        return self
+
     def __getattr__(self, name: str) -> Any:
         try:
             return super().__getattr__(name)
         except AttributeError:
             return getattr(self.student_model, name)
```

## sparseml/modifiers/pruning/constant/pytorch.py

```diff
@@ -67,13 +67,16 @@
             # hooks are used to update, so nothing to do here
             return
         if event.type_ == EventType.OPTIM_POST_STEP:
 
             def apply_masks(module):
                 mask_name = param_mask_name()
                 if hasattr(module, mask_name):
+                    mask = getattr(module, mask_name)
+                    if mask.device != module.weight.device:
+                        setattr(module, mask_name, mask.to(module.weight.device))
                     module.weight *= getattr(module, mask_name)
 
             state.model.model.apply(apply_masks)
 
     def on_end(self, state: State, event: Event, **kwargs):
         self.disable_masks()
```

## sparseml/modifiers/pruning/wanda/base.py

```diff
@@ -14,15 +14,14 @@
 
 
 from typing import Dict, List, Optional, Union
 
 from sparseml.core import Modifier
 from sparseml.core.model.base import ModifiableModel
 from sparseml.core.state import State
-from sparseml.utils import ALL_TOKEN
 
 
 __all__ = ["WandaPruningModifier"]
 
 
 class WandaPruningModifier(Modifier):
     """
@@ -53,15 +52,15 @@
 
     sparsity: Union[float, List[float]] = 0.0
     sparsity_profile: Optional[str] = None
     owl_m: Optional[int] = None
     owl_lmbda: Optional[float] = None
     mask_structure: str = "0:0"
     sequential_update: Optional[bool] = False
-    targets: Union[str, List[str], None] = ALL_TOKEN
+    targets: Union[str, List[str], None] = None
     compressible_layers_: Optional[List] = None
     prunen_: Optional[int] = None
     prunem_: Optional[int] = None
 
     def on_initialize_structure(self, state: State, **kwargs):
         """
         This modifier does not alter the model structure.
```

## sparseml/modifiers/pruning/wanda/pytorch.py

```diff
@@ -59,14 +59,20 @@
 
         :param state: session state storing input model and calibration data
         :param kwargs: Unused, kept to conform to the parent method signature
         """
         modifiable_model = state.model
         calibration_dataloader = state.data.calib
 
+        if self.targets is None:
+            # if no targets are provided, default to the modules that shouldn't be
+            # split by FSDP. For Transformers models this is equivalent to the
+            # decoder layers (ie LlamaDecoderLayer)
+            self.targets = modifiable_model.get_no_split_params()
+
         self.initialize_compression(modifiable_model, calibration_dataloader)
         self.apply_compression(calibration_dataloader)
 
         return True
 
     def initialize_compression(
         self,
@@ -92,19 +98,20 @@
                 f"{len(dataloader)} calibration samples..."
             )
             self.sparsity = self._infer_layer_sparsity(dataloader)
         self._validate_layerwise_sparsity()
 
         for idx, (name, layer) in enumerate(self.compressible_layers_.items()):
             _LOGGER.info(f"Preparing {name} for compression")
-            layer_sparsity = (
-                self.sparsity[name]
-                if isinstance(self.sparsity, Dict)
-                else self.sparsity
-            )
+            if isinstance(self.sparsity, Dict):
+                layer_sparsity = self.sparsity[name]
+            elif isinstance(self.sparsity, List):
+                layer_sparsity = self.sparsity[idx]
+            else:  # float
+                layer_sparsity = self.sparsity
             args = self._pruning_arguments(layer_sparsity)
             comp_cls = self._compression_class()
             compressor = LayerCompressor(comp_cls, self.model, layer, idx, name, args)
             if not self.sequential_update:
                 # add all batch processing hooks before the forward pass
                 compressor.pre_compress()
             self.layer_compressors_.append(compressor)
```

## sparseml/modifiers/utils/layer_compressor.py

```diff
@@ -119,15 +119,19 @@
 
     def revert_layer_wrappers(self):
         """
         Reverts wrapped root modules back to their original structure
         """
         for name, module_wrapper in self.modules.items():
             full_name = self._get_full_submodule_name(name)
-            set_layer(full_name, module_wrapper.layer, self.model)
+            if len(name) == 0:  # special case if layer has no children (i.e. lm_head)
+                with summon_full_params_context(self.model):
+                    set_layer(full_name, module_wrapper.layer, self.model)
+            else:
+                set_layer(name, module_wrapper.layer, self.layer)
             module_wrapper.free()
         self.modules = None
 
     def compress(self):
         """
         Apply compression to each wrapped submodule in the layer
         """
```

## sparseml/pytorch/model_load/helpers.py

```diff
@@ -18,14 +18,15 @@
 import os
 from typing import Any, Dict, List, Optional
 
 import torch
 from torch.nn import Module
 
 import sparseml.core.session as session_manager
+from safetensors import safe_open
 from sparseml.core.framework import Framework
 from sparseml.pytorch.sparsification.quantization.helpers import (
     initialize_channel_wise_scale_zp,
 )
 from sparseml.pytorch.utils import ModuleSparsificationInfo
 
 
@@ -139,15 +140,16 @@
     :return: True if weights are successfully reloaded; False otherwise.
     """
     invalid_load_path = not load_path or not os.path.isdir(load_path)
     files = os.listdir(load_path) if not invalid_load_path else []
     weight_files = [
         os.path.join(load_path, os.path.basename(f))
         for f in files
-        if f.startswith("pytorch_model") and f.endswith("bin")
+        if (f.startswith("pytorch_model") and f.endswith("bin"))
+        or (f.endswith("safetensors"))
     ]
     if not weight_files:
         _LOGGER.warning(
             "Model state was not reloaded for SparseML: "
             f"could not find model weights for {load_path}"
         )
         return False
@@ -164,15 +166,18 @@
     if set(orig_state_dict.keys()) == set(current_state_dict):
         # no change in keys, ignore reload
         return False
 
     # change in keys due to architecture changes, reload statedict
     loaded_state_dict = {}
     for f in weight_files:
-        dd = torch.load(f, map_location="cpu")
+        if f.endswith("safetensors"):
+            dd = load_safetensors_state_dict(file_path=f)
+        else:
+            dd = torch.load(f, map_location="cpu")
         loaded_state_dict.update(dd)
 
     _, missing, unexpected, mismatched, _, _ = model._load_pretrained_model(
         model=model,
         state_dict=loaded_state_dict,
         loaded_keys=list(loaded_state_dict.keys()),
         resolved_archive_file=None,
@@ -225,25 +230,33 @@
 
     # reload the state dict for the model from the checkpoint
     if reload_model_state(model, checkpoint, orig_state_dict):
         _LOGGER.info(f"Reloaded model state from checkpoint {checkpoint}")
 
 
 def save_model_and_recipe(
-    model: Module, save_path: str, tokenizer: Optional[Any] = None
+    model: Module,
+    save_path: str,
+    tokenizer: Optional[Any] = None,
+    save_safetensors: bool = False,
+    save_compressed: bool = False,
 ):
     """
     Save a model, tokenizer and the currently loaded recipe to file
 
     :param model: pytorch model to save
     :param save_path: path to save output to
     :param tokenizer: model tokenizer to save
+    :param save_safetensors: whether to save as safetensors or pickle (bin)
+    :param save_compressed: whether to compress sparse weights on disk
     """
 
-    model.save_pretrained(save_path)
+    model.save_pretrained(
+        save_path, save_compressed=save_compressed, safe_serialization=save_safetensors
+    )
 
     if tokenizer is not None:
         tokenizer.save_pretrained(save_path)
 
     _LOGGER.info("Saving output to {}".format(os.path.abspath(save_path)))
 
     recipe_path = os.path.join(save_path, RECIPE_FILE_NAME)
@@ -322,7 +335,18 @@
 
     :param checkpoint_dir: model checkpoint directory to save stages to
     :param completed_stages: list of stage names that have been run
     """
     stage_path = os.path.join(checkpoint_dir, COMPLETED_STAGES_FILENAME)
     with open(stage_path, "w") as out_file:
         json.dump({"completed": completed_stages}, out_file)
+
+
+def load_safetensors_state_dict(file_path: str) -> Dict[str, torch.Tensor]:
+    """
+    Load a safetensors file from disk
+
+    :param file_path: path to the safetensors file
+    :return: dictionary of safetensors data
+    """
+    with safe_open(file_path, framework="pt", device="cpu") as f:
+        return {key: f.get_tensor(key) for key in f.keys()}
```

## sparseml/pytorch/optim/analyzer_module.py

```diff
@@ -9,18 +9,19 @@
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 """
-Code related to monitoring, analyzing, and reporting info for Modules in PyTorch.
-Records things like FLOPS, input and output shapes, kernel shapes, etc.
+Code for overall sparsity and forward  FLOPs (floating-point operations)
+estimation for neural networks.
 """
 
+import numbers
 from typing import List, Tuple, Union
 
 import numpy
 from torch import Tensor
 from torch.nn import (
     CELU,
     ELU,
@@ -62,24 +63,37 @@
     """
     An analyzer implementation for monitoring the execution profile and graph of
     a Module in PyTorch.
 
     :param module: the module to analyze
     :param enabled: True to enable the hooks for analyzing and actively track,
         False to disable and not track
+    :param ignore_zero: whether zeros should be excluded from FLOPs (standard
+        when estimating 'theoretical' FLOPs in sparse networks
+    : param
+    :param multiply_adds: Whether total flops includes the cost of summing the
+        multiplications together
     """
 
-    def __init__(self, module: Module, enabled: bool = False):
+    def __init__(
+        self,
+        module: Module,
+        enabled: bool = False,
+        ignore_zero=True,
+        multiply_adds=True,
+    ):
         super(ModuleAnalyzer, self).__init__()
         self._module = module
         self._hooks = None  # type: List[RemovableHandle]
         self._forward_called = False
         self._enabled = False
         self._call_count = -1
         self.enabled = enabled
+        self._ignore_zero = ignore_zero
+        self._multiply_adds = multiply_adds
 
     def __del__(self):
         self._delete_hooks()
 
     @property
     def enabled(self) -> bool:
         """
@@ -131,15 +145,15 @@
         Get the descriptions for all layers in the module that support kernel sparsity
         (model pruning). Ex: all convolutions and linear layers.
 
         :return: a list of descriptions for all layers in the module that support ks
         """
         descs = []
 
-        for (name, _) in get_prunable_layers(self._module):
+        for name, _ in get_prunable_layers(self._module):
             desc = self.layer_desc(name)
 
             if desc is None:
                 print("analyzer: no description found for {}".format(name))
             else:
                 descs.append(desc)
 
@@ -208,18 +222,23 @@
     def _forward_pre_hook(
         self,
         mod: Module,
         inp: Union[Tuple[Tensor, ...], Tensor],
     ):
         self._call_count += 1
 
+        if mod._analyzed_layer_desc is not None:
+            return
+
         mod._analyzed_layer_desc = AnalyzedLayerDesc(
             name=mod._analyzed_layer_name,
             type_=mod.__class__.__name__,
             execution_order=self._call_count,
+            flops=0,
+            total_flops=0,
         )
 
     def _init_forward_hook(
         self,
         mod: Module,
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
@@ -254,235 +273,190 @@
         self,
         mod: _ConvNd,
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
-        params = (
-            {"weight": mod.weight}
-            if mod.bias is None
-            else {"weight": mod.weight, "bias": mod.bias}
+        desc.params = mod.weight.data.numel() + (
+            mod.bias.data.numel() if mod.bias is not None else 0
         )
-        prunable_params = {"weight": mod.weight}
+        desc.prunable_params = mod.weight.data.numel()
+        desc.zeroed_params = desc.prunable_params - mod.weight.data.count_nonzero()
 
-        desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
-        desc.stride = mod.stride
-
-        mult_per_out_pix = float(numpy.prod(mod.kernel_size)) * mod.in_channels
-        add_per_out_pix = 1 if mod.bias is not None else 0
-        out_pix = float(numpy.prod(out[0].shape[1:]))
-
-        # total flops counts the cost of summing the
-        # multiplications together as well
-        # most implementations and papers do not include this cost
-        desc.flops = (mult_per_out_pix + add_per_out_pix) * out_pix
-        desc.total_flops = (mult_per_out_pix * 2 + add_per_out_pix) * out_pix
+        batch_size, input_channels, input_height, input_width = inp[0].size()
+        _, output_channels, output_height, output_width = out[0].size()
+
+        bias_ops = 1 if mod.bias is not None else 0
+
+        num_weight_params = (
+            (mod.weight.data != 0.0).float().sum()
+            if self._ignore_zero
+            else mod.weight.data.nelement()
+        )
+
+        flops = (
+            (
+                num_weight_params * (2 if self._multiply_adds else 1)
+                + bias_ops * output_channels
+            )
+            * output_height
+            * output_width
+            * batch_size
+        )
+
+        desc.flops = flops
+        desc.total_flops += desc.flops
 
     def _linear_hook(
         self,
         mod: Linear,
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
-        params = (
-            {"weight": mod.weight}
-            if mod.bias is None
-            else {"weight": mod.weight, "bias": mod.bias}
+        desc.params = mod.weight.data.numel() + (
+            mod.bias.data.numel() if mod.bias is not None else 0
         )
-        prunable_params = {"weight": mod.weight}
+        desc.prunable_params = mod.weight.data.numel()
+        desc.zeroed_params = desc.prunable_params - mod.weight.data.count_nonzero()
 
-        desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
-
-        mult_per_out_pix = mod.in_features
-        add_per_out_pix = 1 if mod.bias is not None else 0
-        out_pix = float(numpy.prod(out[0].shape[1:]))
-
-        # total flops counts the cost of summing the
-        # multiplications together as well
-        # most implementations and papers do not include this cost
-        desc.flops = (mult_per_out_pix + add_per_out_pix) * out_pix
-        desc.total_flops = (mult_per_out_pix * 2 + add_per_out_pix) * out_pix
+        batch_size = inp[0].size(0) if inp[0].dim() == 2 else 1
+
+        num_weight_params = (
+            (mod.weight.data != 0.0).float().sum()
+            if self._ignore_zero
+            else mod.weight.data.nelement()
+        )
+        weight_ops = num_weight_params * (2 if self._multiply_adds else 1)
+        bias_ops = mod.bias.nelement() if mod.bias is not None else 0
+
+        desc.flops = batch_size * (weight_ops + bias_ops)
+        desc.total_flops += desc.flops
 
     def _bn_hook(
         self,
         mod: Linear,
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
-        params = (
-            {"weight": mod.weight}
-            if mod.bias is None
-            else {"weight": mod.weight, "bias": mod.bias}
+        desc.params = mod.weight.data.numel() + (
+            mod.bias.data.numel() if mod.bias is not None else 0
         )
-        prunable_params = {}
+        desc.prunable_params = mod.weight.data.numel()
+        desc.zeroed_params = desc.prunable_params - mod.weight.data.count_nonzero()
 
-        desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
-
-        # 4 elementwise operations on the output space, just need to add all of them up
-        desc.flops = 4 * float(numpy.prod(out[0].shape[1:]))
-        desc.total_flops = desc.flops
+        desc.flops = 2 * float(inp[0].nelement())
+        desc.total_flops += desc.flops
 
     def _pool_hook(
         self,
         mod: Union[_MaxPoolNd, _AvgPoolNd],
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
         params = {key: val for key, val in mod.named_parameters()}
-        prunable_params = {}
-
         desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
-        desc.stride = mod.stride
+        desc.prunable_params = 0
+        desc.zeroed_params = 0
+
+        batch_size, input_channels, input_height, input_width = inp[0].size()
+        batch_size, output_channels, output_height, output_width = out[0].size()
 
-        flops_per_out_pix = float(numpy.prod(mod.kernel_size) + 1)
-        out_pix = float(numpy.prod(out[0].shape[1:]))
+        if isinstance(mod.kernel_size, numbers.Number) or mod.kernel_size.dim() == 1:
+            kernel_ops = mod.kernel_size * mod.kernel_size
+        else:
+            kernel_ops = numpy.prod(mod.kernel_size)
+        flops = kernel_ops * output_channels * output_height * output_width * batch_size
 
-        desc.flops = flops_per_out_pix * out_pix
-        desc.total_flops = desc.flops
+        desc.flops = flops
+        desc.total_flops += desc.flops
 
     def _adaptive_pool_hook(
         self,
         mod: Union[_MaxPoolNd, _AvgPoolNd],
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
         params = {key: val for key, val in mod.named_parameters()}
-        prunable_params = {}
 
         desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
-        desc.stride = 1
+        desc.prunable_params = 0
+        desc.zeroed_params = 0
 
         stride = tuple(
             inp[0].shape[i] // out[0].shape[i] for i in range(2, len(inp[0].shape))
         )
         kernel_size = tuple(
             inp[0].shape[i] - (out[0].shape[i] - 1) * stride[i - 2]
             for i in range(2, len(inp[0].shape))
         )
-        flops_per_out_pix = float(numpy.prod(kernel_size))
-        out_pix = float(numpy.prod(out[0].shape[1:]))
+        kernel_ops = numpy.prod(kernel_size)
+
+        batch_size, output_channels, output_height, output_width = out[0].size()
+
+        flops = kernel_ops * output_channels * output_height * output_width * batch_size
 
-        desc.flops = flops_per_out_pix * out_pix
-        desc.total_flops = desc.flops
+        desc.flops = flops
+        desc.total_flops += desc.flops
 
     def _activation_hook(
         self,
         mod: Union[_MaxPoolNd, _AvgPoolNd],
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
         params = {key: val for key, val in mod.named_parameters()}
-        prunable_params = {}
 
         desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
+        desc.prunable_params = 0
+        desc.zeroed_params = 0
 
         # making assumption that flops spent is one per element
         # (so swish is counted the same activation ReLU)
-        desc.flops = float(numpy.prod(out[0].shape[1:]))
-        desc.total_flops = desc.flops
+        # FIXME (can't really be fixed). Some standard architectures,
+        # such as a standard ResNet use the same activation (ReLU) object
+        # for all of the places that it appears in the net, which works
+        # fine because it's stateless. But it makes it hard to count per-
+        # batch forward FLOPs correctly, since a single forward pass
+        # through the network is actually multiple passes trhough the
+        # activation. So the per-batch FLOPs are undercounted (slightly,
+        # since activations are very few FLOPs in general), but total
+        # (cumulative) FLOPs are counted correctly.
+        desc.flops = float(inp[0].nelement())
+        desc.total_flops += desc.flops
 
     def _softmax_hook(
         self,
         mod: Union[_MaxPoolNd, _AvgPoolNd],
         inp: Union[Tuple[Tensor, ...], Tensor],
         out: Union[Tuple[Tensor, ...], Tensor],
     ):
         desc, inp, out = self._init_forward_hook(mod, inp, out)
 
         params = {key: val for key, val in mod.named_parameters()}
-        prunable_params = {}
 
         desc.params = sum([val.numel() for val in params.values()])
-        desc.prunable_params = sum([val.numel() for val in prunable_params.values()])
-        desc.zeroed_params = sum(
-            [(val == 0).sum().item() for val in prunable_params.values()]
-        )
-        desc.params_dims = {
-            key: tuple(s for s in val.shape) for key, val in params.items()
-        }
-        desc.prunable_params_dims = {
-            key: tuple(s for s in val.shape) for key, val in prunable_params.items()
-        }
+        desc.prunable_params = 0
+        desc.zeroed_params = 0
 
         flops_per_channel = (
             2 if len(out[0].shape) < 3 else float(numpy.prod(out[0].shape[2:]))
         )
         desc.flops = flops_per_channel * out[0].shape[1]
-        desc.total_flops = desc.flops
+        desc.total_flops += desc.flops
 
     @staticmethod
     def _mod_desc(mod: Module) -> AnalyzedLayerDesc:
         child_descs = []
         for _, child in mod.named_children():
             if child != mod:
                 child_desc = ModuleAnalyzer._mod_desc(child)
```

## sparseml/pytorch/sparsification/pruning/modifier_pruning_layer.py

```diff
@@ -26,15 +26,15 @@
 from sparseml.pytorch.optim.analyzer_pruning import ModulePruningAnalyzer
 from sparseml.pytorch.sparsification.modifier import (
     ModifierProp,
     PyTorchModifierYAML,
     ScheduledModifier,
     ScheduledUpdateModifier,
 )
-from sparseml.pytorch.utils import get_layer, get_prunable_layers, replace_layer
+from sparseml.pytorch.utils import get_layer, get_prunable_layers, swap_modules
 from sparseml.pytorch.utils.logger import BaseLogger
 from sparseml.sparsification import SparsificationTypes
 from sparseml.utils import ALL_PRUNABLE_TOKEN, ALL_TOKEN, validate_str_iterable
 
 
 __all__ = [
     "LayerPruningModifier",
@@ -215,15 +215,15 @@
         return layers
 
     def _check_update_pruning(self, module: Module, epoch: float, steps_per_epoch: int):
         if not self._layers_replaced and (
             epoch >= self.start_epoch or self.start_epoch == -1
         ):
             for name in list(self._layer_modules.keys()):
-                self._layer_modules[name] = replace_layer(module, name, Identity())
+                self._layer_modules[name] = swap_modules(module, name, Identity())
             self._layers_replaced = True
 
         if self._layers_replaced and (epoch >= self.end_epoch and self.end_epoch != -1):
             for name, replaced in self._layer_modules.items():
-                replace_layer(module, name, replaced)
+                swap_modules(module, name, replaced)
                 self._layer_modules[name] = None
             self._layers_replaced = False
```

## sparseml/pytorch/sparsification/pruning/modifier_pruning_rigl.py

```diff
@@ -58,27 +58,35 @@
     :param end_value: final value at t_max
     """
     return end_value + (init_value - end_value) * 0.5 * (
         1 + math.cos(math.pi * t / t_max)
     )
 
 
-def threshold_fraction(tensor: Tensor, fraction: float) -> None:
+def threshold_fraction(
+    tensor: Tensor, fraction: float, set_to_max: bool = False
+) -> None:
     """
     A function returning the tensor with all but topk fraction
     elements set to 0.
 
     :param tensor: the input tensor
-    :param fraction: fraction of nonzero elements
+    :param fraction: fraction of zero elements
     """
-    lookup_idx = round(fraction * tensor.numel())
+    lookup_idx = round((1 - fraction) * tensor.numel())
     if lookup_idx == 0:
-        return tensor
-    threshold, _ = torch.kthvalue(tensor.reshape(-1), k=lookup_idx)
-    return torch.where(tensor > threshold, 1.0, 0.0)
+        return torch.zeros_like(tensor)
+    tensor_shape = tensor.shape
+    vals, idx = tensor.reshape(-1).topk(lookup_idx, largest=True)
+    topk = torch.zeros_like(tensor.reshape(-1))
+    if set_to_max:
+        topk[idx] = torch.finfo(tensor.dtype).max
+    else:
+        topk[idx] = vals
+    return topk.reshape(tensor_shape)
 
 
 @PyTorchModifierYAML()
 class RigLPruningModifier(BaseGradualPruningModifier):
     """
     As described in https://arxiv.org/abs/1911.11134
 
@@ -100,16 +108,16 @@
     |   !RigLPruningModifier
     |       final_sparsity: 0.7
     |       start_epoch: 2.0
     |       end_epoch: 26.0
     |       update_frequency: 4.0
     |       num_grads: 100
     |       params: ["re:.*weight"]
+    |       global_sparsity: False
     |       leave_enabled: True
-    |       global_sparsity: True
     |       mask_type: unstructured
     |       sparsity_strategy: "erdos_renyi_kernel"
     |       init_update_fraction: 0.3
     |       grad_sampler_kwargs:
     |           batch_size: 256
 
     :param final_sparsity: the final sparsity for the param to end with at end_epoch.
@@ -120,26 +128,26 @@
     :param update_frequency: The number of epochs or fraction of epochs to update at
         between start and end
     :param params: A list of full parameter names or regex patterns of names to apply
         pruning to.  Regex patterns must be specified with the prefix 're:'. __ALL__
         will match to all parameters. __ALL_PRUNABLE__ will match to all ConvNd
         and Linear layers' weights. If a sparsity to param mapping is defined by
         final_sparsity, then params should be set to []
+    :param global_sparsity: set True to enable global pruning. If False, pruning will
+        be layer-wise. Must be set to False, as global sparsity is not supported yet.
     :param momentum_buffer_reset: set True to reset momentum buffer
         for pruned weights at every optimizer step, so that reintroduced
         weights start with an empty momentum buffer.
     :param leave_enabled: True to continue masking the weights after end_epoch,
         False to stop masking. Should be set to False if exporting the result
         immediately after or doing some other prune
     :param mask_type: String to define type of sparsity to apply.
         RigL modifier supports only 'unstructured'
     :param num_grads: Number of grads to be collected by the grad sampler for
         recomputing the mask.
-    :param global_sparsity: set True to enable global pruning. If False, pruning will
-        be layer-wise. Default is True
     :param sparsity_strategy: String to define the sparsity distribution. Following
         the original paper one can select one of the 3 options:
         [uniform, erdos_renyi, erdos_renyi_kernel].
     :param init_update_fraction: The initial percentage of the weights updated -
         pruned and regrown
     :param grad_sampler_kwargs: kwargs to override default train dataloader config
             for pruner's gradient sampling.
@@ -153,36 +161,38 @@
         final_sparsity: float,
         start_epoch: float,
         end_epoch: float,
         update_frequency: float,
         params: Union[str, List[str]],
         num_grads: int = 1,
         leave_enabled: bool = True,
+        global_sparsity: bool = False,
         momentum_buffer_reset: bool = True,
-        global_sparsity: bool = True,
         mask_type: str = "unstructured",
         sparsity_strategy: str = "erdos_renyi_kernel",
         init_update_fraction: float = 0.3,
         grad_sampler_kwargs: Optional[Dict[str, Any]] = {},
         **kwargs,
     ):
+        self._sparsity_strategy = sparsity_strategy
         super().__init__(
             params=params,
             final_sparsity=final_sparsity,
             init_sparsity=final_sparsity,
             start_epoch=start_epoch,
             end_epoch=end_epoch,
-            global_sparsity=global_sparsity,
+            global_sparsity=False,
             update_frequency=update_frequency,
             leave_enabled=leave_enabled,
             parent_class_kwarg_names=[],
             **kwargs,
         )
+        # self._sparsity_distribution = self._scorer.get_sparsity_distribution()
         self._mask_type = mask_type
-        self._sparsity_strategy = sparsity_strategy
+        # self._sparsity_strategy = sparsity_strategy
         self._momentum_buffer_reset = momentum_buffer_reset
         self._init_update_fraction = init_update_fraction
         self._grad_sampler_kwargs = grad_sampler_kwargs
         self._num_grads = num_grads
         self._validate()
 
     def _validate(self):
@@ -197,22 +207,21 @@
             raise ValueError(f"{FROM_PARAM_TOKEN} is not supported for RigL Pruning.")
 
         assert (
             self._mask_type in self._supported_masks
         ), f"{self._mask_type} mask_type not supported"
 
         if self._global_sparsity:
+            raise ValueError("global sparsity is not supported for RigL.")
+        else:
             assert self._sparsity_strategy in (
                 "erdos_renyi",
                 "erdos_renyi_kernel",
-            ), "Global sparsity supports only `erdos_renyi`, `erdos_renyi_kernel`"
-        else:
-            assert (
-                self._sparsity_strategy == "uniform"
-            ), "Uniform sparsity supports only `uniform`"
+                "uniform",
+            ), "erdos_renyi, erdos_renyi_kernel, and uniform sparsity are supported."
 
     # Override te optimizer_post_step method to reset the momentum of pruned weights.
     # TODO: this implementation has some  dependencies that may be better handled
     # a different way in the future:
     # First:
     # we rely on the BasePruningModifier method to apply the mask to the weights in its
     # own optimizer_post_step method. If this logic is moved or skipped (as it is today
@@ -327,16 +336,18 @@
         self, epoch: float, steps_per_epoch: int
     ) -> Union[float, List[float]]:
         """
         :param epoch: current epoch
         :param steps_per_epoch: number of steps in each epoch
         :return: sparsity level that should be applied (always final_sparsity)
         """
-        _LOGGER.info(f"RigL applied sparsity {self._final_sparsity}")
-        return [self._final_sparsity for _ in range(len(self.module_masks.layers))]
+
+        self._sparsity_distribution = self._scorer.get_sparsity_distribution()
+        _LOGGER.info(f"RigL applied sparsity {self._sparsity_distribution}")
+        return self._sparsity_distribution
 
     def initialize(
         self,
         module: Module,
         epoch: float = 0,
         loggers: Optional[List[BaseLogger]] = None,
         **kwargs,
@@ -559,21 +570,20 @@
         """
         # We drop and replace mask_update_fraction of nonzero elements
         mask_update_fraction = (1 - param_sparsity) * self._update_fraction
         magn_score = param.abs()
         # Of the existing mask, we keep the top 1-param_sparsity-mask_update_fraction
         # elements by magnitude.
         magn_score = threshold_fraction(
-            magn_score, param_sparsity + mask_update_fraction
+            magn_score, (param_sparsity + mask_update_fraction), set_to_max=True
         )
-        # We fill in the mask by also adding the mask_update_fraction weights
-        # of the ones that are currently masked, using the gradient magnitude
-        # as the criterion.
-        grad_score = param_grad.abs() * magn_score.eq(0)
-        grad_score = threshold_fraction(grad_score, 1 - mask_update_fraction)
+        # For the rest of the unmasked weights, we use the gradient magnitude
+        # as the criterion. These cannot be larger than the magnitude scores,
+        # since those are set to the largest possible value.
+        grad_score = (param_grad.abs()) * magn_score.eq(0)
         score = magn_score + grad_score
         return score
 
     def score_parameters(self) -> List[Tensor]:
         """
         :return: List of Tensors the same shapes as the given Parameters where
             each Parameter's elements are scored according to criterion
```

## sparseml/pytorch/sparsification/pruning/modifier_pruning_topkast.py

```diff
@@ -100,15 +100,14 @@
         update_frequency: Union[int, float],
         params: Union[str, List[str]],
         global_sparsity: bool = True,
         leave_enabled: bool = True,
         mask_type: str = "unstructured",
         active_weight_decay: float = 0.0001,
     ):
-
         self._mask_type = mask_type
 
         super(TopKASTPruningModifier, self).__init__(
             start_epoch=start_epoch,
             end_epoch=end_epoch,
             update_frequency=update_frequency,
             global_sparsity=global_sparsity,
@@ -258,19 +257,17 @@
             self._applied_sparsity = self.get_applied_sparsity_for_epoch(
                 epoch, steps_per_epoch
             )
             self._grad_applied_sparsity = self.get_applied_grad_sparsity_for_epoch(
                 epoch, steps_per_epoch
             )
 
-            self._module_masks.update_param_masks(
-                target=recomputation_sparsity or self._applied_sparsity
-            )
+            self._module_masks.update_param_masks(target=self._applied_sparsity)
             self._grad_module_masks.update_param_masks(
-                target=recomputation_sparsity or self._grad_applied_sparsity
+                target=self._grad_applied_sparsity
             )
             self._sparsity_applied = True
 
         if self.end_pending(epoch, steps_per_epoch):
             self._module_masks.pruning_end(leave_enabled=self._leave_enabled)
             self._grad_module_masks.pruning_end(leave_enabled=False)
 
@@ -379,15 +376,15 @@
         for tracking gradient values between backwards pass and optimizer step if
         optimizer clips gradients
         Weights are decayed according to the following formula:
         For weights active in the forward pass:
           w_i = w_i - w_i * self._active_weight_decay * current learning rate
         For weights inactive in the forward pass but active in
         the backward pass:
-          w_i = w_i - w_i * 1/forward_sparsity * self._active_weight_decay * \
+          w_i = w_i - w_i * 1/(1-forward_sparsity) * self._active_weight_decay * \
                   current learning rate
 
         The reason that we multiply by the learning rate is that in the original
         paper, this weight decay is presented as an L2 regularization
         term in the loss, and so is subject to the learning rate. It also
         keeps the magnitude of this term even with the impact of learing.
         Note that unlike computing L2 as a loss term, this implementation
@@ -412,12 +409,12 @@
                     * self._module_masks._param_masks[i]
                     * param
                 )
 
                 param -= (
                     self._active_weight_decay
                     * lr
-                    * (1 / self.forward_sparsity)
+                    * (1 / (1 - self.forward_sparsity))
                     * (1 - self._module_masks.param_masks[i])
                     * self._grad_module_masks.param_masks[i]
                     * param
                 )
```

## sparseml/pytorch/torchvision/train.py

```diff
@@ -44,14 +44,15 @@
 from torch.utils.data.dataloader import DataLoader, default_collate
 from torchvision.transforms.functional import InterpolationMode
 
 import click
 from sparseml.optim.helpers import load_recipe_yaml_str
 from sparseml.pytorch.models.registry import ModelRegistry
 from sparseml.pytorch.optim import ScheduledModifierManager
+from sparseml.pytorch.optim.analyzer_module import ModuleAnalyzer
 from sparseml.pytorch.torchvision import presets, transforms, utils
 from sparseml.pytorch.torchvision.sampler import RASampler
 from sparseml.pytorch.utils.helpers import (
     default_device,
     download_framework_model_by_recipe_type,
     torch_distributed_zero_first,
 )
@@ -89,26 +90,34 @@
     device: torch.device,
     epoch: int,
     args,
     log_metrics_fn: Callable[[str, utils.MetricLogger, int, int], None],
     manager=None,
     model_ema=None,
     scaler=None,
+    flops_analyzer=None,
 ) -> utils.MetricLogger:
     accum_steps = args.gradient_accum_steps
 
     model.train()
     metric_logger = utils.MetricLogger(_LOGGER, delimiter="  ")
     metric_logger.add_meter("lr", utils.SmoothedValue(window_size=1, fmt="{value}"))
     metric_logger.add_meter(
         "imgs_per_sec", utils.SmoothedValue(window_size=10, fmt="{value}")
     )
     metric_logger.add_meter("loss", utils.SmoothedValue(window_size=accum_steps))
     metric_logger.add_meter("acc1", utils.SmoothedValue(window_size=accum_steps))
     metric_logger.add_meter("acc5", utils.SmoothedValue(window_size=accum_steps))
+    if flops_analyzer is not None:
+        metric_logger.add_meter(
+            "flops_per_epoch", utils.SmoothedValue(window_size=1, fmt="{value}")
+        )
+        metric_logger.add_meter(
+            "total_flops", utils.SmoothedValue(window_size=1, fmt="{value}")
+        )
 
     steps_accumulated = 0
     num_optim_steps = 0
 
     # initial zero grad for gradient accumulation
     optimizer.zero_grad()
 
@@ -174,14 +183,18 @@
         )
         metric_logger.meters["acc5"].update(
             acc5.item(), n=batch_size, total=num_correct_5
         )
         metric_logger.meters["imgs_per_sec"].update(
             batch_size / (time.time() - start_time)
         )
+        if flops_analyzer is not None:
+            layer_sparsity = ModuleAnalyzer._mod_desc(model)
+            metric_logger.meters["total_flops"].update(layer_sparsity.total_flops)
+            metric_logger.meters["flops_per_epoch"].update(layer_sparsity.flops)
 
         if args.eval_steps is not None and num_optim_steps % args.eval_steps == 0:
             eval_metrics = evaluate(model, criterion, data_loader_test, device)
             model.train()
             log_metrics_fn("Test", eval_metrics, epoch, num_optim_steps)
 
         if num_optim_steps % args.logging_steps == 0:
@@ -694,14 +707,17 @@
 
     best_top1_acc = -math.inf
 
     _LOGGER.info("Start training")
 
     start_time = time.time()
     max_epochs = manager.max_epochs if manager is not None else args.epochs
+    flops_analyzer = None
+    if args.track_flops:
+        flops_analyzer = ModuleAnalyzer(model, enabled=True)
     for epoch in range(args.start_epoch, max_epochs):
         if args.distributed:
             train_sampler.set_epoch(epoch)
         if manager is not None and manager.qat_active(epoch=epoch):
             if scaler is not None:
                 scaler._enabled = False
             model_ema = None
@@ -715,14 +731,15 @@
             device,
             epoch,
             args,
             log_metrics,
             manager=manager,
             model_ema=model_ema,
             scaler=scaler,
+            flops_analyzer=flops_analyzer,
         )
         log_metrics("Train", train_metrics, epoch, steps_per_epoch)
 
         if lr_scheduler:
             lr_scheduler.step()
 
         eval_metrics = evaluate(model, criterion, data_loader_test, device)
@@ -1277,14 +1294,23 @@
     nargs=3,
     type=float,
     help=(
         "RGB standard-deviation values used to normalize input RGB values; "
         "Note: Will use ImageNet values if not specified."
     ),
 )
+@click.option(
+    "--track-flops",
+    is_flag=True,
+    default=False,
+    help=(
+        "If true, estimate FLOPs (floating point operations) of forward "
+        "passes during training."
+    ),
+)
 @click.pass_context
 def cli(ctx, **kwargs):
     """
     PyTorch classification training
     """
     if len(ctx.args) > 0:
         raise ValueError(_ARGUMENTS_ERROR.format(ctx.args))
```

## sparseml/pytorch/utils/helpers.py

```diff
@@ -81,20 +81,20 @@
     "tensors_export",
     "tensor_density",
     "tensor_sparsity",
     "tensor_list_sparsity",
     "tensor_sample",
     "mask_difference",
     "get_layer",
-    "replace_layer",
     "get_terminal_layers",
     "get_conv_layers",
     "get_linear_layers",
     "get_prunable_layers",
     "get_quantizable_layers",
+    "swap_modules",
     "get_named_layers_and_params_by_regex",
     "any_str_or_regex_matches_param_name",
     "NamedLayerParam",
     "get_layer_param",
     "set_deterministic_seeds",
     "torch_distributed_zero_first",
     "thin_model_from_checkpoint",
@@ -721,39 +721,14 @@
 
     for name in layers:
         layer = layer.__getattr__(name)
 
     return layer
 
 
-def replace_layer(
-    module: Module,
-    name: str,
-    replace: Module,
-) -> Module:
-    """
-    General function to replace a layer in a module with the given new one.
-
-    :param module: the module to replace the layer in
-    :param name: the name of the layer to replace the activation for
-    :param replace: the module to replace the layer with
-    :return: the original layer that was replaced
-    """
-    parent = module
-    sections = name.split(".")
-
-    for sec in sections[:-1]:
-        parent = parent.__getattr__(sec)
-
-    cur = parent.__getattr__(sections[-1])
-    parent.__setattr__(sections[-1], replace)
-
-    return cur
-
-
 def get_terminal_layers(module: Module) -> Dict[str, Module]:
     """
     :param module: the module to grab all terminal layers for
     :return: a list of all of the terminal layers in a model
         (ie not containers; so convs, linears, activations, etc)
     """
     terminal = {}
@@ -1244,7 +1219,42 @@
 
     # register a hook for each module of interest, will be triggered in exeuction order
     handles = [subset[name].register_forward_hook(exe_input(name)) for name in subset]
     layer(an_input, **kwargs)
     for h in handles:
         h.remove()
     return order
+
+
+def swap_modules(
+    module: torch.nn.Module, submodule_name: str, submodule_to_replace: torch.nn.Module
+) -> torch.nn.Module:
+    """
+    Iteratively unfold the submodules of the module according to the submodule_name
+    to eventually replace the leaf submodule (accessed from the module through the
+    submodule_name) with the submodule_to_replace.
+
+    E.g
+    ```
+    swap_modules(module=Model,
+                 module_name="layers.0.sublayer",
+                 module_to_replace=ReplaceModule
+                 )
+    ```
+    this will iteratively traverse through the submodules
+    'layers' -> '0' -> to eventually replace 'sublayer' with ReplaceModule
+
+    :param module: the module to replace with the module_to_replace
+    :param submodule_name: the name of the module to replace
+    :param submodule_to_replace: the module to replace the module with
+    :return: the replaced module
+    """
+    parent = module
+    sections = submodule_name.split(".")
+
+    for sec in sections[:-1]:
+        parent = parent.__getattr__(sec)
+
+    cur = parent.__getattr__(sections[-1])
+    parent.__setattr__(sections[-1], submodule_to_replace)
+
+    return cur
```

## sparseml/pytorch/utils/sparsification.py

```diff
@@ -93,15 +93,15 @@
     @property
     def params_sparse(self) -> int:
         """
         :return: total number of sparse (0) trainable parameters in the model
         """
         return sum(
             round(tensor_sparsity(param).item() * torch.numel(param))
-            for param in self.trainable_params
+            for param in tqdm(self.trainable_params, desc="Calculating model sparsity")
         )
 
     @property
     def params_sparse_percent(self) -> float:
         """
         :return: percent of sparsified parameters in the entire model
         """
```

## sparseml/transformers/__init__.py

```diff
@@ -13,49 +13,25 @@
 # limitations under the License.
 
 """
 Tools for integrating SparseML with transformers training flows
 """
 
 # flake8: noqa
-
-import logging as _logging
-
 from sparseml.analytics import sparseml_analytics as _analytics
+from sparseml.transformers.base import check_transformers_install
 
-
-try:
-    import datasets as _datasets
-    import transformers as _transformers
-except ImportError:
-    raise ImportError("Please install sparseml[transformers] to use this pathway")
-
-
+check_transformers_install()
 _analytics.send_event("python__transformers__init")
 
 
-_LOGGER = _logging.getLogger(__name__)
-
-
-def _check_transformers_install():
-    # check for NM integration in transformers version
-    import transformers as _transformers
-
-    if not getattr(_transformers, "NM_INTEGRATED", False):
-        message = (
-            "****************************************************************\n"
-            "WARNING: It appears that the Neural Magic fork of Transformers is not installed!\n"
-            "This is CRITICAL for the proper application of quantization in SparseML flows.\n\n"
-            "To resolve this, please run: `pip uninstall transformers;pip install nm-transformers`\n"
-            "Failing to do so is UNSUPPORTED and may significantly affect model performance.\n"
-            "****************************************************************"
-        )
-        _LOGGER.warning(message)
-
-
-_check_transformers_install()
-
 # isort: skip_file
 # (import order matters for circular import avoidance)
 from .utils import *
+from .sparsification import (
+    SparseAutoModel,
+    SparseAutoModelForCausalLM,
+    SparseAutoConfig,
+    SparseAutoTokenizer,
+)
 from .export import *
 from .finetune import *
```

## sparseml/transformers/export.py

```diff
@@ -84,17 +84,16 @@
 from transformers import TrainingArguments as HFTrainingArgs
 from transformers.tokenization_utils_base import PaddingStrategy
 
 from sparseml.optim import parse_recipe_variables
 from sparseml.pytorch.opset import TORCH_DEFAULT_ONNX_OPSET
 from sparseml.pytorch.optim import ScheduledModifierManager
 from sparseml.pytorch.utils import export_onnx
-from sparseml.transformers import SparseAutoTokenizer
+from sparseml.transformers import SparseAutoModel, SparseAutoTokenizer
 from sparseml.transformers.sparsification import Trainer
-from sparseml.transformers.utils import SparseAutoModel
 from sparsezoo.utils.onnx import EXTERNAL_ONNX_DATA_NAME
 
 
 __all__ = ["export_transformer_to_onnx", "load_task_model"]
 
 MODEL_ONNX_NAME = "model.onnx"
 MANDATORY_DEPLOYMENT_FILES = [
```

## sparseml/transformers/masked_language_modeling.py

```diff
@@ -50,16 +50,20 @@
     HfArgumentParser,
     set_seed,
 )
 from transformers.trainer_utils import get_last_checkpoint
 from transformers.utils.versions import require_version
 
 from sparseml.pytorch.utils.distributed import record
-from sparseml.transformers.sparsification import Trainer, TrainingArguments
-from sparseml.transformers.utils import SparseAutoModel, get_shared_tokenizer_src
+from sparseml.transformers.sparsification import (
+    SparseAutoModel,
+    Trainer,
+    TrainingArguments,
+)
+from sparseml.transformers.sparsification.sparse_model import get_shared_tokenizer_src
 
 
 metadata_args = [
     "per_device_train_batch_size",
     "per_device_eval_batch_size",
     "fp16",
 ]
```

## sparseml/transformers/question_answering.py

```diff
@@ -43,18 +43,19 @@
 )
 from transformers.trainer_utils import get_last_checkpoint
 from transformers.utils.versions import require_version
 
 from sparseml.pytorch.utils.distributed import record
 from sparseml.transformers.sparsification import (
     QuestionAnsweringTrainer,
+    SparseAutoModel,
     TrainingArguments,
     postprocess_qa_predictions,
 )
-from sparseml.transformers.utils import SparseAutoModel, get_shared_tokenizer_src
+from sparseml.transformers.sparsification.sparse_model import get_shared_tokenizer_src
 
 
 # You can also adapt this script on your own question answering task.
 # Pointers for this are left as comments.
 
 
 require_version(
```

## sparseml/transformers/text_classification.py

```diff
@@ -48,20 +48,21 @@
     default_data_collator,
     set_seed,
 )
 from transformers.trainer_utils import get_last_checkpoint
 from transformers.utils.versions import require_version
 
 from sparseml.pytorch.utils.distributed import record
-from sparseml.transformers.sparsification import Trainer, TrainingArguments
-from sparseml.transformers.utils import (
+from sparseml.transformers.sparsification import (
     SparseAutoModel,
-    get_shared_tokenizer_src,
-    multi_label_precision_recall_f1,
+    Trainer,
+    TrainingArguments,
 )
+from sparseml.transformers.sparsification.sparse_model import get_shared_tokenizer_src
+from sparseml.transformers.utils import multi_label_precision_recall_f1
 
 
 require_version(
     "datasets>=1.18.0",
     "To fix: pip install -r examples/pytorch/text-classification/requirements.txt",
 )
```

## sparseml/transformers/token_classification.py

```diff
@@ -47,16 +47,20 @@
     PreTrainedTokenizerFast,
     set_seed,
 )
 from transformers.trainer_utils import get_last_checkpoint
 from transformers.utils.versions import require_version
 
 from sparseml.pytorch.utils.distributed import record
-from sparseml.transformers.sparsification import Trainer, TrainingArguments
-from sparseml.transformers.utils import SparseAutoModel, get_shared_tokenizer_src
+from sparseml.transformers.sparsification import (
+    SparseAutoModel,
+    Trainer,
+    TrainingArguments,
+)
+from sparseml.transformers.sparsification.sparse_model import get_shared_tokenizer_src
 
 
 require_version(
     "datasets>=1.18.0",
     "To fix: pip install -r examples/pytorch/token-classification/requirements.txt",
 )
```

## sparseml/transformers/finetune/model_args.py

```diff
@@ -26,14 +26,20 @@
         metadata={
             "help": (
                 "A pretrained model or a string as a path to pretrained model, "
                 "sparsezoo stub, or model identifier from huggingface.co/models."
             )
         },
     )
+    distill_teacher: Optional[str] = field(
+        default=None,
+        metadata={
+            "help": "Teacher model (a trained text generation model)",
+        },
+    )
     config_name: Optional[str] = field(
         default=None,
         metadata={
             "help": "Pretrained config name or path if not the same as model_name"
         },
     )
     tokenizer: Optional[str] = field(
```

## sparseml/transformers/finetune/runner.py

```diff
@@ -27,25 +27,28 @@
 from sparseml.core.recipe import Recipe, StageRunType
 from sparseml.pytorch.model_load.helpers import (
     get_completed_stages,
     get_session_model,
     save_completed_stages,
     save_model_and_recipe,
 )
+from sparseml.pytorch.utils import tensors_to_device
 from sparseml.transformers.finetune.data import TextGenerationDataset
 from sparseml.transformers.finetune.data.data_args import DataTrainingArguments
 from sparseml.transformers.finetune.data.data_helpers import (
     format_calibration_data,
     make_dataset_splits,
 )
 from sparseml.transformers.finetune.model_args import ModelArguments
 from sparseml.transformers.finetune.training_args import TrainingArguments
-from sparseml.utils.fsdp.context import summon_full_params_context
-from sparseml.utils.fsdp.helpers import is_fsdp_model, unwrap_and_export_model
-from sparseml.utils.pytorch import qat_active
+from sparseml.utils.fsdp.helpers import (
+    find_and_move_state_dicts_to_cpu,
+    is_fsdp_model,
+    unwrap_and_export_model,
+)
 
 
 _LOGGER: logging.Logger = logging.getLogger(__name__)
 
 
 class StageRunner:
     """
@@ -153,36 +156,49 @@
             num_calibration_samples=self._data_args.num_calibration_samples,
             accelerator=self.trainer.accelerator,
         )
 
         # if we don't run a forward pass after initializing the FSDP model for the
         # first time, calls to summon_full_params will fail ¯\_(ツ)_/¯
         dummy_inp = dict(next(iter(calib_data)))
+        model_device = next(self.trainer.model.parameters()).device
+        dummy_inp = tensors_to_device(dummy_inp, model_device)
         with torch.no_grad():
             self.trainer.model(**dummy_inp)
-        torch.cuda.empty_cache()
+        self.trainer.accelerator.wait_for_everyone()
 
         self.trainer.one_shot(calib_data, stage=stage)
 
         if is_fsdp_model(self.trainer.model):
             try:
                 self.trainer.save_model(output_dir=self._output_dir, _is_oneshot=True)
             except AssertionError:
                 # fallback to this in the case of quantization
                 unwrap_and_export_model(
                     model=self.trainer.model,
                     accelerator=self.trainer.accelerator,
                     output_dir=self._output_dir,
                     tokenizer=self.tokenizer,
                 )
+                # only allow the main process move the state
+                # dicts to cpu
+                if self.trainer.accelerator.is_main_process:
+                    # assuming quantization is the last step
+                    # we no longer need the original model
+                    # and can safely delete it to save memory
+                    del self.trainer.model
+                    find_and_move_state_dicts_to_cpu(self._output_dir)
+
         else:
             save_model_and_recipe(
                 model=self.trainer.model,
                 save_path=self._output_dir,
                 tokenizer=self.tokenizer,
+                save_safetensors=self._training_args.save_safetensors,
+                save_compressed=self._training_args.save_compressed,
             )
 
     def train(self, checkpoint: str, stage: Optional[str] = None):
         """
         Run trainer's training loop on train_dataset, saving the resulting model to
         output_dir
 
@@ -280,19 +296,13 @@
                 completed_stages.append(stage_name)
                 save_completed_stages(self._output_dir, completed_stages)
 
             # setup for next stage
             session = session_manager.active_session()
             session.reset_stage()
 
-            # log model sparsity
-            with summon_full_params_context(self.trainer.model):
-                if self.trainer.accelerator.is_main_process:
-                    if not qat_active(self.trainer.model):
-                        self.trainer.log_model_sparsification()
-
             # synchronize and clean up memory
             self.trainer.accelerator.wait_for_everyone()
             self.trainer.model = get_session_model()
             torch.cuda.empty_cache()
             self.trainer.accelerator.free_memory()
             self.trainer.accelerator.wait_for_everyone()
```

## sparseml/transformers/finetune/session_mixin.py

```diff
@@ -36,14 +36,15 @@
 from sparseml.pytorch.utils import LoggerManager, ModuleSparsificationInfo
 from sparseml.transformers.finetune.callbacks import (
     DisableHalfPrecisionCallback,
     TrainingLoopCallbacks,
 )
 from sparseml.utils.fsdp.context import summon_full_params_context
 from sparseml.utils.fsdp.helpers import is_fsdp_model, save_pretrained_fsdp
+from sparseml.utils.pytorch import qat_active
 
 
 __all__ = [
     "SessionManagerMixIn",
 ]
 
 _LOGGER = logging.getLogger(__name__)
@@ -133,15 +134,15 @@
         if session.lifecycle.initialized_ or session.lifecycle.finalized:
             return False
 
         orig_state_dict = self.model.state_dict()
         train_data = self.get_train_dataloader()
 
         self.accelerator.wait_for_everyone()
-        with summon_full_params_context(self.model):
+        with summon_full_params_context(self.model, offload_to_cpu=True):
             session_manager.initialize(
                 model=self.model,
                 teacher_model=self.teacher,  # TODO: what about for self/disable?
                 recipe=self.recipe,
                 recipe_stage=stage,
                 recipe_args=self.recipe_args,
                 framework=Framework.pytorch,
@@ -366,17 +367,21 @@
         self.accelerator.wait_for_everyone()
         output = super().train(*args, **kwargs)
         self.accelerator.wait_for_everyone()
         self.finalize_session()
 
         self.accelerator.wait_for_everyone()
 
-        # Need to gather parameters across the GPUs before accessing layer weights
-        with summon_full_params_context(self.model):
-            self.log_model_sparsification()
+        # log model sparsity
+        with summon_full_params_context(self.model, offload_to_cpu=True):
+            if self.accelerator.is_main_process:
+                if not qat_active(self.model):
+                    self.log_model_sparsification()
+
+        self.accelerator.wait_for_everyone()
 
         return output
 
     def evaluate(self, *args, **kwargs):
         """
         Run a sparsification evaluation cycle.
         Runs initialize_structure for the sparse session before calling
@@ -422,52 +427,63 @@
         :param stage: which stage of the recipe to run, or None to run whole recipe
         :param calib_data: dataloader of calibration data
         """
         session_manager.apply(
             framework=Framework.pytorch,
             recipe=self.recipe,
             recipe_stage=stage,
+            recipe_args=self.recipe_args,
             model=self.model,
             calib_data=calib_data,
             start=-1,
             copy_data=False,
             accelerator=self.accelerator,
         )
 
+        # log model sparsity
+        with summon_full_params_context(self.model, offload_to_cpu=True):
+            if self.accelerator.is_main_process:
+                if not qat_active(self.model):
+                    self.log_model_sparsification()
+
         self.accelerator.wait_for_everyone()
 
     def save_model(
         self, output_dir: Optional[str] = None, _internal_call=False, _is_oneshot=False
     ):
         """
         Override of the save_model function and expects it to exist in the parent.
         Calls into super() to save the model and additionally saves any recipes
         that were used with the model within the model folder.
 
         :param output_dir: the path to save the recipes into
         """
-        self._check_super_defined("save_model")
-        super().save_model(output_dir=output_dir, _internal_call=_internal_call)
-
         if session_manager.active_session() is None:
             return  # nothing to save
 
         if output_dir is None:
             output_dir = self.args.output_dir
 
-        # don't export the gathered model on checkpoints
-        if is_fsdp_model(self.model) and not _internal_call:
+        if not is_fsdp_model(self.model):
+            self.model.save_pretrained(
+                output_dir,
+                save_compressed=self.args.save_compressed,
+                safe_serialization=self.args.save_safetensors,
+            )
+        else:  # FSDP model
             save_pretrained_fsdp(
                 model=self.model,
                 accelerator=self.accelerator,
                 output_dir=output_dir,
+                save_compressed=self.args.save_compressed,
                 save_safetensors=self.metadata.get("save_safetensors", False),
             )
 
         self.save_state()
+        self.tokenizer.save_pretrained(output_dir)
         if not _is_oneshot:  # optimizer/scheduler not relevant to one-shot
             self.save_optimizer_and_scheduler(output_dir)
 
         if not self.recipe:
             return
 
         # save recipe, will contain modifiers from the model's original recipe as well
@@ -510,14 +526,16 @@
         """
         self.model.to("cpu")
         self.model = self.accelerator.prepare(self.model)
         self.accelerator.wait_for_everyone()
 
         if self.teacher is not None:
             self.teacher.to("cpu")
+            for n, p in self.teacher.named_parameters():
+                p.requires_grad = False
             self.teacher = self.accelerator.prepare(self.teacher)
             self.teacher.eval()
             self.accelerator.wait_for_everyone()
 
     def _extract_metadata(
         self,
         metadata_args: List[str],
```

## sparseml/transformers/finetune/text_generation.py

```diff
@@ -36,15 +36,18 @@
 )
 from sparseml.transformers import SparseAutoTokenizer
 from sparseml.transformers.finetune.data.data_args import DataTrainingArguments
 from sparseml.transformers.finetune.model_args import ModelArguments
 from sparseml.transformers.finetune.runner import StageRunner
 from sparseml.transformers.finetune.trainer import Trainer
 from sparseml.transformers.finetune.training_args import TrainingArguments
-from sparseml.transformers.utils import SparseAutoModel, get_shared_tokenizer_src
+from sparseml.transformers.sparsification.sparse_model import (
+    SparseAutoModel,
+    get_shared_tokenizer_src,
+)
 from sparseml.transformers.utils.helpers import detect_last_checkpoint
 
 
 _LOGGER: logging.Logger = logging.getLogger(__name__)
 
 metadata_args = [
     "per_device_train_batch_size",
@@ -120,19 +123,20 @@
     )
     if not kwargs:
         model_args, data_args, training_args = parser.parse_args_into_dataclasses()
     else:
         model_args, data_args, training_args = parser.parse_dict(kwargs)
 
     if training_args.recipe_args is not None:
-        arg_dict = {}
-        for recipe_arg in training_args.recipe_args:
-            key, value = recipe_arg.split("=")
-            arg_dict[key] = value
-        training_args.recipe_args = arg_dict
+        if not isinstance(training_args.recipe_args, dict):
+            arg_dict = {}
+            for recipe_arg in training_args.recipe_args:
+                key, value = recipe_arg.split("=")
+                arg_dict[key] = value
+            training_args.recipe_args = arg_dict
 
     # when set to true in FSDP mode this causes issues, the model arguments show up
     # as *args and **kwargs so all columns get removed
     training_args.remove_unused_columns = False
 
     return model_args, data_args, training_args
 
@@ -151,18 +155,18 @@
         model_args.config_name if model_args.config_name else model_path,
         cache_dir=model_args.cache_dir,
         revision=model_args.model_revision,
         use_auth_token=True if model_args.use_auth_token else None,
     )
     teacher_config = (
         AutoConfig.from_pretrained(
-            training_args.distill_teacher,
+            model_args.distill_teacher,
             use_auth_token=True if model_args.use_auth_token else None,
         )
-        if training_args.distill_teacher
+        if model_args.distill_teacher
         else None
     )
 
     model_path = (
         last_checkpoint or model_args.model
         if hasattr(model_args, "model")
         else model_args.model_name_or_path
@@ -204,19 +208,19 @@
         model_name_or_path=model_path,
         sequence_length=None,  # use model default
         **model_kwargs,
     )
 
     teacher = (
         SparseAutoModel.text_generation_from_pretrained(
-            model_name_or_path=training_args.distill_teacher,
+            model_name_or_path=model_args.distill_teacher,
             sequence_length=None,  # use model default
             **teacher_kwargs,
         )
-        if training_args.distill_teacher is not None
+        if model_args.distill_teacher is not None
         else None
     )
 
     return teacher, model_path, model
 
 
 def initialize_tokenizer_from_path(model_args, model, teacher):
@@ -285,15 +289,15 @@
         f"distributed training: {bool(training_args.local_rank != -1)}, "
         f"16-bits training: {training_args.fp16}"
     )
     _LOGGER.info(f"Training/evaluation parameters {training_args}")
 
     # Detecting last checkpoint.
     last_checkpoint = None
-    teacher = None
+    teacher = model_args.distill_teacher
     model_path = None
     model = model_args.model
     # Load tokenizer
     # distill TODO: support for different tokenizer for teacher?
     tokenizer = model_args.tokenizer
 
     if isinstance(model, str) or isinstance(model, PosixPath):
@@ -304,18 +308,14 @@
 
     if teacher is not None:
         teacher.eval()
 
     if isinstance(tokenizer, str) or tokenizer is None:
         tokenizer = initialize_tokenizer_from_path(model_args, model, teacher)
 
-    # setup new SparseSession unless user requests otherwise
-    if training_args.clear_sparse_session:
-        session_manager.create_session()
-        session_manager.active_session().reset()
     session_manager.pre_initialize_structure(model=model, framework=Framework.pytorch)
 
     # intialize session manager
     apply_recipe_structure_to_model(model, None, model_path)
 
     # Load datasets
     stage_runner = StageRunner(
@@ -376,10 +376,14 @@
     if training_args.do_eval:
         stage_runner.evaluate()
 
     # Prediction
     if training_args.do_predict:
         stage_runner.predict()
 
+    # Clean up the SparseSession before exit if requested
+    if training_args.clear_sparse_session:
+        session_manager.active_session().reset()
+
 
 if __name__ == "__main__":
     apply()
```

## sparseml/transformers/finetune/training_args.py

```diff
@@ -28,20 +28,14 @@
 
     :param best_model_after_epoch (`int`, *optional*, defaults to None):
         The epoch after which best model will be saved; used in conjunction
         with `load_best_model_at_end` and `metric_for_best_model` training
         arguments
     """
 
-    distill_teacher: Optional[str] = field(
-        default=None,
-        metadata={
-            "help": "Teacher model (a trained text generation model)",
-        },
-    )
     best_model_after_epoch: int = field(
         default=None,
         metadata={"help": "Epoch after which best model will be saved."},
     )
     recipe: Optional[str] = field(
         default=None,
         metadata={
@@ -56,14 +50,18 @@
         metadata={
             "help": (
                 "List of recipe arguments to evaluate, of the format key1=value1 "
                 "key2=value2"
             )
         },
     )
+    save_compressed: Optional[bool] = field(
+        default=False,
+        metadata={"help": "Whether to compress sparse models during save"},
+    )
     do_oneshot: Optional[bool] = field(
         default=False,
         metadata={"help": "Whether to run one-shot calibration"},
     )
     run_stages: Optional[bool] = field(
         default=False, metadata={"help": "Whether to trigger recipe stage by stage"}
     )
```

## sparseml/transformers/finetune/data/__init__.py

```diff
@@ -12,14 +12,15 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 # flake8: noqa
 
 from .base import TextGenerationDataset
 from .c4 import C4Dataset
+from .cnn_dailymail import CNNDailyMailDataset
 from .custom import CustomDataset
 from .evolcodealpaca import EvolCodeAlpacaDataset
 from .gsm8k import GSM8KDataset
 from .open_platypus import OpenPlatypusDataset
 from .ptb import PtbDataset
 from .ultrachat_200k import UltraChatDataset
 from .wikitext import WikiTextDataset
```

## sparseml/transformers/finetune/data/custom.py

```diff
@@ -13,14 +13,18 @@
 # limitations under the License.
 from copy import deepcopy
 from typing import Dict, List, Union
 
 from datasets.dataset_dict import Dataset, DatasetDict
 
 from sparseml.transformers.finetune.data import TextGenerationDataset
+from sparseml.transformers.utils.preprocessing_functions import (
+    PreprocessingFunctionRegistry,
+)
+from sparsezoo.utils.helpers import import_from_path
 
 
 @TextGenerationDataset.register(name="custom", alias=["json", "csv"])
 class CustomDataset(TextGenerationDataset):
     """
     Child text generation class for custom local dataset supporting load
     for csv and json
@@ -51,17 +55,29 @@
             # user passed in an already instantiated dataset, just use it directly
             raw_dataset = dataset
         else:
             # dataset must be loaded from file or HF Hub
             raw_dataset = super().get_raw_dataset()
 
         if self.preprocessing_func is not None:
+
+            if callable(self.preprocessing_func):
+                func = self.preprocessing_func
+            elif ":" in self.preprocessing_func:
+                # load func_name from "/path/to/file.py:func_name"
+                func = import_from_path(self.preprocessing_func)
+            else:
+                # load from the registry
+                func = PreprocessingFunctionRegistry.get_value_from_registry(
+                    name=self.preprocessing_func
+                )
+
             raw_dataset = self.map(
                 raw_dataset,
-                function=self.preprocessing_func,
+                function=func,
                 batched=False,
                 num_proc=self.data_args.preprocessing_num_workers,
                 desc="Applying custom func to the custom dataset",
             )
 
         self.remove_columns = (
             self.remove_columns or self.get_remove_columns_from_dataset(raw_dataset)
@@ -78,14 +94,15 @@
 
         return raw_dataset
 
     def get_remove_columns_from_dataset(
         self, raw_dataset: Union[DatasetDict, Dataset]
     ) -> List[str]:
         """Remove redandant columns from the dataset for processing"""
+
         remove_columns = raw_dataset.column_names
         if isinstance(remove_columns, Dict):
             remove_columns = raw_dataset[list(raw_dataset.keys())[0]].column_names
 
         remove_columns = set(remove_columns)
         if self.text_column in remove_columns:
             remove_columns.remove(self.text_column)
```

## sparseml/transformers/finetune/data/data_args.py

```diff
@@ -51,16 +51,23 @@
     )
 
     remove_columns: Union[None, str, List] = field(
         default=None,
         metadata={"help": "Column names to remove after preprocessing custom datasets"},
     )
 
-    preprocessing_func: Optional[Callable] = field(
-        default=None, metadata={"help": "The preprcessing function to apply"}
+    preprocessing_func: Union[None, str, Callable] = field(
+        default=None,
+        metadata={
+            "help": (
+                "The preprocessing function to apply ",
+                "or the preprocessing func name in "
+                "src/sparseml/transformers/utils/preprocessing_functions.py",
+            )
+        },
     )
 
 
 @dataclass
 class DataTrainingArguments(CustomDataTrainingArguments):
     """
     Arguments pertaining to what data we are going to input our model for
```

## sparseml/transformers/finetune/data/data_helpers.py

```diff
@@ -85,14 +85,15 @@
     Load the raw dataset from Hugging Face, using cached copy if available
 
     :param cache_dir: disk location to search for cached dataset
     :param streaming: True to stream data from Hugging Face, otherwise download
     :return: the requested dataset
 
     """
+
     raw_datasets = load_dataset(
         data_args.dataset,
         data_args.dataset_config_name,
         cache_dir=cache_dir,
         streaming=streaming,
         **kwargs,
     )
@@ -121,14 +122,15 @@
     # handles case where all splits are contained in a single dataset
     if "all" in tokenized_datasets and len(tokenized_datasets) == 1:
         tokenized_datasets = tokenized_datasets.get("all")
         if isinstance(tokenized_datasets, Dataset):
             tokenized_datasets = {"train": tokenized_datasets}
 
     train_split = eval_split = predict_split = calib_split = None
+
     if do_train:
         if "train" not in tokenized_datasets:
             raise ValueError("--do_train requires a train dataset")
         train_split = tokenized_datasets["train"]
     if do_eval:
         if "validation" not in tokenized_datasets:
             raise ValueError("--do_eval requires a validation dataset")
@@ -214,8 +216,39 @@
                 for filename in os.listdir(dir_path):
                     if filename.endswith(ext):
                         file_path = os.path.join(dir_path, filename)
                         dir_dataset.append(file_path)
                 if dir_dataset:
                     data_files[dir_name] = dir_dataset
 
+    return transform_dataset_keys(data_files)
+
+
+def transform_dataset_keys(data_files: Dict[str, Any]):
+    """
+    Transform dict keys to `train`, `val` or `test` for the given input dict
+    if matches exist with the existing keys. Note that there can only be one
+    matching file name.
+    Ex. Folder(train_eval.json)          -> Folder(train.json)
+        Folder(train1.json, train2.json) -> Same
+
+    :param data_files: The dict where keys will be transformed
+    """
+    keys = set(data_files.keys())
+
+    def transform_dataset_key(candidate: str) -> None:
+        for key in keys:
+            if candidate in key:
+                if key == candidate:
+                    return
+                val = data_files.pop(key)
+                data_files[candidate] = val
+
+    def do_transform(candidate: str) -> bool:
+        return sum(candidate in key for key in keys) == 1
+
+    dataset_keys = ("train", "val", "test")
+    for dataset_key in dataset_keys:
+        if do_transform(dataset_key):
+            transform_dataset_key(dataset_key)
+
     return data_files
```

## sparseml/transformers/sparsification/__init__.py

```diff
@@ -16,9 +16,12 @@
 Objects, classes, and methods for applying sparsification algorithms to
 Hugging Face transformers flows
 """
 
 # flake8: noqa
 
 from .question_answering import *
+from .sparse_config import *
+from .sparse_model import *
+from .sparse_tokenizer import *
 from .trainer import *
 from .training_args import *
```

## sparseml/transformers/sparsification/obcq/export.py

```diff
@@ -79,16 +79,15 @@
 import sparseml.core.session as session_manager
 from sparseml.optim import parse_recipe_variables
 from sparseml.pytorch.model_load.helpers import (
     RECIPE_FILE_NAME,
     apply_recipe_structure_to_model,
 )
 from sparseml.pytorch.utils import export_onnx
-from sparseml.transformers import SparseAutoTokenizer
-from sparseml.transformers.utils import SparseAutoModel
+from sparseml.transformers import SparseAutoModel, SparseAutoTokenizer
 from sparsezoo.utils.onnx import EXTERNAL_ONNX_DATA_NAME
 
 
 __all__ = ["export_transformer_to_onnx", "load_task_model"]
 
 MODEL_ONNX_NAME = "model.onnx"
 MANDATORY_DEPLOYMENT_FILES = [
```

## sparseml/transformers/utils/__init__.py

```diff
@@ -16,10 +16,7 @@
 Utilities for applying sparsification algorithms to Hugging Face transformers flows
 """
 
 # flake8: noqa
 from .helpers import *
 from .load_task_dataset import *
 from .metrics import *
-from .sparse_config import *
-from .sparse_model import *
-from .sparse_tokenizer import *
```

## sparseml/transformers/utils/helpers.py

```diff
@@ -67,14 +67,15 @@
     }
     text_generation = {"text-generation"}
 
 
 ALL_TASK_NAMES = list(set.union(*[task_names.value for task_names in TaskNames]))
 ONNX_MODEL_NAME_INTERMEDIATE = "model-orig.onnx"
 RECIPE_NAME = "recipe.yaml"
+SPARSITY_CONFIG_NAME = "sparsity_config"
 MANDATORY_DEPLOYMENT_FILES = {
     ONNX_MODEL_NAME,
     "tokenizer_config.json",
     "config.json",
 }
 OPTIONAL_DEPLOYMENT_FILES = {"tokenizer.json", "tokenizer.model"}
 NLG_MANDATORY_DEPLOYMENT_FILES = {"special_tokens_map.json"}
@@ -230,15 +231,16 @@
         f"Using default sequence length of {sequence_length} "
         "(inferred from HF transformers config) "
     )
     return sequence_length
 
 
 def resolve_recipe(
-    recipe: Union[str, Path, None], model_path: Union[str, Path]
+    model_path: Union[str, Path],
+    recipe: Union[str, Path, None] = None,
 ) -> Union[str, None]:
     """
     Resolve the recipe to apply to the model.
     :param recipe: the recipe to apply to the model.
         It can be one of the following:
         - None
             This means that we are not either not applying
```

## sparseml/transformers/utils/load_task_model.py

```diff
@@ -13,16 +13,16 @@
 # limitations under the License.
 
 from pathlib import Path
 from typing import Any, Optional, Union
 
 from torch.nn import Module
 
+from sparseml.transformers.sparsification.sparse_model import SparseAutoModel
 from sparseml.transformers.utils.helpers import TaskNames
-from sparseml.transformers.utils.sparse_model import SparseAutoModel
 
 
 __all__ = ["load_task_model"]
 
 
 def load_task_model(
     task: str,
```

## sparseml/utils/helpers.py

```diff
@@ -7,23 +7,26 @@
 #    http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
+# flake8: noqa #E501
 
 """
 General utility helper functions.
 Common functions for interfacing with python primitives and directories/files.
 """
 
 import ast
 import errno
 import fnmatch
+import importlib.metadata
+import importlib.util
 import json
 import logging
 import os
 import sys
 import warnings
 from collections import OrderedDict
 from pathlib import Path
@@ -66,14 +69,15 @@
     "tensor_export",
     "tensors_export",
     "parse_optimization_str",
     "json_to_jsonl",
     "deprecation_warning",
     "parse_kwarg_tuples",
     "download_zoo_training_dir",
+    "is_package_available",
 ]
 
 
 ALL_TOKEN = "__ALL__"
 ALL_PRUNABLE_TOKEN = "__ALL_PRUNABLE__"
 FROM_PARAM_TOKEN = "__FROM_PARAM__"
 RECIPE_METADATA_KEY = "__metadata__"
@@ -931,7 +935,42 @@
     # some subset of files in the training directory
     # were downloaded before
 
     for file_name in sparsezoo_model.training.files:
         file_name.path
 
     return training_dir_path
+
+
+def is_package_available(
+    package_name: str,
+    return_version: bool = False,
+) -> Union[Tuple[bool, str], bool]:
+    """
+    A helper function to check if a package is available
+    and optionally return its version. This function enforces
+    a check that the package is available and is not
+    just a directory/file with the same name as the package.
+
+    inspired from:
+    https://github.com/huggingface/transformers/blob/965cf677695dd363285831afca8cf479cf0c600c/src/transformers/utils/import_utils.py#L41
+
+    :param package_name: The package name to check for
+    :param return_version: True to return the version of
+        the package if available
+    :return: True if the package is available, False otherwise or a tuple of
+        (bool, version) if return_version is True
+    """
+
+    package_exists = importlib.util.find_spec(package_name) is not None
+    package_version = "N/A"
+    if package_exists:
+        try:
+            package_version = importlib.metadata.version(package_name)
+            package_exists = True
+        except importlib.metadata.PackageNotFoundError:
+            package_exists = False
+        _LOGGER.debug(f"Detected {package_name} version {package_version}")
+    if return_version:
+        return package_exists, package_version
+    else:
+        return package_exists
```

## sparseml/utils/fsdp/helpers.py

```diff
@@ -8,43 +8,49 @@
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
+import logging
 import operator
+from pathlib import Path
 from typing import Optional, Union
 
 
 try:
     from torch.distributed.fsdp import (
         FullStateDictConfig,
         FullyShardedDataParallel,
         StateDictType,
     )
 except ImportError:
     FullyShardedDataParallel = None
 
+import torch
 from torch.nn import Module
 
 from sparseml.core.model import ModifiableModel
 from sparseml.pytorch.model_load.helpers import save_model_and_recipe
 from sparseml.utils.pytorch import set_layer
 
 
 __all__ = [
     "is_fsdp_model",
     "maybe_get_wrapped",
     "set_wrapped_model",
     "unwrap_and_export_model",
     "save_pretrained_fsdp",
     "get_fsdp_parent",
+    "find_and_move_state_dicts_to_cpu",
 ]
 
+_LOGGER = logging.getLogger(__name__)
+
 
 def is_fsdp_model(model: Module) -> bool:
     """
     Check if a model instance is wrapped by FSDP
 
     :param model: pytorch model to check
     :return: True if module is wrapped, False otherwise
@@ -109,35 +115,64 @@
         save_model_and_recipe(
             model=unwrapped_model,
             save_path=output_dir,
             tokenizer=tokenizer,
         )
 
 
-def save_pretrained_fsdp(model, accelerator, output_dir, save_safetensors: bool = True):
+def find_and_move_state_dicts_to_cpu(output_dir: str):
+    """
+    Looks for state dicts in the output directory and overwrites them
+    with cpu state dicts.
+
+    this is needed for quantized models trained with FSDP as the state dict
+    contains device information, which can cause issues when loading the model
+    using transformers AutoModel.from_pretrained(...) if the device information
+    is not removed, assumes the state dicts are named pytorch_model*.bin
+    """
+
+    for model_file in Path(output_dir).rglob("pytorch_model*.bin"):
+        loaded_dict = torch.load(model_file)
+        for key, value in loaded_dict.items():
+            if isinstance(value, torch.Tensor):
+                loaded_dict[key] = value.cpu()
+
+        torch.save(loaded_dict, model_file)
+        _LOGGER.info(f"Moved state dict {model_file} to cpu")
+
+
+def save_pretrained_fsdp(
+    model,
+    accelerator,
+    output_dir,
+    save_safetensors: bool = True,
+    save_compressed: bool = False,
+):
     full_state_dict_config = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)
     """
     Gathers the full FSDP state dict of the model onto rank0 GPU, then uses it to save
     the pretrained FSDP model to disk
 
     :param model: model to save
     :param accelerator: Accelerator instance used to perform unwrapping
     :param output_dir: where to save output model
     :param save_safetensors: True to safe in safetensors format, otherwise .bin
+    :param save_compressed: whether to compress sparse weights on disk
     """
     with FullyShardedDataParallel.state_dict_type(
         model, StateDictType.FULL_STATE_DICT, full_state_dict_config
     ):
         state_dict = accelerator.get_state_dict(model, unwrap=False)
 
     accelerator.unwrap_model(model).save_pretrained(
         output_dir,
         is_main_process=accelerator.is_main_process,
         save_function=accelerator.save,
         state_dict=state_dict,
+        save_compressed=save_compressed,
         safe_serialization=save_safetensors,
     )
 
 
 def get_fsdp_parent(layer_name: str, model: Module) -> Optional[Module]:
     """
     Gets the closest parent of layer_name that is wrapped by FSDP. If no FSDP wrapper
```

## sparseml/utils/pytorch/module.py

```diff
@@ -66,14 +66,15 @@
     "set_param",
     "get_terminal_layers",
     "get_prunable_layers",
     "get_quantizable_layers",
     "qat_active",
     "get_layers_params",
     "get_matching_layer",
+    "get_no_split_params",
 ]
 
 
 _PARSED_TORCH_VERSION = version.parse(torch.__version__)
 
 
 ALL_TARGET = "__ALL__"
@@ -92,14 +93,25 @@
                 return True, index
         elif name == target:
             return True, index
 
     return False, -1
 
 
+def match_class(layer: Module, targets: Union[str, List[str]]) -> Tuple[bool, int]:
+    if isinstance(targets, str):
+        targets = [targets]
+
+    for index, target in enumerate(targets):
+        if layer.__class__.__name__ == target:
+            return True, index
+
+    return False, -1
+
+
 def get_default_params(layers: Dict[str, Module]) -> Dict[str, Parameter]:
     params = {}
     for name, layer in layers.items():
         for param_name, param in layer.named_parameters():
             if param_name == "weight":
                 params[name] = param
                 break
@@ -133,14 +145,19 @@
     for name, layer in module.named_modules():
         # due to nesting, FSDP may not be the top layer
         name = fix_fsdp_module_name(name)
         match, match_index = match_targets(name, targets)
         if match and not params:
             targets_found[match_index] = True
             resolved[name] = layer
+        else:
+            match, match_index = match_class(layer, targets)
+            if match:
+                targets_found[match_index] = True
+                resolved[name] = layer
 
         for param_name, param in layer.named_parameters():
             if "." in param_name:  # skip parameters of nested layers
                 continue
 
             param_match, param_match_index = match_targets(
                 f"{name}.{param_name}", targets
@@ -310,7 +327,24 @@
             0, len(name), 0, len(name_to_match)
         )
         if match_length > largest_substring:
             match = (name, module)
             largest_substring = match_length
 
     return match
+
+
+def get_no_split_params(module: Module) -> Union[str, List[str]]:
+    """
+    Get list of module classes that shouldn't be split when sharding. For
+    Hugging Face Transformer models, this is the decoder layer type. For other
+    types of models, this just returns all module names.
+
+    :return: list of class names that shouldn't be split
+    """
+    # importing here to avoid circular import
+    from sparseml.utils.fsdp.helpers import maybe_get_wrapped
+
+    model = maybe_get_wrapped(module)
+    if hasattr(model, "_no_split_modules"):
+        return model._no_split_modules
+    return ALL_TARGET
```

## Comparing `sparseml/transformers/utils/sparse_config.py` & `sparseml/transformers/sparsification/sparse_config.py`

 * *Files identical despite different names*

## Comparing `sparseml/transformers/utils/sparse_model.py` & `sparseml/transformers/sparsification/sparse_model.py`

 * *Files 4% similar despite different names*

```diff
@@ -22,48 +22,65 @@
 from torch.nn import Module
 from transformers import (
     AutoModelForCausalLM,
     AutoModelForMaskedLM,
     AutoModelForQuestionAnswering,
     AutoModelForSequenceClassification,
     AutoModelForTokenClassification,
+    PreTrainedModel,
 )
 from transformers.file_utils import WEIGHTS_NAME
 
 from sparseml.pytorch.model_load.helpers import (
     apply_recipe_structure_to_model,
     log_model_load,
 )
+from sparseml.transformers.compression.utils import (
+    infer_compressor_from_model_config,
+    modify_save_pretrained,
+)
+from sparseml.transformers.sparsification.modification import modify_model
 from sparseml.transformers.utils.helpers import resolve_recipe
 from sparseml.utils import download_zoo_training_dir
 from sparseml.utils.fsdp.context import main_process_first_context
 
 
 __all__ = ["SparseAutoModel", "SparseAutoModelForCausalLM", "get_shared_tokenizer_src"]
 
 
 _LOGGER = logging.getLogger(__name__)
 
 
 class SparseAutoModelForCausalLM(AutoModelForCausalLM):
     """
     SparseML wrapper for the AutoModelForCausalLM class
+    Its lifecycle is defined as follows:
+    1. If pretrained_model_name_or_path is a SparseZoo stub
+       the appropriate SparseZoo model will be downloaded
+       (if required) and the path to the deployment directory
+       of the model will be retrieved
+    2. The original model definition will be loaded, without
+        the model weights
+    3. The model will be potentially modifier by `modify_model`
+        function, so that is compatible with SparseML
+    4. The appropriate recipy will be applied to the model
+       if requested or required
+    5. The appropriate set of weights will be loaded into the model
     """
 
     @classmethod
     def from_pretrained(
         cls,
         pretrained_model_name_or_path,
         recipe: Optional[Union[str, Path]] = None,
         *model_args,
         **kwargs,
-    ) -> Module:
+    ) -> PreTrainedModel:
         """
-        A wrapper around the AutoModelForCausalLM.from_pretrained method that
-        enables the loading of a SparseML recipe file to apply to the model
+         A wrapper around the AutoModelForCausalLM.from_pretrained method
 
         :param pretrained_model_name_or_path: the name of or path to the model to load
         :param recipe: the path to the recipe file to apply to the model. Can be a
             string or Path object. If None, a recipe will be searched for in the
             pretrained_model_name_or_path directory and applied if found
         :return the created model for causal language modeling
         """
@@ -89,25 +106,36 @@
                 "Loading model from SparseZoo training files..."
             )
             with main_process_first_context():
                 pretrained_model_name_or_path = download_zoo_training_dir(
                     zoo_stub=pretrained_model_name_or_path
                 )
 
+        # determine compression format, if any, from the model config
+        compressor = infer_compressor_from_model_config(pretrained_model_name_or_path)
+
         # temporarily set the log level to error, to ignore printing out long missing
         # and unexpected key error messages (these are EXPECTED for quantized models)
         logger = logging.getLogger("transformers.modeling_utils")
         restore_log_level = logger.getEffectiveLevel()
         logger.setLevel(level=logging.ERROR)
         model = super(AutoModelForCausalLM, cls).from_pretrained(
             pretrained_model_name_or_path, *model_args, **kwargs
         )
         logger.setLevel(level=restore_log_level)
-
-        recipe = resolve_recipe(recipe, pretrained_model_name_or_path)
+        model = modify_model(model)
+        # override the PreTrainedModel instance with compression save function
+        modify_save_pretrained(model)
+
+        # If model is compressed on disk, decompress and load the weights
+        if compressor is not None:
+            compressor.overwrite_weights(
+                pretrained_model_name_or_path=pretrained_model_name_or_path, model=model
+            )
+        recipe = resolve_recipe(recipe=recipe, model_path=pretrained_model_name_or_path)
         if recipe:
             apply_recipe_structure_to_model(
                 model=model,
                 model_path=pretrained_model_name_or_path,
                 recipe_path=recipe,
             )
         return model
@@ -145,15 +173,15 @@
                 kwargs["state_dict"], delayed = SparseAutoModel._loadable_state_dict(
                     model_name_or_path
                 )
             model = AutoModelForMaskedLM.from_pretrained(
                 model_name_or_path,
                 **kwargs,
             )
-
+        model = modify_model(model)
         log_model_load(model, model_name_or_path, model_type, delayed)
 
         return model
 
     @staticmethod
     def masked_language_modeling_from_pretrained_distil(
         model_name_or_path: str,
@@ -210,14 +238,15 @@
             kwargs["state_dict"], delayed = SparseAutoModel._loadable_state_dict(
                 model_name_or_path
             )
         model = AutoModelForQuestionAnswering.from_pretrained(
             model_name_or_path,
             **kwargs,
         )
+        model = modify_model(model)
         log_model_load(model, model_name_or_path, model_type, delayed)
 
         return model
 
     @staticmethod
     def question_answering_from_pretrained_distil(
         model_name_or_path: str,
@@ -272,14 +301,15 @@
             kwargs["state_dict"], delayed = SparseAutoModel._loadable_state_dict(
                 model_name_or_path
             )
         model = AutoModelForSequenceClassification.from_pretrained(
             model_name_or_path,
             **kwargs,
         )
+        model = modify_model(model)
         log_model_load(model, model_name_or_path, model_type, delayed)
 
         return model
 
     @staticmethod
     def text_classification_from_pretrained_distil(
         model_name_or_path: str,
@@ -369,14 +399,15 @@
             kwargs["state_dict"], delayed = SparseAutoModel._loadable_state_dict(
                 model_name_or_path
             )
         model = AutoModelForTokenClassification.from_pretrained(
             model_name_or_path,
             **kwargs,
         )
+        model = modify_model(model)
         log_model_load(model, model_name_or_path, model_type, delayed)
 
         return model
 
     @staticmethod
     def token_classification_from_pretrained_distil(
         model_name_or_path: str,
```

## Comparing `sparseml/transformers/utils/sparse_tokenizer.py` & `sparseml/transformers/sparsification/sparse_tokenizer.py`

 * *Files 7% similar despite different names*

```diff
@@ -13,14 +13,15 @@
 # limitations under the License.
 
 import os
 
 from transformers import AutoTokenizer
 
 from sparseml.transformers.utils.helpers import POSSIBLE_TOKENIZER_FILES
+from sparseml.utils.fsdp.context import main_process_first_context
 from sparsezoo import Model
 
 
 __all__ = ["SparseAutoTokenizer"]
 
 
 class SparseAutoTokenizer(AutoTokenizer):
@@ -38,18 +39,18 @@
         files are downloaded and the path to the directory containing the
         files is passed to the AutoTokenizer.from_pretrained method
 
         :param pretrained_model_name_or_path: the name of or path to the model to load
         :return tokenizer: the loaded tokenizer from pretrained
         """
         if str(pretrained_model_name_or_path).startswith("zoo:"):
-            model = Model(pretrained_model_name_or_path)
-            for file_name in POSSIBLE_TOKENIZER_FILES:
-                # go over all the possible tokenizer files
-                # and if detected, download them
-                file = model.deployment.get_file(file_name)
-                if file is not None:
-                    tokenizer_file = file
-                    tokenizer_file.download()
-            pretrained_model_name_or_path = os.path.dirname(tokenizer_file.path)
-
+            with main_process_first_context():
+                model = Model(pretrained_model_name_or_path)
+                for file_name in POSSIBLE_TOKENIZER_FILES:
+                    # go over all the possible tokenizer files
+                    # and if detected, download them
+                    file = model.deployment.get_file(file_name)
+                    if file is not None:
+                        tokenizer_file = file
+                        tokenizer_file.download()
+                pretrained_model_name_or_path = os.path.dirname(tokenizer_file.path)
         return super().from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
```

## Comparing `sparseml_nightly-1.7.0.20240304.dist-info/LICENSE` & `sparseml_nightly-1.8.0.20240401.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `sparseml_nightly-1.7.0.20240304.dist-info/LICENSE-ULTRALYTICS` & `sparseml_nightly-1.8.0.20240401.dist-info/LICENSE-ULTRALYTICS`

 * *Files identical despite different names*

## Comparing `sparseml_nightly-1.7.0.20240304.dist-info/METADATA` & `sparseml_nightly-1.8.0.20240401.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sparseml-nightly
-Version: 1.7.0.20240304
+Version: 1.8.0.20240401
 Summary: Libraries for applying sparsification recipes to neural networks with a few lines of code, enabling faster and smaller models
 Home-page: https://github.com/neuralmagic/sparseml
 Author: Neuralmagic, Inc.
 Author-email: support@neuralmagic.com
 License: Apache
 Keywords: inference,machine learning,neural network,computer vision,nlp,cv,deep learning,torch,pytorch,tensorflow,keras,sparsity,pruning,deep learning libraries,onnx,quantization,automl
 Platform: UNKNOWN
@@ -23,18 +23,18 @@
 Classifier: Topic :: Software Development
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Requires-Python: >=3.8.0,<3.12
 Description-Content-Type: text/markdown
 License-File: LICENSE
 License-File: LICENSE-ULTRALYTICS
 License-File: NOTICE
-Requires-Dist: sparsezoo-nightly ~=1.7.0
+Requires-Dist: sparsezoo-nightly ~=1.8.0
 Requires-Dist: setuptools <=59.5.0
 Requires-Dist: pyyaml >=5.0.0
-Requires-Dist: numpy >=1.0.0
+Requires-Dist: numpy >=1.17.0
 Requires-Dist: matplotlib >=3.0.0
 Requires-Dist: merge-args >=0.1.0
 Requires-Dist: onnx <1.15.0,>=1.5.0
 Requires-Dist: pandas >=0.25.0
 Requires-Dist: packaging >=20.0
 Requires-Dist: psutil >=5.0.0
 Requires-Dist: pydantic <2.0.0,>=1.8.2
@@ -46,29 +46,30 @@
 Requires-Dist: protobuf <=3.20.3,>=3.12.2
 Requires-Dist: click !=8.0.0,>=7.1.2
 Requires-Dist: scipy <1.9.2,>=1.8 ; python_version <= "3.9"
 Requires-Dist: scipy >=1.0.0 ; python_version > "3.9"
 Provides-Extra: clip
 Requires-Dist: open-clip-torch ==2.20.0 ; extra == 'clip'
 Provides-Extra: deepsparse
-Requires-Dist: deepsparse-nightly ~=1.7.0 ; extra == 'deepsparse'
+Requires-Dist: deepsparse-nightly ~=1.8.0 ; extra == 'deepsparse'
 Provides-Extra: deepsparse-ent
-Requires-Dist: deepsparse-ent ~=1.7.0 ; extra == 'deepsparse-ent'
+Requires-Dist: deepsparse-ent ~=1.8.0 ; extra == 'deepsparse-ent'
 Provides-Extra: dev
 Requires-Dist: beautifulsoup4 ==4.9.3 ; extra == 'dev'
 Requires-Dist: black ==22.12.0 ; extra == 'dev'
 Requires-Dist: flake8 ==3.9.2 ; extra == 'dev'
 Requires-Dist: isort ==5.8.0 ; extra == 'dev'
 Requires-Dist: wheel >=0.36.2 ; extra == 'dev'
-Requires-Dist: pytest <8.1.0,>=6.0.0 ; extra == 'dev'
+Requires-Dist: pytest >=6.0.0 ; extra == 'dev'
 Requires-Dist: pytest-mock >=3.6.0 ; extra == 'dev'
-Requires-Dist: flaky ~=3.7.0 ; extra == 'dev'
+Requires-Dist: pytest-rerunfailures >=13.0 ; extra == 'dev'
 Requires-Dist: tensorboard <2.9,>=1.0 ; extra == 'dev'
 Requires-Dist: tensorboardX >=1.0 ; extra == 'dev'
 Requires-Dist: evaluate >=0.4.1 ; extra == 'dev'
+Requires-Dist: parameterized ; extra == 'dev'
 Provides-Extra: docs
 Requires-Dist: m2r2 >=0.2.7 ; extra == 'docs'
 Requires-Dist: mistune <3,>=2.0.3 ; extra == 'docs'
 Requires-Dist: myst-parser >=0.14.0 ; extra == 'docs'
 Requires-Dist: rinohtype ~=0.4.2 ; extra == 'docs'
 Requires-Dist: sphinx ~=3.5.0 ; extra == 'docs'
 Requires-Dist: sphinx-copybutton ~=0.3.0 ; extra == 'docs'
@@ -76,15 +77,15 @@
 Requires-Dist: sphinx-multiversion ~=0.2.4 ; extra == 'docs'
 Requires-Dist: sphinx-pydantic ~=0.1.0 ; extra == 'docs'
 Requires-Dist: sphinx-rtd-theme ~=0.5.0 ; extra == 'docs'
 Requires-Dist: docutils <0.17 ; extra == 'docs'
 Provides-Extra: llm
 Requires-Dist: torch <2.2,>=1.7.0 ; extra == 'llm'
 Requires-Dist: gputils ; extra == 'llm'
-Requires-Dist: nm-transformers-nightly ~=1.7.0 ; extra == 'llm'
+Requires-Dist: transformers <4.35.0 ; extra == 'llm'
 Requires-Dist: datasets <=2.14.6 ; extra == 'llm'
 Requires-Dist: dvc ; extra == 'llm'
 Requires-Dist: scikit-learn ; extra == 'llm'
 Requires-Dist: seqeval ; extra == 'llm'
 Requires-Dist: einops ; extra == 'llm'
 Requires-Dist: evaluate >=0.4.1 ; extra == 'llm'
 Requires-Dist: accelerate >=0.20.3 ; extra == 'llm'
@@ -120,15 +121,15 @@
 Requires-Dist: torch <2.2,>=1.7.0 ; extra == 'torchvision'
 Requires-Dist: gputils ; extra == 'torchvision'
 Requires-Dist: torchvision <0.17,>=0.3.0 ; extra == 'torchvision'
 Requires-Dist: opencv-python <=4.6.0.66 ; extra == 'torchvision'
 Provides-Extra: transformers
 Requires-Dist: torch <2.2,>=1.7.0 ; extra == 'transformers'
 Requires-Dist: gputils ; extra == 'transformers'
-Requires-Dist: nm-transformers-nightly ~=1.7.0 ; extra == 'transformers'
+Requires-Dist: transformers <4.35.0 ; extra == 'transformers'
 Requires-Dist: datasets <=2.14.6 ; extra == 'transformers'
 Requires-Dist: dvc ; extra == 'transformers'
 Requires-Dist: scikit-learn ; extra == 'transformers'
 Requires-Dist: seqeval ; extra == 'transformers'
 Requires-Dist: einops ; extra == 'transformers'
 Requires-Dist: evaluate >=0.4.1 ; extra == 'transformers'
 Requires-Dist: accelerate >=0.20.3 ; extra == 'transformers'
@@ -137,15 +138,15 @@
 Requires-Dist: ultralytics ==8.0.124 ; extra == 'ultralytics'
 Requires-Dist: torch <2.2,>=1.7.0 ; extra == 'ultralytics'
 Provides-Extra: yolov5
 Requires-Dist: torch <2.2,>=1.7.0 ; extra == 'yolov5'
 Requires-Dist: gputils ; extra == 'yolov5'
 Requires-Dist: torchvision <0.17,>=0.3.0 ; extra == 'yolov5'
 Requires-Dist: opencv-python <=4.6.0.66 ; extra == 'yolov5'
-Requires-Dist: nm-yolov5-nightly ~=1.7.0 ; extra == 'yolov5'
+Requires-Dist: nm-yolov5-nightly <=1.8.0 ; extra == 'yolov5'
 
 <!--
 Copyright (c) 2021 - present / Neuralmagic, Inc. All Rights Reserved.
 
 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at
```

## Comparing `sparseml_nightly-1.7.0.20240304.dist-info/NOTICE` & `sparseml_nightly-1.8.0.20240401.dist-info/NOTICE`

 * *Files identical despite different names*

## Comparing `sparseml_nightly-1.7.0.20240304.dist-info/entry_points.txt` & `sparseml_nightly-1.8.0.20240401.dist-info/entry_points.txt`

 * *Files identical despite different names*

## Comparing `sparseml_nightly-1.7.0.20240304.dist-info/RECORD` & `sparseml_nightly-1.8.0.20240401.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 sparseml/__init__.py,sha256=T_bs6LwcOiYZveynfxxfZFRqE8qsaHtcSq6s9zbhpgo,1489
 sparseml/analytics.py,sha256=WhXdKgK1-ll9sRzn2n8z-FAikQ02J8rUeWmceiX5S7E,898
 sparseml/base.py,sha256=oOPiaU2JhI0beFwp8Obe7hbt3kUuNvI5XD1wTBCtLnc,10284
 sparseml/integration_helper_functions.py,sha256=SU3dLigJSAPd4oo1A_-yOKiJBoz6w_o-1foXmuUyYc4,7288
 sparseml/log.py,sha256=K5E3goPRIPY7Uc14JcX-4oLXVWu7ecOPf1NYBGHc1r0,2483
-sparseml/version.py,sha256=MWdsJuT6gFRT_pLZnQqnczQtPcOKNR2mO4BFHs6cfkI,1511
+sparseml/version.py,sha256=hZ3UsXlWWuL16aEv7XuvhtK5QBxEVEuaTkojPRlSvxU,1607
 sparseml/benchmark/__init__.py,sha256=WynUhMzXq3-iQAhPwcmcMOj2_xCa9brLubs7gxq9T3U,758
 sparseml/benchmark/info.py,sha256=VjZ7cUD66h1u7IJeRXKjiSfvS8aSr-cbAJdnsTmLmoI,17763
 sparseml/benchmark/serialization.py,sha256=FPpcC93x5H86Fqil9YbERUpltu7qhhIQjsyYaSlW_20,10778
 sparseml/core/__init__.py,sha256=UPGGUU562tk80yMF9HvstVoQIUcGO8SD6WGnFVO0FK4,915
 sparseml/core/event.py,sha256=p8tVMOeVgQMGZF0n4L2kkeI-CqEHZv3F_6Vgb2RwPk0,6842
 sparseml/core/factory.py,sha256=ZSjyQA7n7Or4KPnSHMbweZX8IXN4LOLCSWYQuYUrwoE,6492
 sparseml/core/framework.py,sha256=2psIvMAk1x66OotgEJHrXPzH7HQOWznDDTGvNp1ngUo,2850
@@ -18,55 +18,57 @@
 sparseml/core/data/__init__.py,sha256=A-BAxKdKkQZV3uwVkddf7Y1ELm6PR08vjC7RWm3GbFc,667
 sparseml/core/data/base.py,sha256=mCBTzNJZRkBYDmRs0MRtme2165SEmqx5Zofnd7uaRtM,1565
 sparseml/core/data/pytorch.py,sha256=SCGY15TpOlKK1esLTZivBabZFwN6LTKG4BjiTlWJWy0,6415
 sparseml/core/lifecycle/__init__.py,sha256=vwovEosG7X2vzRY8l79wJTimC939HZyoQoio2zVTRck,678
 sparseml/core/lifecycle/event.py,sha256=5O6Q0Gj_McUVH_heJPbKOncUVP8gYgrNYaFyzlQrq7M,11954
 sparseml/core/lifecycle/session.py,sha256=mtKIEBXUALADFTF-wyCKj6dPwNpn94f_sraxI-Tc2Ts,8242
 sparseml/core/logger/__init__.py,sha256=_mXgqmOtAbxyCUX-D-LzqqktrPgL5vKxj2l5hgu615I,654
-sparseml/core/logger/logger.py,sha256=GWix7C5dbj_HP5JklnRWc6b3cn_-m6NzMdqlNUSv9rg,44657
+sparseml/core/logger/logger.py,sha256=xB6Lx5OKiUDb4guWbljEjdSKDB-vgiwYozxPY-VEEAQ,44703
 sparseml/core/logger/utils/__init__.py,sha256=gpKo4866OtqxB1-pP7pE80fvJYQHkhmL3y6KWa4ZX6s,667
 sparseml/core/logger/utils/frequency_manager.py,sha256=yjPe67GtmRqZKrUjiipAoaCIoAJkNVkXWDNx1MzLq7o,12725
 sparseml/core/model/__init__.py,sha256=l15jfDdshL6wY07mU2MIXE4M32bVWxQVJ-oMs3BcCR8,693
-sparseml/core/model/base.py,sha256=mHaWGt_VWC7LiAZoJwMku8bkHVKYZaEgRPXxEySr35g,5639
-sparseml/core/model/pytorch.py,sha256=BQ-tkZCqEJAhnLkDilXELjdxWEedvEcCXrGD3jQKtkI,5200
+sparseml/core/model/base.py,sha256=eBTyDegoLzLfAUcsNnbxsjN50u9gTMHB8FZGDN8IPx0,5895
+sparseml/core/model/pytorch.py,sha256=bEvw5sYeGmNJzc_G4D8hHhUYJfev9L7mUPLJSgWFAYQ,5641
 sparseml/core/modifier/__init__.py,sha256=sb7lldB_FbIIuxVFAm4PT8Lm_VWFuQV8heF7_pnAOyY,699
 sparseml/core/modifier/base.py,sha256=d-3OIr5jc3OxqdM2msiDEjscO6KEWkihAF1RS6vzWUg,3326
 sparseml/core/modifier/modifier.py,sha256=IyiVMIHrMf3vBbdT8g5SlUunBinghfnPixevyoGSSXs,10810
 sparseml/core/modifier/stage.py,sha256=EOnM-KCga3t9sWQTqpDvDHz0QXuEPreIx_8d1RGS7Yc,6093
 sparseml/core/optimizer/__init__.py,sha256=6ezDyN2xcdvs_Yjwdjm1sEZuHEbcLa2-x6hDsReZBS8,672
 sparseml/core/optimizer/base.py,sha256=WK2Y3xLrO4jxRIyLhUf6hCfKU_XX1mhgfEsydGBxmOs,3409
 sparseml/core/optimizer/pytorch.py,sha256=y3lJvrh8sBzU13fgOq6DEkv0Kp0DtL7QAihSkbidVcM,4584
 sparseml/core/recipe/__init__.py,sha256=brwArG2SqTYBSJnInO3XzLwE56xyJv5ZaC93FN9S1pI,790
 sparseml/core/recipe/args.py,sha256=71JWFOpanUGjj0u9_ndJKtFmbn8LoP4lA6CDNiBplIg,6872
 sparseml/core/recipe/base.py,sha256=SB3ZV6HNPzf7mzRDdIoGpqwfXpRRx5qhL9tI0HapcsY,1599
-sparseml/core/recipe/container.py,sha256=Rxk4B29pii-j1vaVZL3Hm8xI5qdgu8Y9aRkMjB7-RHw,6016
+sparseml/core/recipe/container.py,sha256=BOzgtac0xIemEC6k9bfcUGfZfEGZ1dWdANL8KKlD2M8,6313
 sparseml/core/recipe/metadata.py,sha256=7ZZqQ0F3aV2Fgq7IzCQV-6i04ySBw_oS9-NKnR_K0wk,2932
-sparseml/core/recipe/modifier.py,sha256=0CoY0YFzXeCJ8bMx0lF4IM3QJ5or74fGKhW_MQXjc20,4196
-sparseml/core/recipe/recipe.py,sha256=erXHazRADQORseSE5YF0SoMnuVm6DuVgwDt9krs3xeE,19994
+sparseml/core/recipe/modifier.py,sha256=8_R_Pi6JGvXVwmkegN9P0DYHf5tUPoqbPicS_bT9xHY,4224
+sparseml/core/recipe/recipe.py,sha256=sedLkXQfhq1Sv44O_oGK_d0GTvi0dtcV0mD-KaXWGIw,24978
 sparseml/core/recipe/stage.py,sha256=R9iXDwMv_leN4ICTrsintQzEy9PG_IiyCRbC6pKVZhQ,7629
+sparseml/core/utils/__init__.py,sha256=2HPzh0XB3stE92JJPMvl-Cu7cwa0Qu1Gg1ktlBethDA,663
+sparseml/core/utils/session_helpers.py,sha256=GwxgJCatxeJMmLu_atCcdm-1HoKIYIDmQS8i-DCPzHg,1025
 sparseml/deepsparse/__init__.py,sha256=o5ITzTEOlH--61_SXMISrmPcRk4ci91FGlR-aQxwOn4,863
 sparseml/deepsparse/base.py,sha256=nRjU6TSao0J2iWXcdHwj62X6dVT9vl6TQ2y4Bdn3KN0,3516
 sparseml/deepsparse/framework/__init__.py,sha256=ZHrXXM3AMH78zKcF8Y40IBuy38UFy4fLrvytozw_bNY,801
 sparseml/deepsparse/framework/info.py,sha256=HVDPHFXggFeDqbpM20PkByf1nBccwKnjpTWh0EfrVas,6032
 sparseml/deepsparse/sparsification/__init__.py,sha256=re_2FtHWvO-iQQwRRJZDKz3l_pFZuwe266-4ZFxQqbY,813
 sparseml/deepsparse/sparsification/info.py,sha256=O5FJg5KMJvj-HcJn9W9iiKGZ6Z7_1SavOX-TstXRr6Q,1348
 sparseml/evaluation/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/evaluation/cli.py,sha256=cu1YEgMZXq4bN_cOCseCs2Nhaaqy2_fbh0oi9xig6ho,5689
-sparseml/evaluation/evaluator.py,sha256=Bm8_kaWw6Ndr-6qq-mLRIIlE7nqvUV_TZ2tt4Ijt_eM,1983
+sparseml/evaluation/evaluator.py,sha256=RUY6L3621CtuKlwRjuu8hSuBzoeU9ERypZmfBs9rX0g,2140
 sparseml/evaluation/integrations_config.yaml,sha256=PCSqljI_6wesSy45O-mNeSN9CtRHWtdnd9fiK1pTXXU,940
 sparseml/evaluation/registry.py,sha256=VHS7blDGfq4WzFB5PxAkfOIYuHTWki-UGuGukCP9XzQ,5571
 sparseml/evaluation/integrations/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
-sparseml/evaluation/integrations/lm_evaluation_harness.py,sha256=siP82sA3M6LiV4l-On27nRoAiKP2rTdBH1T7z2pVqmc,5834
-sparseml/evaluation/integrations/perplexity.py,sha256=8_IZ4QMdvZjl1jeI3nw6YzjPGPvncf0zm-ODqIFHpfM,11062
+sparseml/evaluation/integrations/lm_evaluation_harness.py,sha256=2adnmKtGMzowJUveeWbaaZUjmf6YO2a8sHPVFiGcwNQ,6000
+sparseml/evaluation/integrations/perplexity.py,sha256=wBdnkBYv8bhFqt2PA3wVr3nN0GATRkn3qWgdgHKXH88,10987
 sparseml/export/__init__.py,sha256=5CrKZql6PYJq3BpNLBG397pVG7rVxU4-NIgpQeKY188,661
 sparseml/export/export.py,sha256=Z-v8Lyz_RsB74gmU9s79m33vAv3nPoT_uIRexvJRaIA,21172
 sparseml/export/export_data.py,sha256=5t9jEycKHOdcBVdHkA6ktRZxQ5luyqNRALPlSvmkdKE,8049
 sparseml/export/export_torch_model.py,sha256=SiA69b7p0KWhfM2XtYbKaYW6YHIvIdFHL_tWJdGBX58,2681
 sparseml/export/helpers.py,sha256=maoxhetc4Fu94XevWFyZ6-BQErjSZOHZie_rwKyWaFE,13052
-sparseml/export/validators.py,sha256=KQ7KGDKQ_j9FyDDAOqy008rcJ7ItNIej8T1NZ2M_QjQ,7951
+sparseml/export/validators.py,sha256=KZhGKo-py1aE5i6Z9iDNnxkKLQHd1bW74we1hMt0NYE,8850
 sparseml/exporters/__init__.py,sha256=VPcyVcyPnl7Kp05h3ws-UC2jgKR6W-cr11d-m665w9A,786
 sparseml/exporters/base_exporter.py,sha256=M1HEe9GNf51uYx1z-qxWjIYo5iGZ_Ish8uZ3mj6OZR8,1477
 sparseml/exporters/kv_cache_injector.py,sha256=2fKoRPBE7yrR6h3KXxeU7EbsU5ufyZUIbSnRP2FTjwc,6576
 sparseml/exporters/onnx_to_deepsparse.py,sha256=e3RNDtyKAbmYTF-AHV00FAg-ilQDidUPTnUU9oQm4Rg,5522
 sparseml/exporters/transforms/__init__.py,sha256=0SMdBqAFpcoDTWDklE2nSk9G4sZOAUyUfeWUJSlRAD0,2350
 sparseml/exporters/transforms/base_transform.py,sha256=IpvdUdEADl2SfqHawcp6-lcNgz-R3L0zpS05WaWF5h8,2333
 sparseml/exporters/transforms/constants_to_initializers.py,sha256=_PX3y16OC-q85d-6DeOOVpKAAMNIU1m5BdYTZlFV_tk,1388
@@ -156,40 +158,40 @@
 sparseml/modifiers/distillation/output/__init__.py,sha256=mRxLhbapfZ3Q_3wV_fkiovbQlxdXGbk9yOorkzifdxU,654
 sparseml/modifiers/distillation/output/base.py,sha256=S5QQ6SMNA1hwkaZttSaNV64UGsRf-ZTL37mgiRRZA3E,1343
 sparseml/modifiers/distillation/output/pytorch.py,sha256=1rGCW5LnSHK-VU_t1Lk7D2ko7kA36WhzkfjqVUkzq7E,7612
 sparseml/modifiers/distillation/utils/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/modifiers/distillation/utils/pytorch/__init__.py,sha256=PZAS2znyCWzwOoUJwRapwCod1pAJ-ydfaLimAq61laU,715
 sparseml/modifiers/distillation/utils/pytorch/kd_factory.py,sha256=qFbAGeotzlVCsLyTbxOZsoDwqHRT18xDWv0IrtmOu7w,13320
 sparseml/modifiers/distillation/utils/pytorch/kd_wrapper.py,sha256=9f7-5DFA8dOBJK0XmalVQny-mi1V8JWUbJXDmZwAVc8,3921
-sparseml/modifiers/distillation/utils/pytorch/model_wrapper.py,sha256=v9CHkNDuBCb0aqudyuQrdIDRi_c_yUje9m7bEbm4Ta0,4379
+sparseml/modifiers/distillation/utils/pytorch/model_wrapper.py,sha256=LMCOiZh7lWbZgcjx0upT4cTdWCIpMi62dfUfgJbbWw4,4527
 sparseml/modifiers/experimental/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/modifiers/logarithmic_equalization/__init__.py,sha256=QQWiZMR2IxBVSYmsAkop1F_xCGhHzMlukySMVz4lv2I,654
 sparseml/modifiers/logarithmic_equalization/base.py,sha256=4Omr8jRxMIAImM-ws6iGVMSXxt1awoj-g6CCVTFyoJk,2764
 sparseml/modifiers/logarithmic_equalization/pytorch.py,sha256=KeHI-gDVJbjEgWh0mEWKCdp1dXwXeFOLjWE_JVgBnP8,1947
 sparseml/modifiers/obcq/__init__.py,sha256=mRxLhbapfZ3Q_3wV_fkiovbQlxdXGbk9yOorkzifdxU,654
 sparseml/modifiers/obcq/base.py,sha256=wK2wIPY28TfqU68iio6ivaPQ6ranOxTvJIQr7Vc0mYI,5181
 sparseml/modifiers/obcq/pytorch.py,sha256=waCQ6AymBlflz0kHBBj6Q1L5d7dNngwcbyFeUVks6SU,3543
 sparseml/modifiers/obcq/utils/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/modifiers/obcq/utils/helpers.py,sha256=eb8XeB7V1brhTMLjIEdzmSQonYnKDZKKilasL8FC24A,6686
 sparseml/modifiers/obcq/utils/sgpt_wrapper.py,sha256=nJliltPq_VDICpsoGYeFPO6EAJEe33CHilm0e1XP8P0,6753
 sparseml/modifiers/pruning/__init__.py,sha256=3qxXBFnaK2JrDJy13FFckyqF9tpLNdRCAtETUVy2Fso,683
 sparseml/modifiers/pruning/helpers.py,sha256=mgqnvArk40p9_9K-dcN1QzkQICmllgk5YNsYv1luXE0,5725
 sparseml/modifiers/pruning/constant/__init__.py,sha256=ZX5IYPTigTjstA21M3sbHbu9ZfamE0tTeA9tPPctczs,676
 sparseml/modifiers/pruning/constant/base.py,sha256=08lKBIpaMUWhEYoBx317EzZXMF6xVjAOGH9brsD0EuA,951
-sparseml/modifiers/pruning/constant/pytorch.py,sha256=WwxjVH6b9RK9a8yDkd3SPLQde7i8l6Sh2xUYXQeV8H0,2907
+sparseml/modifiers/pruning/constant/pytorch.py,sha256=ph_C27HPWu_TIWBPqAs_eqpTkAJ-cpBVbE0T7rMPgU4,3103
 sparseml/modifiers/pruning/magnitude/__init__.py,sha256=E59xmevUYsLvjYqhjxzCLTAWMpb2ltTxNf6XDo-1ejw,677
 sparseml/modifiers/pruning/magnitude/base.py,sha256=3cATdYRcasOxgNZzaOXAnGyh4kbKRrsJ4W6dQnMyTbo,1168
 sparseml/modifiers/pruning/magnitude/pytorch.py,sha256=Q6WY_pw13oEBCeIReKn8xbFd2h6rdSAqiAHFj5pqKR0,5262
 sparseml/modifiers/pruning/utils/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/modifiers/pruning/utils/pytorch/__init__.py,sha256=Pttyyyhm6pjNbKSdFbP8WxTCeBQJ_wWpuTuk9rnzEOY,688
 sparseml/modifiers/pruning/utils/pytorch/layer_mask.py,sha256=r3LZR6O0LNwJ_aqmKV8U5IuZiyRif9mSfBYcwTab_N4,5984
 sparseml/modifiers/pruning/utils/pytorch/mask_factory.py,sha256=k-Nikp_bN7LxB64LHyMN4Xf4JcsFQUADywPgd3VlAmk,5622
 sparseml/modifiers/pruning/wanda/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
-sparseml/modifiers/pruning/wanda/base.py,sha256=TPRGtje6dWBui2Qrc1FST0g1Uev2JrB5pb7GU5QHV6M,3947
-sparseml/modifiers/pruning/wanda/pytorch.py,sha256=AeykangO6AoAMC1WHfKTGhei97wXTdXGRV6X9C3sL5E,9922
+sparseml/modifiers/pruning/wanda/base.py,sha256=bsXiTsATTrjdieYq8VmiJAODkxu6EbMwnBOU984fBsc,3905
+sparseml/modifiers/pruning/wanda/pytorch.py,sha256=k3fWJRaUCfssCjjC-AQcDfJN0Fvu6DuWbf2s43Hx7DQ,10346
 sparseml/modifiers/pruning/wanda/utils/__init__.py,sha256=TF5uEKrpc2qYdbgmXh9xVp2GQ3p--by-LoCegY19EeI,633
 sparseml/modifiers/pruning/wanda/utils/wanda_wrapper.py,sha256=mOwf1k0A6NZOLCP2QlTgfpdm1lGJYunrJQW6763sNjs,4469
 sparseml/modifiers/quantization/__init__.py,sha256=mRxLhbapfZ3Q_3wV_fkiovbQlxdXGbk9yOorkzifdxU,654
 sparseml/modifiers/quantization/base.py,sha256=zsxVrP_mLh895z1g56o1xtNgUAMVgqMGKmUk0GBnmYg,5512
 sparseml/modifiers/quantization/pytorch.py,sha256=Gzy_AemrYNkbr29RLo4MuqVcLc_heF8bdQlrkvCRxDA,8924
 sparseml/modifiers/quantization/utils/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/modifiers/quantization/utils/constants.py,sha256=sla-j0QwLFq92AbDZkHkNLxugpGrNEQJIuLWoWqV3Ks,2220
@@ -198,15 +200,15 @@
 sparseml/modifiers/quantization/utils/quantization_scheme.py,sha256=VvDo8KBtc6uTWnKDM9izgEcWtTdXGxkR_E-zKQ2aTO0,13545
 sparseml/modifiers/quantization/utils/quantize.py,sha256=-t4-i1DDQDvKMLMFk6qNQzlYf0jz98sK7hti6zKz5dw,19811
 sparseml/modifiers/smoothquant/__init__.py,sha256=QQWiZMR2IxBVSYmsAkop1F_xCGhHzMlukySMVz4lv2I,654
 sparseml/modifiers/smoothquant/base.py,sha256=_KxGDJh54i_0Ltrw6NnN0FaRPWWbxjiK-3yzZHkH5-E,7535
 sparseml/modifiers/smoothquant/pytorch.py,sha256=bv9FmqGfiafK1TOh-MM66eBUXVHgdc5ECDye5PUwtQk,8167
 sparseml/modifiers/utils/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/modifiers/utils/compression_wrapper.py,sha256=qjq6mycdiMvWUktylSr4gWplzHxQEctkwnP1XORUSvE,3944
-sparseml/modifiers/utils/layer_compressor.py,sha256=xqYhMf_I_0imUzwk_CyYFydAIfRNvI3bwoTl4-xFIlQ,5017
+sparseml/modifiers/utils/layer_compressor.py,sha256=PgICAZVJ3qFixoA-TD6eykBByF_d4O3LF0WukdvHVyk,5257
 sparseml/modifiers/utils/pytorch_helpers.py,sha256=HjpIZmD8KnyLh8opb6YxpCbZ8JZTDlkONHloYxsKC_4,3265
 sparseml/onnx/__init__.py,sha256=KeWF6EQ7cpX_b-fMhiG5n6pVPUvRxiWMpzpiI9EagFI,1036
 sparseml/onnx/base.py,sha256=Kv3YC0Xh1xlxpIuwh9916SHuz96phaf36KbL71DSZWk,6202
 sparseml/onnx/benchmark/__init__.py,sha256=tl8cy1ta02lUmMxwmDfRAYcVQfaj5OpU3igqYJHMGg8,743
 sparseml/onnx/benchmark/info.py,sha256=iCNry2VAuSmTLrPl3a8pxDU_R-U9-Lpcka40QIg5BZg,15366
 sparseml/onnx/framework/__init__.py,sha256=HpgplVizgXIPOmnE24RM1geQLp924227_T12jJjQCaA,823
 sparseml/onnx/framework/info.py,sha256=YzZmDaR6Z1y66xo_OKtmQGA1ZVFOozZNXBJ_Ec74ueU,6116
@@ -271,15 +273,15 @@
 sparseml/pytorch/image_classification/train.py,sha256=-My1yUclgRA5wQoV4B_jtoOMRO1nQj389WfDkebu3fs,29287
 sparseml/pytorch/image_classification/utils/__init__.py,sha256=ambjlzpSCaSZ7ZadPk2vMAB6kaZCm7f_hVqOVSWz8k8,682
 sparseml/pytorch/image_classification/utils/cli_helpers.py,sha256=qypcmjezy-fZn2Cjozv9vumZoB44_9PDe_WXnChbvLg,4278
 sparseml/pytorch/image_classification/utils/constants.py,sha256=k01fijyL2BicSWLL1EzhhdvG07WYMMXHZeFz-9fxecM,1257
 sparseml/pytorch/image_classification/utils/helpers.py,sha256=MfToJnfK4WUqtzBOfjGh9d1BbbxGLrZft2-rUv22IWQ,23894
 sparseml/pytorch/image_classification/utils/trainer.py,sha256=2WOP42hSlowDG2_DyCZOu8T5yohhV38e192ZxeWXj_A,12056
 sparseml/pytorch/model_load/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
-sparseml/pytorch/model_load/helpers.py,sha256=1LRsVj1LvFGbP9_MAj1Wv4JVnPGuVyLOts7PQKZDvao,10586
+sparseml/pytorch/model_load/helpers.py,sha256=43DpF9PDBiEsJUNCNSd64-fJyaOdp4MeitM7aGtGcvI,11440
 sparseml/pytorch/models/__init__.py,sha256=Lj1KLciXTQiZObA5HHgrPMHNQ1bGYswrsP776eizaUc,976
 sparseml/pytorch/models/registry.py,sha256=cJLPsK8zzhVyZPvcJ8_Kj9-Ru9lTOywv61xuE50LiC8,14753
 sparseml/pytorch/models/classification/__init__.py,sha256=opnCtf6WMl1kuQ_vRAZRLl1eFZefpG9GFc9o729HndQ,901
 sparseml/pytorch/models/classification/darknet.py,sha256=rR4XXQu7shLADU4Th0D-eodnv-Z3AmA6kj8tDgHmtxU,11658
 sparseml/pytorch/models/classification/efficientnet.py,sha256=Bs88xu2xX9P65TOZ_6rn_qO2CMa6oLsJm5xt-Y6gISI,40293
 sparseml/pytorch/models/classification/inception_v3.py,sha256=wxWU3ja6E0_ERhYniDlzcsnVWi-rvJVfgxmhsyrpuC4,16512
 sparseml/pytorch/models/classification/mnist.py,sha256=RyFLHgKzmbmSvI-7F4nkbUI7xkz5pKElT7ve1ZIn7VU,4164
@@ -299,15 +301,15 @@
 sparseml/pytorch/nn/__init__.py,sha256=bd3tEwx7afmeU0yK0ywTsq4bI1QoxtjRA4Dq-C5ImMs,925
 sparseml/pytorch/nn/activations.py,sha256=dNDJaeZIUOqtQW-aAvARBVz0uE4MXKKZFbGt6_vu6Yk,8673
 sparseml/pytorch/nn/fatrelu.py,sha256=twbvUqaJsKkjplrUJaVm4mfq-OC63eN-IboG70nhZO8,11854
 sparseml/pytorch/nn/identity.py,sha256=vCs9du3P0fQS6clFFNCacHE-J_OGZiKcvsEz-iHZy4s,1690
 sparseml/pytorch/nn/se.py,sha256=kR9agk8OKTEq_iPRLX8NHlbFUJlZEVFt7Otgtk5LoXQ,2828
 sparseml/pytorch/optim/__init__.py,sha256=pV-8sO8TP23X6gS81BvCfEC9LCnRYws3ek-pylOnaHg,1243
 sparseml/pytorch/optim/analyzer_as.py,sha256=6WCMuxF-8rcFYNTNiNoQMNloISfJBrk_9bYbSiMK1-8,13638
-sparseml/pytorch/optim/analyzer_module.py,sha256=u8E3l-hvIhicNqsGcY4WTrT1hZBtPsIN2unqix8RAhI,17069
+sparseml/pytorch/optim/analyzer_module.py,sha256=lCzfpKh4fqmd0LNMmCc0l5EOK7KE_s_vgoJCtA9hZuU,15582
 sparseml/pytorch/optim/analyzer_pruning.py,sha256=V-VWmMgTU1nHgcLlVmyl3aNo4yeeG0HGleAfTkhNiyI,3955
 sparseml/pytorch/optim/manager.py,sha256=abFJNGYSBohaZAq65ZVojG7dl45QuXALmhkJanIVyWg,26838
 sparseml/pytorch/optim/mask_creator_pruning.py,sha256=k0gHVM8fThZqLOBfdfte1l7zoylvDRpaAxfcM32eioc,36844
 sparseml/pytorch/optim/mask_pruning.py,sha256=QqBrPfskL0vJlFOsxrqZp0sCk8NQUf4srj5WNuWHyJY,23085
 sparseml/pytorch/optim/mask_pruning_scorer.py,sha256=IKiIegTFtez2taiWwDwaxJOMvEd8---GQ28CeZD24gI,10449
 sparseml/pytorch/optim/optimizer.py,sha256=f20_TaCsvNRybm0qqG1BqXu1KOQpDeQkIOZWiMvftJc,6605
 sparseml/pytorch/optim/sensitivity_as.py,sha256=9QJiRvMkFXCFCCQYuA77BwJgJRoHDtuQ4fxx3T3cwtY,14879
@@ -329,22 +331,22 @@
 sparseml/pytorch/sparsification/pruning/mask_creator.py,sha256=Ysq75fdYo5WQcvt6ox8HTKv6SVNQjy_Y4rSs1JeLsuI,29250
 sparseml/pytorch/sparsification/pruning/mask_params.py,sha256=3ed4BlkG3DMgeeViLoSj1TqI4YZ2lv6h4ufEcOCXgHk,24209
 sparseml/pytorch/sparsification/pruning/modifier_as.py,sha256=7JKrvWdm3-xHF4z8IUd046BuU08P0Z-Hqqbl5YwShog,13389
 sparseml/pytorch/sparsification/pruning/modifier_powerpropagation.py,sha256=A94H24w_tZElkW6dIEO8h5UOlfdMOBxs2Lh8Dz26QXk,12006
 sparseml/pytorch/sparsification/pruning/modifier_pruning_acdc.py,sha256=jRMApqylXjFHW31nZY_iMveu265uqQqIqNHrXGzmmyU,10455
 sparseml/pytorch/sparsification/pruning/modifier_pruning_base.py,sha256=HsLi7Mdu9Lty5A9w4nY9sTe9NgzDxgJRoM-LzFkl6Ao,33219
 sparseml/pytorch/sparsification/pruning/modifier_pruning_constant.py,sha256=D3zx4rL5ccwi9kFGsIo1OoPW9zl--ditOu7JKb-9hGs,5757
-sparseml/pytorch/sparsification/pruning/modifier_pruning_layer.py,sha256=giv8z84R0-nQ7MRfW6MrqBd0C19GFnFTUNjJz_5HlRo,8860
+sparseml/pytorch/sparsification/pruning/modifier_pruning_layer.py,sha256=n25kaxnfu8FPx6aq5hUiE76ihA8ge_WtAgYI9GLZgmg,8857
 sparseml/pytorch/sparsification/pruning/modifier_pruning_magnitude.py,sha256=5W-H7scPflGySPoeLZaFwyvihbqsYcZP6xwMWsQ75WQ,15595
 sparseml/pytorch/sparsification/pruning/modifier_pruning_mfac.py,sha256=GFJy-obm0cvr2c1vNgCWaUXAhFplvHDxUfmun98rWmY,63519
 sparseml/pytorch/sparsification/pruning/modifier_pruning_movement.py,sha256=gmRbalMpVEJ-U5xdL5Vh-XcTOhkfr8z_cWlKw_m1c9k,8774
 sparseml/pytorch/sparsification/pruning/modifier_pruning_obs.py,sha256=bKZojNIl4aWvU0xXxfAvTZztFcS2Q5QCljt43icIux0,24121
-sparseml/pytorch/sparsification/pruning/modifier_pruning_rigl.py,sha256=XxmFXFBHeTToW2bBZWBdihBO5IV_zXFzBAFbRbtj3FU,23346
+sparseml/pytorch/sparsification/pruning/modifier_pruning_rigl.py,sha256=n8gVTTCYqNlb8Hs9WxjraQcm6I5x-dhTrExIeOJX3Wo,23735
 sparseml/pytorch/sparsification/pruning/modifier_pruning_structured.py,sha256=h7ASPoik7zrBXE_lbdfBO3UkbrTeXG5gGE1Flg75h8s,18245
-sparseml/pytorch/sparsification/pruning/modifier_pruning_topkast.py,sha256=byYe683HZh3w-S6ZOYnLZr4TfIqiuLLVxThwKfiJUt8,17756
+sparseml/pytorch/sparsification/pruning/modifier_pruning_topkast.py,sha256=6ukbXWtRe_4wZ-awRfD7uZPQiIVPaTOm1Jf-z3qNO9Y,17683
 sparseml/pytorch/sparsification/pruning/scorer.py,sha256=8gyYSv611GOJwmpQeD7FsWVrLxF8jeM_f59zhQlC6f8,4644
 sparseml/pytorch/sparsification/quantization/__init__.py,sha256=OjbeCzzhoeFJEJQvLmXZc89pghO83sLRhmvNF7_q_oQ,813
 sparseml/pytorch/sparsification/quantization/constants.py,sha256=sla-j0QwLFq92AbDZkHkNLxugpGrNEQJIuLWoWqV3Ks,2220
 sparseml/pytorch/sparsification/quantization/helpers.py,sha256=Q1kXCoQ0t4gEFFUEmf_skQvlyjJhhAuAJwIkBBWT3l8,34914
 sparseml/pytorch/sparsification/quantization/legacy_modifier_quantization.py,sha256=TToI4dGYZZEzB1q61m1YVg0THlvH7Ew1CZ2y-ajpTts,33626
 sparseml/pytorch/sparsification/quantization/modifier_quantization.py,sha256=LkHNB1IsiFlZugUecB4-LZMjWuoboFYf_PXPx6uPl1g,26778
 sparseml/pytorch/sparsification/quantization/quantization_scheme.py,sha256=-Ceik2aGOCuxxe0lijUJvCLR25HPEbRUT6ZPzUa0RsQ,13482
@@ -356,29 +358,29 @@
 sparseml/pytorch/sparsification/training/modifier_lr.py,sha256=m_tCydo_BHiXCHMUKZu6iqKLAP24acAT8-NLjH9RIlE,24287
 sparseml/pytorch/sparsification/training/modifier_params.py,sha256=G_0eVqu0Cup8WNLFhkfPmYnKtJlNrxcJt0FcOOdq9tA,21497
 sparseml/pytorch/sparsification/training/modifier_regularizer.py,sha256=ezHbcwI8ITgq4vwkzsWXgnq_ls6NONW_D8jEN-YR7u8,6690
 sparseml/pytorch/torchvision/__init__.py,sha256=fD0HjvgSO8WgfyPPSn7r_Fej6xWAelVJVbgWfI9ypY4,943
 sparseml/pytorch/torchvision/export_onnx.py,sha256=oiittOzvPEWMBpyldcfX6Yr7GQjKiKkOH4IUX-QQ718,6490
 sparseml/pytorch/torchvision/presets.py,sha256=PMRKjg4sBm6_UdhAV29wSSeOdDR6QlCzjcJbQWSenUA,2870
 sparseml/pytorch/torchvision/sampler.py,sha256=VuebeOVoQWLsafwJEeGgKQrDfF8PxzimHWFLs9odGz8,2530
-sparseml/pytorch/torchvision/train.py,sha256=_Gb3NxWdyTYhpD4qugKLXzReToQVpzvUlyFfsIFS7qw,42927
+sparseml/pytorch/torchvision/train.py,sha256=RwHFh5Mn01bRP3m8Nc41irZI7QEbKTecQIxbGuvyHx0,43917
 sparseml/pytorch/torchvision/transforms.py,sha256=_WfLKV2G9ZLt2zdpKvaHA1ricPGufVIF-lzgKaOL2Ec,7128
 sparseml/pytorch/torchvision/utils.py,sha256=weRmF78Qf9_Kgd-L7aAHERmXKoCVqUP4J8pbSZmav58,16675
 sparseml/pytorch/utils/__init__.py,sha256=WWPrEPVj8YsCZN0JemnAF5z7hOf0nL203uixlqWoAeo,1160
 sparseml/pytorch/utils/benchmarker.py,sha256=Zw1pEj7wDe4ZU_-G0JOCymdLXydN19K1QZKzPJvBp9E,9706
 sparseml/pytorch/utils/callbacks.py,sha256=1z10T8xE0IY5mcL2ARSsHDt6sDWRVF-Nq6zVf9OvD0s,2846
 sparseml/pytorch/utils/distributed.py,sha256=lJtEvgMg6LvH9iUwhveCaWNrx_t7pjn-sOW9rfYViwI,1061
 sparseml/pytorch/utils/exporter.py,sha256=GvKBjd2WVLKJCBjfXXokF8c3vt_tq-KY_mmOgJFhcs4,30884
-sparseml/pytorch/utils/helpers.py,sha256=OVGY48sE-Cp1j5O0qylLBeMUhjyDlqjZ1RJQkA1ypXE,42297
+sparseml/pytorch/utils/helpers.py,sha256=viLrRpSYGLDcJAAj2rRkRcoQuwJfKMbrUTG7-mifl_I,42811
 sparseml/pytorch/utils/log_sparsification_info.py,sha256=o9WdrrDU8W1J09NHLnW2cja5PXNq442UFzgpXf8po8M,1663
 sparseml/pytorch/utils/logger.py,sha256=KOhmFXNj46gmy5XovwQOZigBuHidVmNqDnVWMUXD7PE,31374
 sparseml/pytorch/utils/loss.py,sha256=RWFyThMBaB-7jAVuS3_CU5bmsWOVFG1jqzPciSpVsj8,27048
 sparseml/pytorch/utils/model.py,sha256=KCEZ6cNkIzLKd6N8KqJe7GX3GD-PoWErZk05nEbQuJc,11754
 sparseml/pytorch/utils/module.py,sha256=gWKNLqn8bI_q97u_QC95WkxBPAclMCwz3HmrZEHEYtU,39117
-sparseml/pytorch/utils/sparsification.py,sha256=pY4x0xtQSZ7-y0adIl1GRr3Nkwb0ymqDGCruDs570jQ,9139
+sparseml/pytorch/utils/sparsification.py,sha256=LmG2WfSnp2rZo372dRirNsBFTd_qw1-ptZLkDZti0t0,9180
 sparseml/pytorch/utils/ssd_helpers.py,sha256=05fySE5KNwrt7UF213niHp2STRSeprlU1NbLAjpYRaU,30059
 sparseml/pytorch/utils/yolo_helpers.py,sha256=nFlDPOEWfooq8GrUzKRpr7vS36m9NQMPGZSqCYmGMks,12337
 sparseml/pytorch/utils/sparsification_info/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/pytorch/utils/sparsification_info/configs.py,sha256=t0GTpRnT4LnmxLT9XUcuh0FZna1EzCUw-VNSkHluTi8,15081
 sparseml/pytorch/utils/sparsification_info/helpers.py,sha256=8bGeZ3_WO9HmxQwf-zeKI0ax9DG6jRoMeXJWeeorI3o,4336
 sparseml/pytorch/utils/sparsification_info/module_sparsification_info.py,sha256=S-WyGuIZgQ8lZX4pj1WmXjyHEuEupMLu5ZGWvHbVIG8,2788
 sparseml/recipe_template/__init__.py,sha256=0HHlF01-zO71wTzxQ9AE8UvqmXbgoyEEykAVGcyVjWA,655
@@ -437,80 +439,108 @@
 sparseml/tensorflow_v1/utils/exporter.py,sha256=RqpSP-w21SrkA_ik9WoIWdIVAAui88AiBXxRWaDZJJs,10913
 sparseml/tensorflow_v1/utils/helpers.py,sha256=40eZgnejvIki_CdupK4V1gETAgGDE9rbEXEwuNg9ASA,996
 sparseml/tensorflow_v1/utils/loss.py,sha256=4AsXh70fjp1dDcxBUzgjjpLgndwVa1CBiMG1sYi5Was,1974
 sparseml/tensorflow_v1/utils/nets_utils.py,sha256=cOTKgw7PVPEjRVU-bvcsNLdBJGTi-A7djJaUaZQwsT4,8119
 sparseml/tensorflow_v1/utils/summary.py,sha256=A2ub7KDwzsaindIuCHa7N3cRpCU6d7QbD5uNHV-R6H8,1327
 sparseml/tensorflow_v1/utils/variable.py,sha256=6ziLaNOLnxQrSPWJ2RaINqg4w-4NK9reVJWH-weK3-k,12536
 sparseml/tools/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
-sparseml/transformers/__init__.py,sha256=3f1gBs7MqwlliirNHxjPWJQFxXkda4TEVtDRENTyxCw,2060
-sparseml/transformers/export.py,sha256=CfMU8Z8Ums2wbATRzqTB-ciEE1p83IROSZVPwZGU8-A,23943
+sparseml/transformers/__init__.py,sha256=IG8RRDXHDzWCpN1GPagT3HBeNJu96Iiaf6LTCHNoVuc,1193
+sparseml/transformers/base.py,sha256=-d4OhazJ6EDau7Ug3OjwISsP8NQKjU5ptnsvazBiJZs,985
+sparseml/transformers/export.py,sha256=h1fumr-V_TGUTT3VITtPhT7P5qhXd4MKdHJgRXL8AgE,23904
 sparseml/transformers/integration_helper_functions.py,sha256=4swIpJyutt9WX7375JRX9Vo8lWKwDAvFaY7US7RNZOM,9485
-sparseml/transformers/masked_language_modeling.py,sha256=xV1H7jyWCWMKTiow501cI498I5ouNC68nF7g-QNuzjw,30756
-sparseml/transformers/question_answering.py,sha256=AZnC7mlibBPijps7yCbqVPj8voJOCQJ4rECt29FIZwg,36976
-sparseml/transformers/text_classification.py,sha256=UYCpgSGTkmeGOeePQF5Idd8uY4GHQc-ShZK5SFOlP7E,40299
+sparseml/transformers/masked_language_modeling.py,sha256=VxuHhEPXUu2nuv73eTUYbtVSnK101NrtYpwOQaS8QCA,30795
+sparseml/transformers/question_answering.py,sha256=b5fMA_dMKsxl-BEI2yIkn1hjJ2kz8VfYwZBHInnD8pQ,37002
+sparseml/transformers/text_classification.py,sha256=QfpUTL7nfPNcMYVxNhySFjLd4BKBhGqSR-YS83oQEOk,40360
 sparseml/transformers/text_generation.py,sha256=RDCzUC4tjfgkyzAOdkYvie563fez1dYivD_U4cmpWu8,818
-sparseml/transformers/token_classification.py,sha256=6RUe1CmXQv7dHsE35aTg-xLW1g4BGakRp6pn0un2_mE,34350
+sparseml/transformers/token_classification.py,sha256=Opb0gL8Das6sDsxdDd9DirFUWVg7IYHpMGImL_yfU-Q,34389
+sparseml/transformers/compression/__init__.py,sha256=e-naxCnurIkngVTQ3eIU13CqTg0N0jQ_Xm0_3wZYtgo,683
+sparseml/transformers/compression/compressors/__init__.py,sha256=fXlgLEeFgLXdc7ofYWIJ07VOUUoD5pcPiSAKndHsAqg,749
+sparseml/transformers/compression/compressors/base.py,sha256=GNFr2mfDVrDT5kvJzhtraizzo2Ad6ReSmtWTlvmiWG0,3136
+sparseml/transformers/compression/compressors/dense.py,sha256=akD31OMTJfee2QkGS4ZlJn1LUuKn5XnJSuyyPmRbDMQ,1160
+sparseml/transformers/compression/compressors/sparse_bitmask.py,sha256=mDRmFX4lDQnazphaj68ZEU1sgIhA8ILNS90bbvn6X5Y,8377
+sparseml/transformers/compression/config/__init__.py,sha256=fV4XY44QQ5krlLZhf11OIg7Q91vDcTW5blRITa7LL4c,751
+sparseml/transformers/compression/config/base.py,sha256=Ova_943QUCtB7RcCjPRIQvcdCmSWd5TS7X9PLMRkeJQ,3846
+sparseml/transformers/compression/config/dense.py,sha256=j5Tp-xGtqMK6TtModLIA4h5nc1BkKW6VWM2TXKtkDRQ,1263
+sparseml/transformers/compression/config/sparse_bitmask.py,sha256=Q6lcE-7xlc-KhaldDWfG7foHwlCcW3gZqQ4KnK2Gx4s,1236
+sparseml/transformers/compression/utils/__init__.py,sha256=VJzYDHjYGHcqVRrO06Pgstju2Df4rhVhQt3W-LIdIbk,718
+sparseml/transformers/compression/utils/compress_save.py,sha256=J5CbPJH3LZdQAW2_1xm_tr4yQqQwIxVs78WhV10GXfY,6092
+sparseml/transformers/compression/utils/helpers.py,sha256=VngJebXKN0tyxLlzl5--DhwOLUJ8BxI55MwXHdaBPos,1778
+sparseml/transformers/compression/utils/safetensors_load.py,sha256=VYNcQ8S2BMgJFlOpWndOpO60zE8fYF6QJV4gcBUlloQ,5276
 sparseml/transformers/finetune/__init__.py,sha256=0bOoxD9cLg2VVtreGrcrakhzdMeUmFeTWFhm3oZkRp8,701
 sparseml/transformers/finetune/callbacks.py,sha256=j7k7LDuMmOZcn0PKxbNdcho2nAGq4lMMvRNo21DDS98,5251
-sparseml/transformers/finetune/model_args.py,sha256=Bsd-YCTMUjexif18Z6yzSqvK2gb8OjKXAZO3g8gY5CA,2346
-sparseml/transformers/finetune/runner.py,sha256=lCckA_DdCsni4slDYeOyjQ1_M2Dd0JZZSEOsTUJSaPI,11539
-sparseml/transformers/finetune/session_mixin.py,sha256=ppr9dJl9KpMzQJSospTxSLVm81oKChRaa3X-PdTrcB8,22233
-sparseml/transformers/finetune/text_generation.py,sha256=xDU2m4GmCffvChso70lTCHKQzBIbyZmYNTISJT0vAlE,13019
+sparseml/transformers/finetune/model_args.py,sha256=RkppN_0YiHjK1PUCAuKZsGvIs52FHLAc8pJNqymbHPE,2519
+sparseml/transformers/finetune/runner.py,sha256=aQxCzxEBRAe8Z_YAIY_Tz491hvQdn2r7VN-z2F3ZVBA,11988
+sparseml/transformers/finetune/session_mixin.py,sha256=1PL-z7vx43prOiqnRKkdR6mKLrwp0mv4eLcsVIpqF-c,22944
+sparseml/transformers/finetune/text_generation.py,sha256=lvCIcuV1N9GVfYYjXe3BSjw3JE6LAKejpKrWy0zNho0,13101
 sparseml/transformers/finetune/trainer.py,sha256=xqbz1ClwV3Fe9dw4batuLMp1-KiXBT-qqP_Y93YlgI0,4290
-sparseml/transformers/finetune/training_args.py,sha256=gWXpk4Cnm2ytS3FOR_4ABKDffgjZ8mlKjNi2E4QNriw,3028
-sparseml/transformers/finetune/data/__init__.py,sha256=q83O2uMX8NPmVyOOi5xYjq4Ulr25McH9glgu8dK2-1Q,974
+sparseml/transformers/finetune/training_args.py,sha256=BLe9Wjcf-HVpds_1XS8NPHZzm10WQ3_Ii-EjS0ODc2U,3005
+sparseml/transformers/finetune/data/__init__.py,sha256=1suS2CfhJGBW08wniPgbFuOLG4g71rBu7f15OrI7ZrQ,1021
 sparseml/transformers/finetune/data/base.py,sha256=GwABRyBbLgooASRO-XpNvrj-_omS_oVAvBdI_59iSFg,8736
 sparseml/transformers/finetune/data/c4.py,sha256=tJW0Dnf5rs6uFmgoRD0TGuf9Sl0qLDkiVdMAtwhceSo,1322
-sparseml/transformers/finetune/data/custom.py,sha256=WYA_nGVx-AbAhxLteXj3uKGGk8h3zJY9gDqCi-FgheY,3659
-sparseml/transformers/finetune/data/data_args.py,sha256=HUmB3usT5eA8z1WF3JtJpDr8Ptezg3k3Pkdrp2WYw6Q,5194
-sparseml/transformers/finetune/data/data_helpers.py,sha256=Shgt_PfBKWXgAYYJ2SPR6Gu7rq1rKz3D6Cf8xfcK4fE,7914
+sparseml/transformers/finetune/data/cnn_dailymail.py,sha256=EpASl2Rd2L2IURBm8ALVkUbE-RAxzoW0LFmOsRxJs10,2537
+sparseml/transformers/finetune/data/custom.py,sha256=WqKecNf45cS1pGe8T9M_AccvSFAFO5YNJEUoyHA9tbY,4281
+sparseml/transformers/finetune/data/data_args.py,sha256=MEwc-aPL8TxZsEUtRuZVDN1OEg8YD4RhZ1nqtX-Th58,5399
+sparseml/transformers/finetune/data/data_helpers.py,sha256=XPcTLw3EFHlYXUazPOyx0EJsoZOIg0ORwBcTkjL9ML8,8961
 sparseml/transformers/finetune/data/evolcodealpaca.py,sha256=-P8hAodeEQ3QDGw17UXf7igRHlCU2e74ntjzExXtZ4I,2892
 sparseml/transformers/finetune/data/gsm8k.py,sha256=jHAwAUScU9a4jsnl0edtmvhSUVLlxFy07fczMjN90gI,2597
 sparseml/transformers/finetune/data/open_platypus.py,sha256=ZJEPEiiJtKpxKm5rOTUHdANnTk0C24mGL3lpghSpj8w,3435
 sparseml/transformers/finetune/data/ptb.py,sha256=mr572aTmdSK7AyY3btPE0eQh27Xcx-dnWY76jcdtMFg,1369
 sparseml/transformers/finetune/data/ultrachat_200k.py,sha256=lRNNO7JV0SIxp1SMp2RG25R4jBpD2_LopsjqCc1KhB8,3521
 sparseml/transformers/finetune/data/wikitext.py,sha256=jHCYaAqMx2vgInMV2-Hg7wXh-TU4TZ691rAkVkP9UnM,1237
-sparseml/transformers/sparsification/__init__.py,sha256=22XZNePvLFXNxp5NrcUIXzjgynCZm6jvQOErpRGlQNY,833
+sparseml/transformers/sparsification/__init__.py,sha256=f1YW4ztJxM1OlRPimYAW4nIabqDUSaUArM-VuFbJtSA,922
 sparseml/transformers/sparsification/question_answering.py,sha256=FAXhtQ8MW_2ar1dix2tQ1x1RXZuSWMLHZbVHToNWwmo,19529
+sparseml/transformers/sparsification/sparse_config.py,sha256=1zAwQcO2yQB-b0kecaAXECJMjlwIQPEKnui90Wvj7Dw,1874
+sparseml/transformers/sparsification/sparse_model.py,sha256=4SI32FTT7S49vIMwMYWCTIFrBhg4fRX0TOIKfcbmv1s,20054
+sparseml/transformers/sparsification/sparse_tokenizer.py,sha256=kW_7pQ4awjsGMx3pzPvOS89n6T3ehBes1geop02XWKY,2327
 sparseml/transformers/sparsification/trainer.py,sha256=ssoMIFie31582qtzB-NGXS3abdF89rM7S_9xMN0amqY,41727
 sparseml/transformers/sparsification/training_args.py,sha256=gGivIDchLi__PZMNQRmzDOaQcQLkUVFystq3LaVko3Y,1890
+sparseml/transformers/sparsification/modification/__init__.py,sha256=LpHfgSjpeYu_-E54ddk0bOd3X_uuUMcQQvKBi4GfXtU,866
+sparseml/transformers/sparsification/modification/base.py,sha256=yKqZLDDoS-0z18WhNJsufxS9gzdTQnnjsPNx2K2T044,2429
+sparseml/transformers/sparsification/modification/modification_objects.py,sha256=hZzGEv1pg7z8CKpdQpBpnB-0cBVuwJM2c8SxYODAL5E,3922
+sparseml/transformers/sparsification/modification/modify_model.py,sha256=RI2DrXwX0MfCQmWQkUUwJV0beemUa7hZGq7wNp5Q6MQ,2434
+sparseml/transformers/sparsification/modification/modifying_bert.py,sha256=kzZpKS_PHW_TPcIwl95Od0N45qVeL-RqynbT7h9YgJQ,9199
+sparseml/transformers/sparsification/modification/modifying_distilbert.py,sha256=3tu06QFnJLJaAHb3zFW2LjVWxzqfpZ6Zek8hFDyCqM4,5492
+sparseml/transformers/sparsification/modification/modifying_llama.py,sha256=ID2z-ztbQnhsEZ8G6McYYQ3eLq-TiK5ltoMZj6aurWI,8703
+sparseml/transformers/sparsification/modification/modifying_mistral.py,sha256=5df_N0uBvFwC7y7VB7R3na8Dv--kIg2dYUDdhcInDPw,6945
+sparseml/transformers/sparsification/modification/modifying_mobilebert.py,sha256=ZCUhkLeX36sQ75yRuxXETUlwG4VoChnoEljxiznCQHs,2549
+sparseml/transformers/sparsification/modification/modifying_opt.py,sha256=sBeWxuxXVgcHoVk1hU4K9VObNqdAKX-z15JyzRwV2QI,9618
+sparseml/transformers/sparsification/modification/registry.py,sha256=U4AeTD4xJHt3pnn6iXskq3zP1GY1d26h9owV4r3OdzE,1486
 sparseml/transformers/sparsification/obcq/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
-sparseml/transformers/sparsification/obcq/export.py,sha256=r4WxLCiNmO7qA6TFPAEwmQN5AJypE5fjRNWMOCi_wc0,19722
+sparseml/transformers/sparsification/obcq/export.py,sha256=6gJHqz0J4tNanmEC0fi1xn6jQ4Y0WEqzJg1nHfH4PXM,19683
 sparseml/transformers/sparsification/obcq/obcq.py,sha256=QLN1ywZCCMF5GH-Z0-ETf4EpsdfR589h8ws-_-EJL2A,7695
 sparseml/transformers/sparsification/obcq/utils/__init__.py,sha256=fH6rjBYAxuwrTzBTlTjTgCYNyh6TCvCqajCz4Im4YrA,617
 sparseml/transformers/sparsification/obcq/utils/helpers.py,sha256=btmRVzMnGC4rxqeFRaZxVfewVhoerib6xA62cBuyFfA,3671
-sparseml/transformers/utils/__init__.py,sha256=kFlebbE3efp5UtG6AsYJa-RwHD8WxKCfyaMLAQUWoUQ,894
-sparseml/transformers/utils/helpers.py,sha256=vZ0MRPGM1YklLT5_6eKIDAf_eh-MBaqKn5CCjGoOrIY,20002
+sparseml/transformers/utils/__init__.py,sha256=NVWYxKuoVwMglNalk_zs0PiDi6ec4JHG-DsuCNEDkBY,805
+sparseml/transformers/utils/helpers.py,sha256=few6gxw9b04X2xVCbNJC26vyoB_1NIlXB7SlGZ8WCzM,20055
 sparseml/transformers/utils/initializers.py,sha256=UrFAqZhQemFOGu8ljmpqpm2mDV4rpP7NfNMzscbtz58,6711
 sparseml/transformers/utils/load_task_dataset.py,sha256=zwOhd7deFZmgerr1ohhICHulOrMYnxx2XEs9bQbXFG0,5081
-sparseml/transformers/utils/load_task_model.py,sha256=hHBmSJ6jJVo8CJCx11Zk_lalKSz_2uh1TytroCCr9aE,2755
+sparseml/transformers/utils/load_task_model.py,sha256=9YQhIMpFeZB48uaJjgOD1Vy_D8NDp2s2JzUPsqpbOrE,2764
 sparseml/transformers/utils/metrics.py,sha256=ciZsxgdrzlSMnyzbgKOFE3spWsKql0z82BiYFRXiVOU,2536
 sparseml/transformers/utils/optimizations.py,sha256=InpU3m6pHp_2X9PEq_ueYL4iHI512LprVJAaY5Io_6A,1972
-sparseml/transformers/utils/sparse_config.py,sha256=1zAwQcO2yQB-b0kecaAXECJMjlwIQPEKnui90Wvj7Dw,1874
-sparseml/transformers/utils/sparse_model.py,sha256=CCzgiHrnltSb0VNPmVtUANly6T091zTiidtzrlMBt3M,18556
-sparseml/transformers/utils/sparse_tokenizer.py,sha256=3CfMP0DfFucvw-nrS_W6YNme-RVIb6nhN-PyJ2Qm5q0,2178
+sparseml/transformers/utils/preprocessing_functions.py,sha256=fPmmo1StTu4845lqZvyRyrXZOro-BrmWTMX3hJPUBZM,1037
 sparseml/utils/__init__.py,sha256=-WKBN4DERhw7rTJkarilkyAM9pw4rW8qkXGRPSEJ8SM,844
 sparseml/utils/frameworks.py,sha256=S-cGkbVc6DoWfI6Hu5AkIqF0Vi1PyxKX5GfhwRfpv_E,886
-sparseml/utils/helpers.py,sha256=zAsLq86m-rFVciQAOC45S50KTLC7DNr27joUyQ9a6Fs,30188
+sparseml/utils/helpers.py,sha256=bjGYhUh5pu4-Wh2qr4f_5nctMeM_BOa0bjwZCygAAzE,31604
 sparseml/utils/restricted_eval.py,sha256=bBScMel61Cl3OcXs1TvxQgao1P2cJgmeDHeLSHF5Cqg,3983
 sparseml/utils/singleton.py,sha256=SbOoiw_CW7d9TEYIcvfb_ueaAD4iKbURZiTlBfM173g,1083
 sparseml/utils/worker.py,sha256=swoPegdTmV8nYbyie2WUytLLdwaK9skjx4RejHD3cww,6312
 sparseml/utils/wrapper.py,sha256=xrhPKRrXajQtDGIS--ZZxLsvnVTnnP0vlcnt_Tyd--g,2952
 sparseml/utils/datasets/__init__.py,sha256=HFbqzS5n0692VGBO5eqlTxc14WlRM2S_Qt2xhFxsGE4,819
 sparseml/utils/datasets/cifar.py,sha256=tvkMGu8afg9-EVlHXAEfEYXkje8nFzgnlG4mREsbxzE,833
 sparseml/utils/datasets/coco.py,sha256=5w9Fm0O2kUtrC1upa6DCC4WZ13df-ZlORPUHEwGFDLc,3750
 sparseml/utils/datasets/helpers.py,sha256=1i1jiOoj1q-_Nef5dJBWHoO9v7ZjogggihDjBMNbf_A,1217
 sparseml/utils/datasets/imagenet.py,sha256=qAL7K6tmlfwBY7FI14wcVb-7g3Rzs4wtZIOV1kvoV0w,23366
 sparseml/utils/datasets/imagenette.py,sha256=AIxAI0wfUqu08XPJ1cG8SNUVocjoeFHVepQZDfsztFI,8967
 sparseml/utils/datasets/voc.py,sha256=CzSEnTe-KqWyOLwleame66PtYqF8vuq9EXaNgmms6u0,1009
 sparseml/utils/fsdp/__init__.py,sha256=TF5uEKrpc2qYdbgmXh9xVp2GQ3p--by-LoCegY19EeI,633
 sparseml/utils/fsdp/context.py,sha256=z3d6oH1eebYnOTVd8-fGRXo6pMV2NLhTiXMNYbQ8v0g,2096
-sparseml/utils/fsdp/helpers.py,sha256=kZXGL0h9aHxCvv6DCEh4rr_GO8HTA-8Q_9xSu_uYcQw,5492
+sparseml/utils/fsdp/helpers.py,sha256=TJN6AASbh6H7kLvNXh8d1R81BRO3HiXcOdXNVTaE5pk,6631
 sparseml/utils/pytorch/__init__.py,sha256=zgv8znrlT0w5SeQUkCnbZGVhFyBS_bD4Ojx7x2xz7tI,656
-sparseml/utils/pytorch/module.py,sha256=eE_Vx6SlTaoNSYcFjaZ3xbLhdpTju-tf7Wq2DVzxTPo,9787
+sparseml/utils/pytorch/module.py,sha256=37S5evDCaNt1ZKWDrc8WGpQngu66wWcKn9v9M48UsyM,10897
+sparseml/utils/pytorch/utils.py,sha256=x5G0_FNF12xX-WFd5Al2GcRfSzRprx-1rjxWp4AHBII,1696
 sparseml/utils/pytorch/pruning/__init__.py,sha256=N03cP9aDRA_oYadFQPEHg7vkR8hzQrh8CXeDN4AZPb8,680
 sparseml/yolact/COCO.sh,sha256=Q_1I3VZwS4N1e3AwOoimQH2plK2K0athUDWooWR4ZVQ,1875
 sparseml/yolact/COCO_test.sh,sha256=ZoA_h_68zM8EWF510o24_5xBaQtbJLMHenNjSzldYYc,1418
 sparseml/yolact/__init__.py,sha256=5t9V0aePHnzJBik6z1r4W_3DsSn0lKpYjl3pIuZQft0,4020
 sparseml/yolact/scripts.py,sha256=7GE3xp_B8JJpa2H-Vum6rmiOJHcChyffuno4-yteUUw,1784
 sparseml/yolov5/__init__.py,sha256=LiVvIlHR1FF63Ixm2MabdDH1Ul8sFEUEIb3Sbs4awLI,1440
 sparseml/yolov5/helpers.py,sha256=jxzJrgKjsb0PHTeGevKICaL8iBOUzxwZXvPAyGyVE-c,4505
@@ -523,15 +553,15 @@
 sparseml/yolov8/train.py,sha256=eetdfCbRQJdBWc7XHb9GYPqMQxZzbKG7FG-4xQeTutk,7394
 sparseml/yolov8/trainers.py,sha256=uQsIX5Zyv6mkK8NLJqmM5kukHojZTZmVEKTKm1pkgxU,37860
 sparseml/yolov8/val.py,sha256=hlFImvknSpV1nONOxA3ivYgvzm64EmK0_Lh-JHLbOsw,2748
 sparseml/yolov8/validators.py,sha256=fkEnjRp1day-KY0n7DZ_VI-zmNqKbalh-g6U-lwHmfQ,8459
 sparseml/yolov8/utils/__init__.py,sha256=6JekgnibQP-8p8Dm1dGiIEGCGdBOAkSOnEds0BMSYhQ,685
 sparseml/yolov8/utils/export_samples.py,sha256=HFmQsXpmXZlxLTNBvHwp-lcM5mVcZN1ouBfAXTdYFeM,6683
 sparseml/yolov8/utils/helpers.py,sha256=8JZNaTT1zPKiZaOccmMtQu5mXCSMGkq8BDEgUqaPVIs,4041
-sparseml_nightly-1.7.0.20240304.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-sparseml_nightly-1.7.0.20240304.dist-info/LICENSE-ULTRALYTICS,sha256=JtH3RHvJDRVTEhj6JJZJH5MQFk5IkSg_TxYAqtPEOOs,13747
-sparseml_nightly-1.7.0.20240304.dist-info/METADATA,sha256=CuLLr6RDXXzEzGLNaBpQ2cHeLiqCSDkBWkHWyMBjHG8,23605
-sparseml_nightly-1.7.0.20240304.dist-info/NOTICE,sha256=jkdOJGVbNDogFmOaXgc_Qr6U35t67RqzUJgf_Yc8C5w,2085
-sparseml_nightly-1.7.0.20240304.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-sparseml_nightly-1.7.0.20240304.dist-info/entry_points.txt,sha256=AOCpCae2aLRUTce3NNDHYPZevTpJ-GTOQuzy8YPafmc,3122
-sparseml_nightly-1.7.0.20240304.dist-info/top_level.txt,sha256=JOOlWKgkyuJBScnty7pC1SQ58fOo1ONbslvMdxB6L2M,9
-sparseml_nightly-1.7.0.20240304.dist-info/RECORD,,
+sparseml_nightly-1.8.0.20240401.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+sparseml_nightly-1.8.0.20240401.dist-info/LICENSE-ULTRALYTICS,sha256=JtH3RHvJDRVTEhj6JJZJH5MQFk5IkSg_TxYAqtPEOOs,13747
+sparseml_nightly-1.8.0.20240401.dist-info/METADATA,sha256=T6Y6oxAQD72KB5GzHFP2Pz8XVMeq_HsPSDMzTZX187Y,23637
+sparseml_nightly-1.8.0.20240401.dist-info/NOTICE,sha256=jkdOJGVbNDogFmOaXgc_Qr6U35t67RqzUJgf_Yc8C5w,2085
+sparseml_nightly-1.8.0.20240401.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+sparseml_nightly-1.8.0.20240401.dist-info/entry_points.txt,sha256=AOCpCae2aLRUTce3NNDHYPZevTpJ-GTOQuzy8YPafmc,3122
+sparseml_nightly-1.8.0.20240401.dist-info/top_level.txt,sha256=JOOlWKgkyuJBScnty7pC1SQ58fOo1ONbslvMdxB6L2M,9
+sparseml_nightly-1.8.0.20240401.dist-info/RECORD,,
```

